[{"authorTime":"2020-12-04 13:20:34","codes":[{"authorDate":"2020-12-04 13:20:34","commitOrder":1,"curCode":"  public void testSingleTopic() {\n    KafkaSource source = new UniversalKafkaSource();\n    SourceState state = new SourceState(new State(props));\n    state.setProp(\"gobblin.kafka.streaming.enableIndexing\", false);\n    state.setProp(ConfigurationKeys.WRITER_OUTPUT_DIR, Files.createTempDir().getAbsolutePath());\n\n    Map<String, List<WorkUnit>> workUnitsByTopic = ImmutableMap.of(\"topic1\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic1\", 1), getWorkUnitWithTopicPartition(\"topic1\", 2),\n            getWorkUnitWithTopicPartition(\"topic1\", 3)));\n\n    List<WorkUnit> workUnits = new KafkaTopicGroupingWorkUnitPacker(source, state, Optional.absent()).pack(workUnitsByTopic, 10);\n    Assert.assertEquals(workUnits.size(), 2);\n    Assert.assertEquals(workUnits.get(0).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(1).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(1).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n  }\n","date":"2020-12-04 13:20:34","endLine":74,"groupId":"195","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSingleTopic","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/eb/676d407819d52b41749580e39df34d318699d1.src","preCode":"  public void testSingleTopic() {\n    KafkaSource source = new UniversalKafkaSource();\n    SourceState state = new SourceState(new State(props));\n    state.setProp(\"gobblin.kafka.streaming.enableIndexing\", false);\n    state.setProp(ConfigurationKeys.WRITER_OUTPUT_DIR, Files.createTempDir().getAbsolutePath());\n\n    Map<String, List<WorkUnit>> workUnitsByTopic = ImmutableMap.of(\"topic1\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic1\", 1), getWorkUnitWithTopicPartition(\"topic1\", 2),\n            getWorkUnitWithTopicPartition(\"topic1\", 3)));\n\n    List<WorkUnit> workUnits = new KafkaTopicGroupingWorkUnitPacker(source, state, Optional.absent()).pack(workUnitsByTopic, 10);\n    Assert.assertEquals(workUnits.size(), 2);\n    Assert.assertEquals(workUnits.get(0).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(1).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(1).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n  }\n","realPath":"gobblin-modules/gobblin-kafka-common/src/test/java/org/apache/gobblin/source/extractor/extract/kafka/workunit/packer/KafkaTopicGroupingWorkUnitPackerTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"B"},{"authorDate":"2020-12-04 13:20:34","commitOrder":1,"curCode":"  public void testMultiTopic() {\n    KafkaSource source = new UniversalKafkaSource();\n    SourceState state = new SourceState(new State(props));\n    state.setProp(\"gobblin.kafka.streaming.enableIndexing\", false);\n    state.setProp(ConfigurationKeys.WRITER_OUTPUT_DIR, Files.createTempDir().getAbsolutePath());\n\n    Map<String, List<WorkUnit>> workUnitsByTopic = ImmutableMap.of(\"topic1\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic1\", 1), getWorkUnitWithTopicPartition(\"topic1\", 2),\n            getWorkUnitWithTopicPartition(\"topic1\", 3)), \"topic2\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic2\", 1), getWorkUnitWithTopicPartition(\"topic2\", 2),\n            getWorkUnitWithTopicPartition(\"topic2\", 3)));\n\n    List<WorkUnit> workUnits = new KafkaTopicGroupingWorkUnitPacker(source, state, Optional.absent()).pack(workUnitsByTopic, 10);\n    Assert.assertEquals(workUnits.size(), 4);\n\n    Assert.assertEquals(workUnits.get(0).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(1).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(1).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n\n    Assert.assertEquals(workUnits.get(2).getProp(KafkaSource.TOPIC_NAME), \"topic2\");\n    Assert.assertEquals(workUnits.get(2).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(2).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(3).getProp(KafkaSource.TOPIC_NAME), \"topic2\");\n    Assert.assertEquals(workUnits.get(3).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n  }\n","date":"2020-12-04 13:20:34","endLine":106,"groupId":"195","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testMultiTopic","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/eb/676d407819d52b41749580e39df34d318699d1.src","preCode":"  public void testMultiTopic() {\n    KafkaSource source = new UniversalKafkaSource();\n    SourceState state = new SourceState(new State(props));\n    state.setProp(\"gobblin.kafka.streaming.enableIndexing\", false);\n    state.setProp(ConfigurationKeys.WRITER_OUTPUT_DIR, Files.createTempDir().getAbsolutePath());\n\n    Map<String, List<WorkUnit>> workUnitsByTopic = ImmutableMap.of(\"topic1\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic1\", 1), getWorkUnitWithTopicPartition(\"topic1\", 2),\n            getWorkUnitWithTopicPartition(\"topic1\", 3)), \"topic2\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic2\", 1), getWorkUnitWithTopicPartition(\"topic2\", 2),\n            getWorkUnitWithTopicPartition(\"topic2\", 3)));\n\n    List<WorkUnit> workUnits = new KafkaTopicGroupingWorkUnitPacker(source, state, Optional.absent()).pack(workUnitsByTopic, 10);\n    Assert.assertEquals(workUnits.size(), 4);\n\n    Assert.assertEquals(workUnits.get(0).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(1).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(1).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n\n    Assert.assertEquals(workUnits.get(2).getProp(KafkaSource.TOPIC_NAME), \"topic2\");\n    Assert.assertEquals(workUnits.get(2).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(2).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(3).getProp(KafkaSource.TOPIC_NAME), \"topic2\");\n    Assert.assertEquals(workUnits.get(3).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n  }\n","realPath":"gobblin-modules/gobblin-kafka-common/src/test/java/org/apache/gobblin/source/extractor/extract/kafka/workunit/packer/KafkaTopicGroupingWorkUnitPackerTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":80,"status":"B"}],"commitId":"44d7aa00b1a8ecf50974d1004f8ff18677eeffed","commitMessage":"@@@[GOBBLIN-1259] Implement a Kafka streaming extractor\n\nCloses #3102 from sv2000/kafkaStreamingExtractor\n","date":"2020-12-04 13:20:34","modifiedFileCount":"4","status":"B","submitter":"Sudarshan Vasudevan"},{"authorTime":"2021-03-17 03:47:43","codes":[{"authorDate":"2021-03-17 03:47:43","commitOrder":2,"curCode":"  public void testSingleTopic() {\n    KafkaSource source = new UniversalKafkaSource();\n    SourceState state = new SourceState(new State(props));\n    state.setProp(\"gobblin.kafka.streaming.enableIndexing\", false);\n    state.setProp(ConfigurationKeys.WRITER_OUTPUT_DIR, Files.createTempDir().getAbsolutePath());\n\n    Map<String, List<WorkUnit>> workUnitsByTopic = ImmutableMap.of(\"topic1\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic1\", 1), getWorkUnitWithTopicPartition(\"topic1\", 2),\n            getWorkUnitWithTopicPartition(\"topic1\", 3)));\n\n    List<WorkUnit> workUnits = new KafkaTopicGroupingWorkUnitPacker(source, state, Optional.absent()).pack(workUnitsByTopic, 10);\n    Assert.assertEquals(workUnits.size(), 2);\n    Assert.assertEquals(workUnits.get(0).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(0).getPropAsDouble(KafkaTopicGroupingWorkUnitPacker.CONTAINER_CAPACITY_KEY), 2, 0.001);\n    Assert.assertEquals(workUnits.get(1).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(1).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n    Assert.assertEquals(workUnits.get(1).getPropAsDouble(KafkaTopicGroupingWorkUnitPacker.CONTAINER_CAPACITY_KEY), 2, 0.001);\n  }\n","date":"2021-03-17 03:47:43","endLine":76,"groupId":"10436","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"testSingleTopic","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b4/4df38baaba02ad5e6e5d9f8ff09c8c1a1dfa34.src","preCode":"  public void testSingleTopic() {\n    KafkaSource source = new UniversalKafkaSource();\n    SourceState state = new SourceState(new State(props));\n    state.setProp(\"gobblin.kafka.streaming.enableIndexing\", false);\n    state.setProp(ConfigurationKeys.WRITER_OUTPUT_DIR, Files.createTempDir().getAbsolutePath());\n\n    Map<String, List<WorkUnit>> workUnitsByTopic = ImmutableMap.of(\"topic1\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic1\", 1), getWorkUnitWithTopicPartition(\"topic1\", 2),\n            getWorkUnitWithTopicPartition(\"topic1\", 3)));\n\n    List<WorkUnit> workUnits = new KafkaTopicGroupingWorkUnitPacker(source, state, Optional.absent()).pack(workUnitsByTopic, 10);\n    Assert.assertEquals(workUnits.size(), 2);\n    Assert.assertEquals(workUnits.get(0).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(1).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(1).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n  }\n","realPath":"gobblin-modules/gobblin-kafka-common/src/test/java/org/apache/gobblin/source/extractor/extract/kafka/workunit/packer/KafkaTopicGroupingWorkUnitPackerTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":57,"status":"M"},{"authorDate":"2021-03-17 03:47:43","commitOrder":2,"curCode":"  public void testMultiTopic() {\n    KafkaSource source = new UniversalKafkaSource();\n    SourceState state = new SourceState(new State(props));\n    state.setProp(\"gobblin.kafka.streaming.enableIndexing\", false);\n    state.setProp(ConfigurationKeys.WRITER_OUTPUT_DIR, Files.createTempDir().getAbsolutePath());\n\n    Map<String, List<WorkUnit>> workUnitsByTopic = ImmutableMap.of(\"topic1\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic1\", 1), getWorkUnitWithTopicPartition(\"topic1\", 2),\n            getWorkUnitWithTopicPartition(\"topic1\", 3)), \"topic2\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic2\", 1), getWorkUnitWithTopicPartition(\"topic2\", 2),\n            getWorkUnitWithTopicPartition(\"topic2\", 3)));\n\n    List<WorkUnit> workUnits = new KafkaTopicGroupingWorkUnitPacker(source, state, Optional.absent()).pack(workUnitsByTopic, 10);\n    Assert.assertEquals(workUnits.size(), 4);\n\n    Assert.assertEquals(workUnits.get(0).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(0).getPropAsDouble(KafkaTopicGroupingWorkUnitPacker.CONTAINER_CAPACITY_KEY), 2, 0.001);\n\n    Assert.assertEquals(workUnits.get(1).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(1).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n    Assert.assertEquals(workUnits.get(1).getPropAsDouble(KafkaTopicGroupingWorkUnitPacker.CONTAINER_CAPACITY_KEY), 2, 0.001);\n\n    Assert.assertEquals(workUnits.get(2).getProp(KafkaSource.TOPIC_NAME), \"topic2\");\n    Assert.assertEquals(workUnits.get(2).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(2).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(2).getPropAsDouble(KafkaTopicGroupingWorkUnitPacker.CONTAINER_CAPACITY_KEY), 2, 0.001);\n\n    Assert.assertEquals(workUnits.get(3).getProp(KafkaSource.TOPIC_NAME), \"topic2\");\n    Assert.assertEquals(workUnits.get(3).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n    Assert.assertEquals(workUnits.get(3).getPropAsDouble(KafkaTopicGroupingWorkUnitPacker.CONTAINER_CAPACITY_KEY), 2, 0.001);\n  }\n","date":"2021-03-17 03:47:43","endLine":114,"groupId":"10436","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testMultiTopic","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-gobblin-10-0.7/blobInfo/CC_OUT/blobs/b4/4df38baaba02ad5e6e5d9f8ff09c8c1a1dfa34.src","preCode":"  public void testMultiTopic() {\n    KafkaSource source = new UniversalKafkaSource();\n    SourceState state = new SourceState(new State(props));\n    state.setProp(\"gobblin.kafka.streaming.enableIndexing\", false);\n    state.setProp(ConfigurationKeys.WRITER_OUTPUT_DIR, Files.createTempDir().getAbsolutePath());\n\n    Map<String, List<WorkUnit>> workUnitsByTopic = ImmutableMap.of(\"topic1\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic1\", 1), getWorkUnitWithTopicPartition(\"topic1\", 2),\n            getWorkUnitWithTopicPartition(\"topic1\", 3)), \"topic2\", Lists\n        .newArrayList(getWorkUnitWithTopicPartition(\"topic2\", 1), getWorkUnitWithTopicPartition(\"topic2\", 2),\n            getWorkUnitWithTopicPartition(\"topic2\", 3)));\n\n    List<WorkUnit> workUnits = new KafkaTopicGroupingWorkUnitPacker(source, state, Optional.absent()).pack(workUnitsByTopic, 10);\n    Assert.assertEquals(workUnits.size(), 4);\n\n    Assert.assertEquals(workUnits.get(0).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(0).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(1).getProp(KafkaSource.TOPIC_NAME), \"topic1\");\n    Assert.assertEquals(workUnits.get(1).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n\n    Assert.assertEquals(workUnits.get(2).getProp(KafkaSource.TOPIC_NAME), \"topic2\");\n    Assert.assertEquals(workUnits.get(2).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 1);\n    Assert.assertEquals(workUnits.get(2).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 1)), 2);\n    Assert.assertEquals(workUnits.get(3).getProp(KafkaSource.TOPIC_NAME), \"topic2\");\n    Assert.assertEquals(workUnits.get(3).getPropAsInt(KafkaUtils.getPartitionPropName(KafkaSource.PARTITION_ID, 0)), 3);\n  }\n","realPath":"gobblin-modules/gobblin-kafka-common/src/test/java/org/apache/gobblin/source/extractor/extract/kafka/workunit/packer/KafkaTopicGroupingWorkUnitPackerTest.java","repoName":"gobblin","snippetEndLine":0,"snippetStartLine":0,"startLine":82,"status":"M"}],"commitId":"a030866737eca462c7eec9eb11483ca09ec29e83","commitMessage":"@@@[GOBBLIN-1406] Make KafkaIngestionHealth check use auto-tuned consumer?\n\nCloses #3240 from sv2000/autotuneConsumeRate\n","date":"2021-03-17 03:47:43","modifiedFileCount":"4","status":"M","submitter":"suvasude"}]
