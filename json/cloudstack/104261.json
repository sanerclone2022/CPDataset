[{"authorTime":"2019-07-25 16:43:04","codes":[{"authorDate":"2019-07-25 16:43:04","commitOrder":1,"curCode":"    public boolean deleteDataStore(DataStore store) {\n        List<SnapshotVO> lstSnapshots = _snapshotDao.listAll();\n\n        if (lstSnapshots != null) {\n            for (SnapshotVO snapshot : lstSnapshots) {\n                SnapshotDetailsVO snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(),\n                        DateraUtil.STORAGE_POOL_ID);\n\n                \r\n                if (snapshotDetails != null && snapshotDetails.getValue() != null\n                        && Long.parseLong(snapshotDetails.getValue()) == store.getId()) {\n                    throw new CloudRuntimeException(\n                            \"This primary storage cannot be deleted because it currently contains one or more snapshots.\");\n                }\n            }\n        }\n\n        return dataStoreHelper.deletePrimaryDataStore(store);\n    }\n","date":"2019-07-25 16:43:04","endLine":350,"groupId":"15170","id":1,"instanceNumber":1,"isCurCommit":1,"methodName":"deleteDataStore","params":"(DataStorestore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cloudstack-10-0.7/blobInfo/CC_OUT/blobs/ff/253fc8d181062988ace210566305a93d847113.src","preCode":"    public boolean deleteDataStore(DataStore store) {\n        List<SnapshotVO> lstSnapshots = _snapshotDao.listAll();\n\n        if (lstSnapshots != null) {\n            for (SnapshotVO snapshot : lstSnapshots) {\n                SnapshotDetailsVO snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(),\n                        DateraUtil.STORAGE_POOL_ID);\n\n                \r\n                if (snapshotDetails != null && snapshotDetails.getValue() != null\n                        && Long.parseLong(snapshotDetails.getValue()) == store.getId()) {\n                    throw new CloudRuntimeException(\n                            \"This primary storage cannot be deleted because it currently contains one or more snapshots.\");\n                }\n            }\n        }\n\n        return dataStoreHelper.deletePrimaryDataStore(store);\n    }\n","realPath":"plugins/storage/volume/datera/src/main/java/org/apache/cloudstack/storage/datastore/lifecycle/DateraPrimaryDataStoreLifeCycle.java","repoName":"cloudstack","snippetEndLine":0,"snippetStartLine":0,"startLine":332,"status":"B"},{"authorDate":"2019-07-25 16:43:04","commitOrder":1,"curCode":"    private long getUsedBytes(StoragePool storagePool, long volumeIdToIgnore) {\n        long usedSpaceBytes = 0;\n\n        List<VolumeVO> lstVolumes = _volumeDao.findByPoolId(storagePool.getId(), null);\n\n        if (lstVolumes != null) {\n            for (VolumeVO volume : lstVolumes) {\n                if (volume.getId() == volumeIdToIgnore) {\n                    continue;\n                }\n\n                VolumeDetailVO volumeDetail = volumeDetailsDao.findDetail(volume.getId(), DateraUtil.VOLUME_SIZE);\n\n                if (volumeDetail != null && volumeDetail.getValue() != null) {\n                    long volumeSizeGib = Long.parseLong(volumeDetail.getValue());\n                    long volumeSizeBytes = DateraUtil.gibToBytes((int) (volumeSizeGib));\n                    usedSpaceBytes += volumeSizeBytes;\n                } else {\n                    DateraObject.DateraConnection conn = DateraUtil.getDateraConnection(storagePool.getId(),\n                            _storagePoolDetailsDao);\n                    try {\n\n                        String appInstanceName = getAppInstanceName(volumeDataFactory.getVolume(volume.getId()));\n                        DateraObject.AppInstance appInstance = DateraUtil.getAppInstance(conn, appInstanceName);\n                        if (appInstance != null) {\n                            usedSpaceBytes += DateraUtil.gibToBytes(appInstance.getSize());\n                        }\n                    } catch (DateraObject.DateraError dateraError) {\n                        String errMesg = \"Error getting used bytes for storage pool : \" + storagePool.getId();\n                        s_logger.warn(errMesg, dateraError);\n                        throw new CloudRuntimeException(errMesg);\n                    }\n                }\n            }\n        }\n\n        List<SnapshotVO> lstSnapshots = _snapshotDao.listAll();\n\n        if (lstSnapshots != null) {\n            for (SnapshotVO snapshot : lstSnapshots) {\n                SnapshotDetailsVO snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(),\n                        DateraUtil.STORAGE_POOL_ID);\n\n                \r\n                if (snapshotDetails != null && snapshotDetails.getValue() != null\n                        && Long.parseLong(snapshotDetails.getValue()) == storagePool.getId()) {\n                    snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(), DateraUtil.VOLUME_SIZE);\n\n                    if (snapshotDetails != null && snapshotDetails.getValue() != null) {\n                        long snapshotSize = Long.parseLong(snapshotDetails.getValue());\n\n                        usedSpaceBytes += snapshotSize;\n                    }\n                }\n            }\n        }\n\n        List<VMTemplateStoragePoolVO> lstTemplatePoolRefs = tmpltPoolDao.listByPoolId(storagePool.getId());\n\n        if (lstTemplatePoolRefs != null) {\n            for (VMTemplateStoragePoolVO templatePoolRef : lstTemplatePoolRefs) {\n                usedSpaceBytes += templatePoolRef.getTemplateSize();\n            }\n        }\n        s_logger.debug(\"usedSpaceBytes: \" + String.valueOf(usedSpaceBytes));\n\n        return usedSpaceBytes;\n    }\n","date":"2019-07-25 16:43:04","endLine":622,"groupId":"15170","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getUsedBytes","params":"(StoragePoolstoragePool@longvolumeIdToIgnore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cloudstack-10-0.7/blobInfo/CC_OUT/blobs/9a/9a165a80b53ed1d6103e6cc28e6ec1b322c59f.src","preCode":"    private long getUsedBytes(StoragePool storagePool, long volumeIdToIgnore) {\n        long usedSpaceBytes = 0;\n\n        List<VolumeVO> lstVolumes = _volumeDao.findByPoolId(storagePool.getId(), null);\n\n        if (lstVolumes != null) {\n            for (VolumeVO volume : lstVolumes) {\n                if (volume.getId() == volumeIdToIgnore) {\n                    continue;\n                }\n\n                VolumeDetailVO volumeDetail = volumeDetailsDao.findDetail(volume.getId(), DateraUtil.VOLUME_SIZE);\n\n                if (volumeDetail != null && volumeDetail.getValue() != null) {\n                    long volumeSizeGib = Long.parseLong(volumeDetail.getValue());\n                    long volumeSizeBytes = DateraUtil.gibToBytes((int) (volumeSizeGib));\n                    usedSpaceBytes += volumeSizeBytes;\n                } else {\n                    DateraObject.DateraConnection conn = DateraUtil.getDateraConnection(storagePool.getId(),\n                            _storagePoolDetailsDao);\n                    try {\n\n                        String appInstanceName = getAppInstanceName(volumeDataFactory.getVolume(volume.getId()));\n                        DateraObject.AppInstance appInstance = DateraUtil.getAppInstance(conn, appInstanceName);\n                        if (appInstance != null) {\n                            usedSpaceBytes += DateraUtil.gibToBytes(appInstance.getSize());\n                        }\n                    } catch (DateraObject.DateraError dateraError) {\n                        String errMesg = \"Error getting used bytes for storage pool : \" + storagePool.getId();\n                        s_logger.warn(errMesg, dateraError);\n                        throw new CloudRuntimeException(errMesg);\n                    }\n                }\n            }\n        }\n\n        List<SnapshotVO> lstSnapshots = _snapshotDao.listAll();\n\n        if (lstSnapshots != null) {\n            for (SnapshotVO snapshot : lstSnapshots) {\n                SnapshotDetailsVO snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(),\n                        DateraUtil.STORAGE_POOL_ID);\n\n                \r\n                if (snapshotDetails != null && snapshotDetails.getValue() != null\n                        && Long.parseLong(snapshotDetails.getValue()) == storagePool.getId()) {\n                    snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(), DateraUtil.VOLUME_SIZE);\n\n                    if (snapshotDetails != null && snapshotDetails.getValue() != null) {\n                        long snapshotSize = Long.parseLong(snapshotDetails.getValue());\n\n                        usedSpaceBytes += snapshotSize;\n                    }\n                }\n            }\n        }\n\n        List<VMTemplateStoragePoolVO> lstTemplatePoolRefs = tmpltPoolDao.listByPoolId(storagePool.getId());\n\n        if (lstTemplatePoolRefs != null) {\n            for (VMTemplateStoragePoolVO templatePoolRef : lstTemplatePoolRefs) {\n                usedSpaceBytes += templatePoolRef.getTemplateSize();\n            }\n        }\n        s_logger.debug(\"usedSpaceBytes: \" + String.valueOf(usedSpaceBytes));\n\n        return usedSpaceBytes;\n    }\n","realPath":"plugins/storage/volume/datera/src/main/java/org/apache/cloudstack/storage/datastore/driver/DateraPrimaryDataStoreDriver.java","repoName":"cloudstack","snippetEndLine":0,"snippetStartLine":0,"startLine":555,"status":"B"}],"commitId":"e3d70b7dcc1a319fac7bb30d6e8e5e79e236ad67","commitMessage":"@@@storage: Datera storage plugin (#3470)\n\nFeatures:\n\nZone-wide and cluster-wide primary storage support\nVM template caching automatically on Datera.  the subsequent VMs can be created instantaneously by fast cloning the root volume.\nRapid storage-native snapshot\nMultiple managed primary storages can be created with a single Datera cluster to provide better management of\nTotal provisioned capacity\nDefault storage QoS values\nReplica size ( 1 to 5 )\nIP pool assignment for iSCSI target\nVolume Placement ( hybrid.  single_flash.  all_flash )\nVolume snapshot to VM template\nVolume to VM template\nVolume size increase using service policy\nVolume QoS change using service policy\nEnabled KVM support\nNew Datera app_instance name format to include ACS volume name\nVM live migration","date":"2019-07-25 16:43:04","modifiedFileCount":"0","status":"B","submitter":"manojkverma"},{"authorTime":"2020-08-13 18:25:16","codes":[{"authorDate":"2019-07-25 16:43:04","commitOrder":2,"curCode":"    public boolean deleteDataStore(DataStore store) {\n        List<SnapshotVO> lstSnapshots = _snapshotDao.listAll();\n\n        if (lstSnapshots != null) {\n            for (SnapshotVO snapshot : lstSnapshots) {\n                SnapshotDetailsVO snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(),\n                        DateraUtil.STORAGE_POOL_ID);\n\n                \r\n                if (snapshotDetails != null && snapshotDetails.getValue() != null\n                        && Long.parseLong(snapshotDetails.getValue()) == store.getId()) {\n                    throw new CloudRuntimeException(\n                            \"This primary storage cannot be deleted because it currently contains one or more snapshots.\");\n                }\n            }\n        }\n\n        return dataStoreHelper.deletePrimaryDataStore(store);\n    }\n","date":"2019-07-25 16:43:04","endLine":350,"groupId":"104261","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"deleteDataStore","params":"(DataStorestore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cloudstack-10-0.7/blobInfo/CC_OUT/blobs/ff/253fc8d181062988ace210566305a93d847113.src","preCode":"    public boolean deleteDataStore(DataStore store) {\n        List<SnapshotVO> lstSnapshots = _snapshotDao.listAll();\n\n        if (lstSnapshots != null) {\n            for (SnapshotVO snapshot : lstSnapshots) {\n                SnapshotDetailsVO snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(),\n                        DateraUtil.STORAGE_POOL_ID);\n\n                \r\n                if (snapshotDetails != null && snapshotDetails.getValue() != null\n                        && Long.parseLong(snapshotDetails.getValue()) == store.getId()) {\n                    throw new CloudRuntimeException(\n                            \"This primary storage cannot be deleted because it currently contains one or more snapshots.\");\n                }\n            }\n        }\n\n        return dataStoreHelper.deletePrimaryDataStore(store);\n    }\n","realPath":"plugins/storage/volume/datera/src/main/java/org/apache/cloudstack/storage/datastore/lifecycle/DateraPrimaryDataStoreLifeCycle.java","repoName":"cloudstack","snippetEndLine":0,"snippetStartLine":0,"startLine":332,"status":"N"},{"authorDate":"2020-08-13 18:25:16","commitOrder":2,"curCode":"    private long getUsedBytes(StoragePool storagePool, long volumeIdToIgnore) {\n        long usedSpaceBytes = 0;\n\n        List<VolumeVO> lstVolumes = _volumeDao.findByPoolId(storagePool.getId(), null);\n\n        if (lstVolumes != null) {\n            for (VolumeVO volume : lstVolumes) {\n                if (volume.getId() == volumeIdToIgnore) {\n                    continue;\n                }\n\n                VolumeDetailVO volumeDetail = volumeDetailsDao.findDetail(volume.getId(), DateraUtil.VOLUME_SIZE);\n\n                if (volumeDetail != null && volumeDetail.getValue() != null) {\n                    long volumeSizeGib = Long.parseLong(volumeDetail.getValue());\n                    long volumeSizeBytes = DateraUtil.gibToBytes((int) (volumeSizeGib));\n                    usedSpaceBytes += volumeSizeBytes;\n                } else {\n                    DateraObject.DateraConnection conn = DateraUtil.getDateraConnection(storagePool.getId(),\n                            _storagePoolDetailsDao);\n                    try {\n\n                        String appInstanceName = getAppInstanceName(volumeDataFactory.getVolume(volume.getId()));\n                        DateraObject.AppInstance appInstance = DateraUtil.getAppInstance(conn, appInstanceName);\n                        if (appInstance != null) {\n                            usedSpaceBytes += DateraUtil.gibToBytes(appInstance.getSize());\n                        }\n                    } catch (DateraObject.DateraError dateraError) {\n                        String errMesg = \"Error getting used bytes for storage pool : \" + storagePool.getId();\n                        s_logger.warn(errMesg, dateraError);\n                        throw new CloudRuntimeException(errMesg);\n                    }\n                }\n            }\n        }\n\n        List<SnapshotVO> lstSnapshots = _snapshotDao.listAll();\n\n        if (lstSnapshots != null) {\n            for (SnapshotVO snapshot : lstSnapshots) {\n                SnapshotDetailsVO snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(),\n                        DateraUtil.STORAGE_POOL_ID);\n\n                \r\n                if (snapshotDetails != null && snapshotDetails.getValue() != null\n                        && Long.parseLong(snapshotDetails.getValue()) == storagePool.getId()) {\n                    snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(), DateraUtil.VOLUME_SIZE);\n\n                    if (snapshotDetails != null && snapshotDetails.getValue() != null) {\n                        long snapshotSize = Long.parseLong(snapshotDetails.getValue());\n\n                        usedSpaceBytes += snapshotSize;\n                    }\n                }\n            }\n        }\n\n        List<VMTemplateStoragePoolVO> lstTemplatePoolRefs = tmpltPoolDao.listByPoolId(storagePool.getId());\n\n        if (lstTemplatePoolRefs != null) {\n            for (VMTemplateStoragePoolVO templatePoolRef : lstTemplatePoolRefs) {\n                usedSpaceBytes += templatePoolRef.getTemplateSize();\n            }\n        }\n        s_logger.debug(\"usedSpaceBytes: \" + toHumanReadableSize(usedSpaceBytes));\n\n        return usedSpaceBytes;\n    }\n","date":"2020-08-13 18:25:16","endLine":624,"groupId":"104261","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getUsedBytes","params":"(StoragePoolstoragePool@longvolumeIdToIgnore)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-cloudstack-10-0.7/blobInfo/CC_OUT/blobs/49/7960d1c2329d8c02ae65b35c22ab3920e58932.src","preCode":"    private long getUsedBytes(StoragePool storagePool, long volumeIdToIgnore) {\n        long usedSpaceBytes = 0;\n\n        List<VolumeVO> lstVolumes = _volumeDao.findByPoolId(storagePool.getId(), null);\n\n        if (lstVolumes != null) {\n            for (VolumeVO volume : lstVolumes) {\n                if (volume.getId() == volumeIdToIgnore) {\n                    continue;\n                }\n\n                VolumeDetailVO volumeDetail = volumeDetailsDao.findDetail(volume.getId(), DateraUtil.VOLUME_SIZE);\n\n                if (volumeDetail != null && volumeDetail.getValue() != null) {\n                    long volumeSizeGib = Long.parseLong(volumeDetail.getValue());\n                    long volumeSizeBytes = DateraUtil.gibToBytes((int) (volumeSizeGib));\n                    usedSpaceBytes += volumeSizeBytes;\n                } else {\n                    DateraObject.DateraConnection conn = DateraUtil.getDateraConnection(storagePool.getId(),\n                            _storagePoolDetailsDao);\n                    try {\n\n                        String appInstanceName = getAppInstanceName(volumeDataFactory.getVolume(volume.getId()));\n                        DateraObject.AppInstance appInstance = DateraUtil.getAppInstance(conn, appInstanceName);\n                        if (appInstance != null) {\n                            usedSpaceBytes += DateraUtil.gibToBytes(appInstance.getSize());\n                        }\n                    } catch (DateraObject.DateraError dateraError) {\n                        String errMesg = \"Error getting used bytes for storage pool : \" + storagePool.getId();\n                        s_logger.warn(errMesg, dateraError);\n                        throw new CloudRuntimeException(errMesg);\n                    }\n                }\n            }\n        }\n\n        List<SnapshotVO> lstSnapshots = _snapshotDao.listAll();\n\n        if (lstSnapshots != null) {\n            for (SnapshotVO snapshot : lstSnapshots) {\n                SnapshotDetailsVO snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(),\n                        DateraUtil.STORAGE_POOL_ID);\n\n                \r\n                if (snapshotDetails != null && snapshotDetails.getValue() != null\n                        && Long.parseLong(snapshotDetails.getValue()) == storagePool.getId()) {\n                    snapshotDetails = _snapshotDetailsDao.findDetail(snapshot.getId(), DateraUtil.VOLUME_SIZE);\n\n                    if (snapshotDetails != null && snapshotDetails.getValue() != null) {\n                        long snapshotSize = Long.parseLong(snapshotDetails.getValue());\n\n                        usedSpaceBytes += snapshotSize;\n                    }\n                }\n            }\n        }\n\n        List<VMTemplateStoragePoolVO> lstTemplatePoolRefs = tmpltPoolDao.listByPoolId(storagePool.getId());\n\n        if (lstTemplatePoolRefs != null) {\n            for (VMTemplateStoragePoolVO templatePoolRef : lstTemplatePoolRefs) {\n                usedSpaceBytes += templatePoolRef.getTemplateSize();\n            }\n        }\n        s_logger.debug(\"usedSpaceBytes: \" + String.valueOf(usedSpaceBytes));\n\n        return usedSpaceBytes;\n    }\n","realPath":"plugins/storage/volume/datera/src/main/java/org/apache/cloudstack/storage/datastore/driver/DateraPrimaryDataStoreDriver.java","repoName":"cloudstack","snippetEndLine":0,"snippetStartLine":0,"startLine":557,"status":"M"}],"commitId":"b586eb22f1b31f3cab2f2cb1aaeafca4f4646abd","commitMessage":"@@@Human readable sizes in logs (#4207)\n\nThis PR adds outputting human readable byte sizes in the management server logs.  agent logs.  and usage records. A non-dynamic global variable is added (display.human.readable.sizes) to control switching this feature on and off. This setting is sent to the agent on connection and is only read from the database when the management server is started up. The setting is kept in memory by the use of a static field on the NumbersUtil class and is available throughout the codebase.\n\nInstead of seeing things like:\n2020-07-23 15:31:58. 593 DEBUG [c.c.a.t.Request] (AgentManager-Handler-12:null) (logid:) Seq 8-1863645820801253428: Processing: { Ans: .  MgmtId: 52238089807.  via: 8.  Ver: v1.  Flags: 10.  [{\"com.cloud.agent.api.NetworkUsageAnswer\":{\"routerName\":\"r-224-VM\". \"bytesSent\":\"106496\". \"bytesReceived\":\"0\". \"result\":\"true\". \"details\":\"\". \"wait\":\"0\". }}] }\n\nThe KB MB and GB values will be printed out:\n\n2020-07-23 15:31:58. 593 DEBUG [c.c.a.t.Request] (AgentManager-Handler-12:null) (logid:) Seq 8-1863645820801253428: Processing: { Ans: .  MgmtId: 52238089807.  via: 8.  Ver: v1.  Flags: 10.  [{\"com.cloud.agent.api.NetworkUsageAnswer\":{\"routerName\":\"r-224-VM\". \"bytesSent\":\"(104.00 KB) 106496\". \"bytesReceived\":\"(0 bytes) 0\". \"result\":\"true\". \"details\":\"\". \"wait\":\"0\". }}] }\n\nFS: https://cwiki.apache.org/confluence/display/CLOUDSTACK/Human+Readable+Byte+sizes","date":"2020-08-13 18:25:16","modifiedFileCount":"55","status":"M","submitter":"Spaceman1984"}]
