[{"authorTime":"2019-01-19 05:32:22","codes":[{"authorDate":"2019-01-19 05:32:22","commitOrder":2,"curCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\tassumeTrue(\n\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(id);\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","date":"2019-01-26 00:56:42","endLine":176,"groupId":"38875","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testKillYarnSessionClusterEntrypoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/de/7e02aaa409c95cb0a5c5d40375d4c4d5113411.src","preCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\tassumeTrue(\n\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(id);\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":153,"status":"MB"},{"authorDate":"2019-01-19 05:32:22","commitOrder":2,"curCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tstopTaskManagerContainer();\n\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","date":"2019-01-26 00:56:42","endLine":195,"groupId":"36588","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testJobRecoversAfterKillingTaskManager","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/de/7e02aaa409c95cb0a5c5d40375d4c4d5113411.src","preCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tstopTaskManagerContainer();\n\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":179,"status":"B"}],"commitId":"c95e9f642288bb2816cf84868709ea2543a90ae5","commitMessage":"@@@[FLINK-11390][tests] Port testTaskManagerFailure to new codebase.\n\nPort YARNSessionCapacitySchedulerITCase#testTaskManagerFailure to flip6 codebase:\n* Remove assertions that rely on log messages only\n* Move part where TMs are killed to YARNHighAvailabilityITCase\n* Rename test to a proper name that describes what it does\n* Add Javadoc explaning what this test does\n\n[FLINK-11390][tests] Move comment to right position\n\n[FLINK-11390][tests] Reuse YarnClient from super class\n\nMove waitUntilCondition to YarnTestBase\n\n[FLINK-11390][tests] Extract method parse hostname\n\nExtract method getOnlyApplicationReport\n\nExtract method submitJob\n\nExtract method getNumberOfSlotsPerTaskManager\n\nExtract method getFlinkConfigFromRestApi\n\nDelete useless comment\n\nRename: runner -> yarnSessionClusterRunner\n\nDelete useless sleep & refactor\n\nReorder methods and add static keyword where possible\n\nThis closes #7546.\n","date":"2019-01-26 00:56:42","modifiedFileCount":"7","status":"M","submitter":"Gary Yao"},{"authorTime":"2019-01-24 19:05:29","codes":[{"authorDate":"2019-01-24 19:05:29","commitOrder":3,"curCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\tassumeTrue(\n\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(id);\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","date":"2019-01-29 22:44:56","endLine":179,"groupId":"38875","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testKillYarnSessionClusterEntrypoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/9d/0ba46b64000f6ec7d36cb95bf1056ce49fab7f.src","preCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\tassumeTrue(\n\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(id);\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":154,"status":"M"},{"authorDate":"2019-01-24 19:05:29","commitOrder":3,"curCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tstopTaskManagerContainer();\n\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","date":"2019-01-29 22:44:56","endLine":200,"groupId":"36588","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testJobRecoversAfterKillingTaskManager","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/9d/0ba46b64000f6ec7d36cb95bf1056ce49fab7f.src","preCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tstopTaskManagerContainer();\n\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":182,"status":"M"}],"commitId":"0d7af4eeb44fbc988e24a7fbe7e4059e165d5098","commitMessage":"@@@[FLINK-11270][build] Do not include hadoop in flink-dist by default\n","date":"2019-01-29 22:44:56","modifiedFileCount":"6","status":"M","submitter":"zentol"},{"authorTime":"2019-05-24 16:45:59","codes":[{"authorDate":"2019-05-24 16:45:59","commitOrder":4,"curCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\trunTest(() -> {\n\t\t\tassumeTrue(\n\t\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(id);\n\t\t\t} finally {\n\t\t\t\trestClusterClient.shutdown();\n\t\t\t}\n\t\t});\n\t}\n","date":"2019-06-06 16:08:28","endLine":182,"groupId":"38875","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testKillYarnSessionClusterEntrypoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/8b/22b25bbedfb7a9657001fb41f2c2db009f7d16.src","preCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\tassumeTrue(\n\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(id);\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":155,"status":"M"},{"authorDate":"2019-05-24 16:45:59","commitOrder":4,"curCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\trunTest(() -> {\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tstopTaskManagerContainer();\n\t\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t\t} finally {\n\t\t\t\trestClusterClient.shutdown();\n\t\t\t}\n\t\t});\n\t}\n","date":"2019-06-06 16:08:28","endLine":205,"groupId":"36588","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testJobRecoversAfterKillingTaskManager","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/8b/22b25bbedfb7a9657001fb41f2c2db009f7d16.src","preCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\ttry {\n\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\tstopTaskManagerContainer();\n\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t} finally {\n\t\t\trestClusterClient.shutdown();\n\t\t}\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":185,"status":"M"}],"commitId":"350846507450ba7afa0159a2c574bd2f44bacaac","commitMessage":"@@@[FLINK-12614][yarn] Refactor test to not do assertions in @After methods\n","date":"2019-06-06 16:08:28","modifiedFileCount":"7","status":"M","submitter":"Chesnay Schepler"},{"authorTime":"2019-09-04 19:56:44","codes":[{"authorDate":"2019-09-04 19:56:44","commitOrder":5,"curCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\trunTest(() -> {\n\t\t\tassumeTrue(\n\t\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(id);\n\t\t\t} finally {\n\t\t\t\trestClusterClient.close();\n\t\t\t}\n\t\t});\n\t}\n","date":"2019-09-06 21:27:52","endLine":182,"groupId":"38875","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testKillYarnSessionClusterEntrypoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/8c/be8c2dccc984157042934d2a11109e038d61eb.src","preCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\trunTest(() -> {\n\t\t\tassumeTrue(\n\t\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(id);\n\t\t\t} finally {\n\t\t\t\trestClusterClient.shutdown();\n\t\t\t}\n\t\t});\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":155,"status":"M"},{"authorDate":"2019-09-04 19:56:44","commitOrder":5,"curCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\trunTest(() -> {\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tstopTaskManagerContainer();\n\t\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t\t} finally {\n\t\t\t\trestClusterClient.close();\n\t\t\t}\n\t\t});\n\t}\n","date":"2019-09-06 21:27:52","endLine":205,"groupId":"36588","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testJobRecoversAfterKillingTaskManager","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/8c/be8c2dccc984157042934d2a11109e038d61eb.src","preCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\trunTest(() -> {\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tstopTaskManagerContainer();\n\t\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t\t} finally {\n\t\t\t\trestClusterClient.shutdown();\n\t\t\t}\n\t\t});\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":185,"status":"M"}],"commitId":"e8650cd402084576338255048d110a70ed3f67be","commitMessage":"@@@[FLINK-13946] Make the ClusterClient autocloseable\n","date":"2019-09-06 21:27:52","modifiedFileCount":"17","status":"M","submitter":"Kostas Kloudas"},{"authorTime":"2020-05-04 16:15:41","codes":[{"authorDate":"2020-05-04 16:15:41","commitOrder":6,"curCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\trunTest(() -> {\n\t\t\tassumeTrue(\n\t\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(id);\n\t\t\t} finally {\n\t\t\t\trestClusterClient.close();\n\t\t\t}\n\t\t});\n\t}\n","date":"2020-05-13 22:27:18","endLine":180,"groupId":"101679","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testKillYarnSessionClusterEntrypoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b3/a92699e7abcb6ee58c842e546cf3dc77cf2df0.src","preCode":"\tpublic void testKillYarnSessionClusterEntrypoint() throws Exception {\n\t\trunTest(() -> {\n\t\t\tassumeTrue(\n\t\t\t\t\"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n\t\t\t\tOperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris());\n\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\tfinal ApplicationId id = restClusterClient.getClusterId();\n\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n\t\t\t\twaitForApplicationAttempt(id, 2);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(id);\n\t\t\t} finally {\n\t\t\t\trestClusterClient.close();\n\t\t\t}\n\t\t});\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":155,"status":"M"},{"authorDate":"2020-05-04 16:15:41","commitOrder":6,"curCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\trunTest(() -> {\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tstopTaskManagerContainer();\n\t\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t\t} finally {\n\t\t\t\trestClusterClient.close();\n\t\t\t}\n\t\t});\n\t}\n","date":"2020-05-13 22:27:18","endLine":201,"groupId":"101679","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testJobRecoversAfterKillingTaskManager","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b3/a92699e7abcb6ee58c842e546cf3dc77cf2df0.src","preCode":"\tpublic void testJobRecoversAfterKillingTaskManager() throws Exception {\n\t\trunTest(() -> {\n\t\t\tfinal YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor();\n\t\t\tyarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles()));\n\n\t\t\tfinal RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor);\n\t\t\ttry {\n\t\t\t\tfinal JobID jobId = submitJob(restClusterClient);\n\t\t\t\twaitUntilJobIsRunning(restClusterClient, jobId);\n\n\t\t\t\tstopTaskManagerContainer();\n\t\t\t\twaitUntilJobIsRestarted(restClusterClient, jobId, 1);\n\n\t\t\t\twaitForJobTermination(restClusterClient, jobId);\n\n\t\t\t\tkillApplicationAndWait(restClusterClient.getClusterId());\n\t\t\t} finally {\n\t\t\t\trestClusterClient.close();\n\t\t\t}\n\t\t});\n\t}\n","realPath":"flink-yarn-tests/src/test/java/org/apache/flink/yarn/YARNHighAvailabilityITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":183,"status":"M"}],"commitId":"082061da5ec52c7d4257adc272869c1ecb7fa222","commitMessage":"@@@[FLINK-11086][yarn] Use YARN_APPLICATION_CLASSPATH instead of flink-shaded-hadoop fat jar in tests\n","date":"2020-05-13 22:27:18","modifiedFileCount":"8","status":"M","submitter":"Robert Metzger"}]
