[{"authorTime":"2020-05-15 23:07:58","codes":[{"authorDate":"2020-05-16 16:17:05","commitOrder":2,"curCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", AvroFormatFactory.IDENTIFIER);\n\t\treturn options;\n\t}\n","date":"2020-05-17 21:33:39","endLine":105,"groupId":"26310","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getAllOptions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d1/c1156c23cca723e99a5e68e843670f8842ecb4.src","preCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", AvroFormatFactory.IDENTIFIER);\n\t\treturn options;\n\t}\n","realPath":"flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroFormatFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"B"},{"authorDate":"2020-05-15 23:07:58","commitOrder":2,"curCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", \"canal-json\");\n\t\toptions.put(\"canal-json.ignore-parse-errors\", \"true\");\n\t\treturn options;\n\t}\n","date":"2020-05-15 23:07:58","endLine":124,"groupId":"26310","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getAllOptions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b5/ebfc0ff79f27e42fefe3f12f5c7fdd5304d1fc.src","preCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", \"canal-json\");\n\t\toptions.put(\"canal-json.ignore-parse-errors\", \"true\");\n\t\treturn options;\n\t}\n","realPath":"flink-formats/flink-json/src/test/java/org/apache/flink/formats/json/canal/CanalJsonFormatFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":115,"status":"NB"}],"commitId":"e2f2fd1aa9b25f4818886afd2263a8d1e7549e34","commitMessage":"@@@[FLINK-17757][avro] Implement format factory for Avro serialization and deserialization schema of RowData type\n\nThis closes #12190\n","date":"2020-05-17 21:33:39","modifiedFileCount":"0","status":"M","submitter":"yuzhao.cyz"},{"authorTime":"2020-06-17 21:32:10","codes":[{"authorDate":"2020-05-16 16:17:05","commitOrder":3,"curCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", AvroFormatFactory.IDENTIFIER);\n\t\treturn options;\n\t}\n","date":"2020-05-17 21:33:39","endLine":105,"groupId":"26310","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getAllOptions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d1/c1156c23cca723e99a5e68e843670f8842ecb4.src","preCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", AvroFormatFactory.IDENTIFIER);\n\t\treturn options;\n\t}\n","realPath":"flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroFormatFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"N"},{"authorDate":"2020-06-17 21:32:10","commitOrder":3,"curCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", \"canal-json\");\n\t\toptions.put(\"canal-json.ignore-parse-errors\", \"true\");\n\t\toptions.put(\"canal-json.timestamp-format.standard\", \"ISO-8601\");\n\t\treturn options;\n\t}\n","date":"2020-06-17 21:47:28","endLine":127,"groupId":"26310","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getAllOptions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/44/86a498bee362ec53c89b86251fd0cb097269dd.src","preCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", \"canal-json\");\n\t\toptions.put(\"canal-json.ignore-parse-errors\", \"true\");\n\t\treturn options;\n\t}\n","realPath":"flink-formats/flink-json/src/test/java/org/apache/flink/formats/json/canal/CanalJsonFormatFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":117,"status":"M"}],"commitId":"c42a2f9cd6fcf50ff79f030f9b7c7bbe30d64a0f","commitMessage":"@@@[FLINK-18299][json] Fix the non SQL standard timestamp format in JSON format\n\n\nThe current timestamp format in JSON format is not SQL standard which uses RFC-3339. This commit changes the default behavior to parse/generate timestamp using SQL standard. Besides.  it introduces an option \"json.timestamp-format.standard\" to have the ability to fallback to ISO standard. \n\nThis closes #12661","date":"2020-06-17 21:47:28","modifiedFileCount":"19","status":"M","submitter":"Shengkai"},{"authorTime":"2020-09-18 15:52:20","codes":[{"authorDate":"2020-05-16 16:17:05","commitOrder":4,"curCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", AvroFormatFactory.IDENTIFIER);\n\t\treturn options;\n\t}\n","date":"2020-05-17 21:33:39","endLine":105,"groupId":"102114","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getAllOptions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d1/c1156c23cca723e99a5e68e843670f8842ecb4.src","preCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", AvroFormatFactory.IDENTIFIER);\n\t\treturn options;\n\t}\n","realPath":"flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroFormatFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":97,"status":"N"},{"authorDate":"2020-09-18 15:52:20","commitOrder":4,"curCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\t\toptions.put(\"format\", \"canal-json\");\n\t\treturn options;\n\t}\n","date":"2020-09-18 15:52:20","endLine":149,"groupId":"102114","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getAllOptions","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/47/67c99f2c66cec208009eae99c43c1a30e0c9f5.src","preCode":"\tprivate Map<String, String> getAllOptions() {\n\t\tfinal Map<String, String> options = new HashMap<>();\n\t\toptions.put(\"connector\", TestDynamicTableFactory.IDENTIFIER);\n\t\toptions.put(\"target\", \"MyTarget\");\n\t\toptions.put(\"buffer-size\", \"1000\");\n\n\t\toptions.put(\"format\", \"canal-json\");\n\t\toptions.put(\"canal-json.ignore-parse-errors\", \"true\");\n\t\toptions.put(\"canal-json.timestamp-format.standard\", \"ISO-8601\");\n\t\treturn options;\n\t}\n","realPath":"flink-formats/flink-json/src/test/java/org/apache/flink/formats/json/canal/CanalJsonFormatFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":142,"status":"M"}],"commitId":"a3b4c93f82bb04d7313bd0ab34e584061cf22974","commitMessage":"@@@[FLINK-19002][canal][json] Support to only read changelogs of specific database and table for canal-json format\n\nThis closes  (#13294)","date":"2020-09-18 15:52:20","modifiedFileCount":"4","status":"M","submitter":"Jark Wu"}]
