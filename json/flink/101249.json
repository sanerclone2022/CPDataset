[{"authorTime":"2017-04-29 01:40:20","codes":[{"authorDate":"2017-04-29 01:40:20","commitOrder":1,"curCode":"\tprivate String migrateJob() throws Throwable {\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToMigrate, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobToMigrate.getJobID());\n\t\tAwait.result(jobManager.ask(msg, timeout), timeout);\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tmsg = new JobManagerMessages.CancelJobWithSavepoint(jobToMigrate.getJobID(), targetDirectory.getAbsolutePath());\n\t\tFuture<Object> future = jobManager.ask(msg, timeout);\n\t\tresult = Await.result(future, timeout);\n\n\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\tJobManagerMessages.CancellationFailure failure = (JobManagerMessages.CancellationFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\n\t\tString savepointPath = ((JobManagerMessages.CancellationSuccess) result).savepointPath();\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.NotifyWhenJobStatus(jobToMigrate.getJobID(), JobStatus.CANCELED);\n\t\tAwait.ready(jobManager.ask(msg, timeout), timeout);\n\n\t\treturn savepointPath;\n\t}\n","date":"2017-04-29 02:11:35","endLine":195,"groupId":"989","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/ecf499417bdefc8e3828a92212afb010eb5798.src","preCode":"\tprivate String migrateJob() throws Throwable {\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToMigrate, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobToMigrate.getJobID());\n\t\tAwait.result(jobManager.ask(msg, timeout), timeout);\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tmsg = new JobManagerMessages.CancelJobWithSavepoint(jobToMigrate.getJobID(), targetDirectory.getAbsolutePath());\n\t\tFuture<Object> future = jobManager.ask(msg, timeout);\n\t\tresult = Await.result(future, timeout);\n\n\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\tJobManagerMessages.CancellationFailure failure = (JobManagerMessages.CancellationFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\n\t\tString savepointPath = ((JobManagerMessages.CancellationSuccess) result).savepointPath();\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.NotifyWhenJobStatus(jobToMigrate.getJobID(), JobStatus.CANCELED);\n\t\tAwait.ready(jobManager.ask(msg, timeout), timeout);\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":152,"status":"B"},{"authorDate":"2017-04-29 01:40:20","commitOrder":1,"curCode":"\tprivate void restoreJob(String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, true));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToRestore, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\tmsg = new JobManagerMessages.RequestJobStatus(jobToRestore.getJobID());\n\t\tJobStatus status = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\twhile (!status.isTerminalState()) {\n\t\t\tstatus = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\t}\n\n\t\tAssert.assertEquals(JobStatus.FINISHED, status);\n\t}\n","date":"2017-04-29 02:11:35","endLine":221,"groupId":"984","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/ecf499417bdefc8e3828a92212afb010eb5798.src","preCode":"\tprivate void restoreJob(String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, true));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToRestore, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\tmsg = new JobManagerMessages.RequestJobStatus(jobToRestore.getJobID());\n\t\tJobStatus status = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\twhile (!status.isTerminalState()) {\n\t\t\tstatus = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\t}\n\n\t\tAssert.assertEquals(JobStatus.FINISHED, status);\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"B"}],"commitId":"f7980a7e29457753eb3c5b975f3bb4b59d2014f8","commitMessage":"@@@[Flink-5892] Restore state on operator level\n","date":"2017-04-29 02:11:35","modifiedFileCount":"39","status":"B","submitter":"zentol"},{"authorTime":"2017-04-29 01:40:20","codes":[{"authorDate":"2017-06-15 14:54:42","commitOrder":2,"curCode":"\tprivate String migrateJob() throws Throwable {\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToMigrate, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobToMigrate.getJobID());\n\t\tAwait.result(jobManager.ask(msg, timeout), timeout);\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tmsg = new JobManagerMessages.CancelJobWithSavepoint(jobToMigrate.getJobID(), targetDirectory.getAbsolutePath());\n\n\t\t\r\n\t\t\r\n\t\tboolean retry = true;\n\t\tfor (int i = 0; retry && i < 10; i++) {\n\t\t\tFuture<Object> future = jobManager.ask(msg, timeout);\n\t\t\tresult = Await.result(future, timeout);\n\n\t\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\t\tThread.sleep(50L);\n\t\t\t} else {\n\t\t\t\tretry = false;\n\t\t\t}\n\t\t}\n\n\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\tJobManagerMessages.CancellationFailure failure = (JobManagerMessages.CancellationFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\n\t\tString savepointPath = ((JobManagerMessages.CancellationSuccess) result).savepointPath();\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.NotifyWhenJobStatus(jobToMigrate.getJobID(), JobStatus.CANCELED);\n\t\tAwait.ready(jobManager.ask(msg, timeout), timeout);\n\n\t\treturn savepointPath;\n\t}\n","date":"2017-06-21 11:33:13","endLine":224,"groupId":"989","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b6/dfb026b2b64b6227a21204779e20a70464ae14.src","preCode":"\tprivate String migrateJob() throws Throwable {\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToMigrate, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobToMigrate.getJobID());\n\t\tAwait.result(jobManager.ask(msg, timeout), timeout);\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tmsg = new JobManagerMessages.CancelJobWithSavepoint(jobToMigrate.getJobID(), targetDirectory.getAbsolutePath());\n\t\tFuture<Object> future = jobManager.ask(msg, timeout);\n\t\tresult = Await.result(future, timeout);\n\n\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\tJobManagerMessages.CancellationFailure failure = (JobManagerMessages.CancellationFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\n\t\tString savepointPath = ((JobManagerMessages.CancellationSuccess) result).savepointPath();\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.NotifyWhenJobStatus(jobToMigrate.getJobID(), JobStatus.CANCELED);\n\t\tAwait.ready(jobManager.ask(msg, timeout), timeout);\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":169,"status":"M"},{"authorDate":"2017-04-29 01:40:20","commitOrder":2,"curCode":"\tprivate void restoreJob(String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, true));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToRestore, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\tmsg = new JobManagerMessages.RequestJobStatus(jobToRestore.getJobID());\n\t\tJobStatus status = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\twhile (!status.isTerminalState()) {\n\t\t\tstatus = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\t}\n\n\t\tAssert.assertEquals(JobStatus.FINISHED, status);\n\t}\n","date":"2017-04-29 02:11:35","endLine":221,"groupId":"984","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/ecf499417bdefc8e3828a92212afb010eb5798.src","preCode":"\tprivate void restoreJob(String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, true));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToRestore, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\tmsg = new JobManagerMessages.RequestJobStatus(jobToRestore.getJobID());\n\t\tJobStatus status = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\twhile (!status.isTerminalState()) {\n\t\t\tstatus = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\t}\n\n\t\tAssert.assertEquals(JobStatus.FINISHED, status);\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":197,"status":"N"}],"commitId":"47862afbef98faee61e07ca4a00f41f34a764cf5","commitMessage":"@@@[FLINK-6918] [tests] Harden AbstractOperatorRestoreTestBase by retrying CancelWithSavepoint messages\n\nThe problem is that a StreamTask can be in state RUNNING without internally being running.\nAs a consequence checkpoint message will be discarded. This problem will be solved once\nFLINK-4714 has been addressed. Until then.  we harden the test case by retrying the\nCancelWithSavepoint message.\n\nThis closes #4129.\n","date":"2017-06-21 11:33:13","modifiedFileCount":"1","status":"M","submitter":"Till Rohrmann"},{"authorTime":"2017-09-06 21:38:20","codes":[{"authorDate":"2017-06-15 14:54:42","commitOrder":3,"curCode":"\tprivate String migrateJob() throws Throwable {\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToMigrate, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobToMigrate.getJobID());\n\t\tAwait.result(jobManager.ask(msg, timeout), timeout);\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tmsg = new JobManagerMessages.CancelJobWithSavepoint(jobToMigrate.getJobID(), targetDirectory.getAbsolutePath());\n\n\t\t\r\n\t\t\r\n\t\tboolean retry = true;\n\t\tfor (int i = 0; retry && i < 10; i++) {\n\t\t\tFuture<Object> future = jobManager.ask(msg, timeout);\n\t\t\tresult = Await.result(future, timeout);\n\n\t\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\t\tThread.sleep(50L);\n\t\t\t} else {\n\t\t\t\tretry = false;\n\t\t\t}\n\t\t}\n\n\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\tJobManagerMessages.CancellationFailure failure = (JobManagerMessages.CancellationFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\n\t\tString savepointPath = ((JobManagerMessages.CancellationSuccess) result).savepointPath();\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.NotifyWhenJobStatus(jobToMigrate.getJobID(), JobStatus.CANCELED);\n\t\tAwait.ready(jobManager.ask(msg, timeout), timeout);\n\n\t\treturn savepointPath;\n\t}\n","date":"2017-06-21 11:33:13","endLine":224,"groupId":"989","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b6/dfb026b2b64b6227a21204779e20a70464ae14.src","preCode":"\tprivate String migrateJob() throws Throwable {\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToMigrate, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobToMigrate.getJobID());\n\t\tAwait.result(jobManager.ask(msg, timeout), timeout);\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tmsg = new JobManagerMessages.CancelJobWithSavepoint(jobToMigrate.getJobID(), targetDirectory.getAbsolutePath());\n\n\t\t\r\n\t\t\r\n\t\tboolean retry = true;\n\t\tfor (int i = 0; retry && i < 10; i++) {\n\t\t\tFuture<Object> future = jobManager.ask(msg, timeout);\n\t\t\tresult = Await.result(future, timeout);\n\n\t\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\t\tThread.sleep(50L);\n\t\t\t} else {\n\t\t\t\tretry = false;\n\t\t\t}\n\t\t}\n\n\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\tJobManagerMessages.CancellationFailure failure = (JobManagerMessages.CancellationFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\n\t\tString savepointPath = ((JobManagerMessages.CancellationSuccess) result).savepointPath();\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.NotifyWhenJobStatus(jobToMigrate.getJobID(), JobStatus.CANCELED);\n\t\tAwait.ready(jobManager.ask(msg, timeout), timeout);\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":169,"status":"N"},{"authorDate":"2017-09-06 21:38:20","commitOrder":3,"curCode":"\tprivate void restoreJob(String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToRestore, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\tmsg = new JobManagerMessages.RequestJobStatus(jobToRestore.getJobID());\n\t\tJobStatus status = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\twhile (!status.isTerminalState()) {\n\t\t\tstatus = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\t}\n\n\t\tAssert.assertEquals(JobStatus.FINISHED, status);\n\t}\n","date":"2017-12-04 19:42:24","endLine":272,"groupId":"984","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c8/6f21fddc282958f7be94b47302f583aac416d7.src","preCode":"\tprivate void restoreJob(String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, true));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToRestore, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\tmsg = new JobManagerMessages.RequestJobStatus(jobToRestore.getJobID());\n\t\tJobStatus status = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\twhile (!status.isTerminalState()) {\n\t\t\tstatus = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\t}\n\n\t\tAssert.assertEquals(JobStatus.FINISHED, status);\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":248,"status":"M"}],"commitId":"80348d653b48e1b7d6a0b9275dbfa510eaea151f","commitMessage":"@@@[FLINK-7595] [Savepoints] Allow removing stateless operators\n\nThis closes #4651.\n","date":"2017-12-04 19:42:24","modifiedFileCount":"4","status":"M","submitter":"zentol"},{"authorTime":"2018-02-27 20:42:09","codes":[{"authorDate":"2018-02-27 20:42:09","commitOrder":4,"curCode":"\tprivate String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!(exceptionString.matches(\"(.*\\n)*.*savepoint for the job .* failed(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Not all required tasks are currently running(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Checkpoint was declined \\\\(tasks not ready\\\\)(.*\\n)*\"))) { \r\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","date":"2018-03-11 23:17:21","endLine":167,"groupId":"20189","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"(ClassLoaderclassLoader@ClusterClient<?>clusterClient@Deadlinedeadline)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/72/f700a82bcc4fa300b82fd973cfb66fd080aa4e.src","preCode":"\tprivate String migrateJob() throws Throwable {\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToMigrate, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobToMigrate.getJobID());\n\t\tAwait.result(jobManager.ask(msg, timeout), timeout);\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tmsg = new JobManagerMessages.CancelJobWithSavepoint(jobToMigrate.getJobID(), targetDirectory.getAbsolutePath());\n\n\t\t\r\n\t\t\r\n\t\tboolean retry = true;\n\t\tfor (int i = 0; retry && i < 10; i++) {\n\t\t\tFuture<Object> future = jobManager.ask(msg, timeout);\n\t\t\tresult = Await.result(future, timeout);\n\n\t\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\t\tThread.sleep(50L);\n\t\t\t} else {\n\t\t\t\tretry = false;\n\t\t\t}\n\t\t}\n\n\t\tif (result instanceof JobManagerMessages.CancellationFailure) {\n\t\t\tJobManagerMessages.CancellationFailure failure = (JobManagerMessages.CancellationFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\n\t\tString savepointPath = ((JobManagerMessages.CancellationSuccess) result).savepointPath();\n\n\t\t\r\n\t\tmsg = new TestingJobManagerMessages.NotifyWhenJobStatus(jobToMigrate.getJobID(), JobStatus.CANCELED);\n\t\tAwait.ready(jobManager.ask(msg, timeout), timeout);\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":110,"status":"M"},{"authorDate":"2018-02-27 20:42:09","commitOrder":4,"curCode":"\tprivate void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","date":"2018-03-11 23:17:21","endLine":186,"groupId":"52980","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(ClassLoaderclassLoader@ClusterClient<?>clusterClient@Deadlinedeadline@StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/72/f700a82bcc4fa300b82fd973cfb66fd080aa4e.src","preCode":"\tprivate void restoreJob(String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tObject msg;\n\t\tObject result;\n\n\t\t\r\n\t\tmsg = new JobManagerMessages.SubmitJob(jobToRestore, ListeningBehaviour.DETACHED);\n\t\tresult = Await.result(jobManager.ask(msg, timeout), timeout);\n\n\t\tif (result instanceof JobManagerMessages.JobResultFailure) {\n\t\t\tJobManagerMessages.JobResultFailure failure = (JobManagerMessages.JobResultFailure) result;\n\t\t\tthrow new Exception(failure.cause());\n\t\t}\n\t\tAssert.assertSame(JobManagerMessages.JobSubmitSuccess.class, result.getClass());\n\n\t\tmsg = new JobManagerMessages.RequestJobStatus(jobToRestore.getJobID());\n\t\tJobStatus status = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\twhile (!status.isTerminalState()) {\n\t\t\tstatus = ((JobManagerMessages.CurrentJobStatus) Await.result(jobManager.ask(msg, timeout), timeout)).status();\n\t\t}\n\n\t\tAssert.assertEquals(JobStatus.FINISHED, status);\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":169,"status":"M"}],"commitId":"6732669a684de0b230046b8f4291e367e35d9477","commitMessage":"@@@[FLINK-8797] Port AbstractOperatorRestoreTestBase to MiniClusterResource\n","date":"2018-03-11 23:17:21","modifiedFileCount":"1","status":"M","submitter":"Aljoscha Krettek"},{"authorTime":"2018-02-27 20:42:09","codes":[{"authorDate":"2018-11-08 22:51:16","commitOrder":5,"curCode":"\tprivate String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!(exceptionString.matches(\"(.*\\n)*.*savepoint for the job .* failed(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*was not running(.*\\n)*\")\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Not all required tasks are currently running(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Checkpoint was declined \\\\(tasks not ready\\\\)(.*\\n)*\"))) { \r\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","date":"2018-11-13 01:33:16","endLine":166,"groupId":"20189","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"(ClassLoaderclassLoader@ClusterClient<?>clusterClient@Deadlinedeadline)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/09/7616feb96630209d7e1d36bdd78a59478c7fa8.src","preCode":"\tprivate String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!(exceptionString.matches(\"(.*\\n)*.*savepoint for the job .* failed(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Not all required tasks are currently running(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Checkpoint was declined \\\\(tasks not ready\\\\)(.*\\n)*\"))) { \r\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":108,"status":"M"},{"authorDate":"2018-02-27 20:42:09","commitOrder":5,"curCode":"\tprivate void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","date":"2018-03-11 23:17:21","endLine":186,"groupId":"52980","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(ClassLoaderclassLoader@ClusterClient<?>clusterClient@Deadlinedeadline@StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/72/f700a82bcc4fa300b82fd973cfb66fd080aa4e.src","preCode":"\tprivate void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":169,"status":"N"}],"commitId":"dc8e27fb07ec8593037ce0205b5ecb4a5bc16a40","commitMessage":"@@@[FLINK-10753] Improve propagation and logging of snapshot exceptions\n\nThis closes #7064.\n","date":"2018-11-13 01:33:16","modifiedFileCount":"5","status":"M","submitter":"Stefan Richter"},{"authorTime":"2018-11-14 18:40:35","codes":[{"authorDate":"2018-11-14 18:40:35","commitOrder":6,"curCode":"\tprivate String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!(exceptionString.matches(\"(.*\\n)*.*savepoint for the job .* failed(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*was not running(.*\\n)*\")\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Not all required tasks are currently running(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Checkpoint was declined \\\\(tasks not ready\\\\)(.*\\n)*\"))) { \r\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","date":"2018-11-15 19:40:18","endLine":166,"groupId":"20189","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"(ClassLoaderclassLoader@ClusterClient<?>clusterClient@Deadlinedeadline)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/0b/79af513f6bb34074fbf11da7455fd66e5de6fb.src","preCode":"\tprivate String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!(exceptionString.matches(\"(.*\\n)*.*savepoint for the job .* failed(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*was not running(.*\\n)*\")\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Not all required tasks are currently running(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Checkpoint was declined \\\\(tasks not ready\\\\)(.*\\n)*\"))) { \r\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":108,"status":"M"},{"authorDate":"2018-11-14 18:40:35","commitOrder":6,"curCode":"\tprivate void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","date":"2018-11-15 19:40:18","endLine":185,"groupId":"52980","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(ClassLoaderclassLoader@ClusterClient<?>clusterClient@Deadlinedeadline@StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/0b/79af513f6bb34074fbf11da7455fd66e5de6fb.src","preCode":"\tprivate void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccesfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":168,"status":"M"}],"commitId":"8a101ce8940ecb756524a55ac412a3c4ba8214cd","commitMessage":"@@@[hotfix][tests] Fix typo in FutureUtils#retrySuccessfulWithDelay\n","date":"2018-11-15 19:40:18","modifiedFileCount":"11","status":"M","submitter":"zentol"},{"authorTime":"2018-11-14 18:40:35","codes":[{"authorDate":"2019-07-12 17:55:24","commitOrder":7,"curCode":"\tprivate String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!PATTERN_CANCEL_WITH_SAVEPOINT_TOLERATED_EXCEPTIONS.matcher(exceptionString).find()) {\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","date":"2019-07-15 17:16:27","endLine":170,"groupId":"41404","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"(ClassLoaderclassLoader@ClusterClient<?>clusterClient@Deadlinedeadline)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/86/a8aaa0b78ce327ecaa46da34ba00d7ed90fe20.src","preCode":"\tprivate String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!(exceptionString.matches(\"(.*\\n)*.*savepoint for the job .* failed(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*was not running(.*\\n)*\")\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Not all required tasks are currently running(.*\\n)*\") \r\n\t\t\t\t\t\t|| exceptionString.matches(\"(.*\\n)*.*Checkpoint was declined \\\\(tasks not ready\\\\)(.*\\n)*\"))) { \r\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":115,"status":"M"},{"authorDate":"2018-11-14 18:40:35","commitOrder":7,"curCode":"\tprivate void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","date":"2018-11-15 19:40:18","endLine":185,"groupId":"52980","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(ClassLoaderclassLoader@ClusterClient<?>clusterClient@Deadlinedeadline@StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/0b/79af513f6bb34074fbf11da7455fd66e5de6fb.src","preCode":"\tprivate void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":168,"status":"N"}],"commitId":"60432798fc68d507d76e652e36ce92b5f5cb5d0c","commitMessage":"@@@[FLINK-13243][tests] Simplify exception matching\n","date":"2019-07-15 17:16:27","modifiedFileCount":"1","status":"M","submitter":"Chesnay Schepler"},{"authorTime":"2019-11-01 14:51:28","codes":[{"authorDate":"2019-11-01 14:51:28","commitOrder":8,"curCode":"\tprivate String migrateJob(ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tClientUtils.submitJob(clusterClient, jobToMigrate);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!PATTERN_CANCEL_WITH_SAVEPOINT_TOLERATED_EXCEPTIONS.matcher(exceptionString).find()) {\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","date":"2019-11-01 14:51:28","endLine":177,"groupId":"41404","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"(ClusterClient<?>clusterClient@Deadlinedeadline)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ae/1484c27ae0b0b57e8cc60ed892c03ead841e94.src","preCode":"\tprivate String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!PATTERN_CANCEL_WITH_SAVEPOINT_TOLERATED_EXCEPTIONS.matcher(exceptionString).find()) {\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"},{"authorDate":"2019-11-01 14:51:28","commitOrder":8,"curCode":"\tprivate void restoreJob(ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tClientUtils.submitJob(clusterClient, jobToRestore);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","date":"2019-11-01 14:51:28","endLine":196,"groupId":"9598","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(ClusterClient<?>clusterClient@Deadlinedeadline@StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ae/1484c27ae0b0b57e8cc60ed892c03ead841e94.src","preCode":"\tprivate void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore, classLoader);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":179,"status":"M"}],"commitId":"bf5235e340543b9c4551d2131e8a405bd1e9e0c0","commitMessage":"@@@[FLINK-14496][client] Exclude detach flag from ClusterClient\n\nThis closes #9972 .","date":"2019-11-01 14:51:28","modifiedFileCount":"37","status":"M","submitter":"tison"},{"authorTime":"2019-11-01 14:51:28","codes":[{"authorDate":"2019-11-08 10:23:59","commitOrder":9,"curCode":"\tprivate String migrateJob(ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tClientUtils.submitJob(clusterClient, jobToMigrate);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath()).get();\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!PATTERN_CANCEL_WITH_SAVEPOINT_TOLERATED_EXCEPTIONS.matcher(exceptionString).find()) {\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","date":"2019-11-08 10:23:59","endLine":177,"groupId":"49437","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"(ClusterClient<?>clusterClient@Deadlinedeadline)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f0/4280573d17c1de5abdb45a33bd8b9fb2f00404.src","preCode":"\tprivate String migrateJob(ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tClientUtils.submitJob(clusterClient, jobToMigrate);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath());\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!PATTERN_CANCEL_WITH_SAVEPOINT_TOLERATED_EXCEPTIONS.matcher(exceptionString).find()) {\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":122,"status":"M"},{"authorDate":"2019-11-01 14:51:28","commitOrder":9,"curCode":"\tprivate void restoreJob(ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tClientUtils.submitJob(clusterClient, jobToRestore);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","date":"2019-11-01 14:51:28","endLine":196,"groupId":"9598","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(ClusterClient<?>clusterClient@Deadlinedeadline@StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ae/1484c27ae0b0b57e8cc60ed892c03ead841e94.src","preCode":"\tprivate void restoreJob(ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tClientUtils.submitJob(clusterClient, jobToRestore);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":179,"status":"N"}],"commitId":"d938c19480c220344827271ff8da729cd91735b3","commitMessage":"@@@[FLINK-14593][client] Port ClusterClient to asynchronous interface version\n\nThis closes #10069 .\n","date":"2019-11-08 10:23:59","modifiedFileCount":"27","status":"M","submitter":"tison"},{"authorTime":"2020-08-15 08:29:49","codes":[{"authorDate":"2020-08-15 08:29:49","commitOrder":10,"curCode":"\tprivate String migrateJob(ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tclusterClient.submitJob(jobToMigrate).get();\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath()).get();\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!PATTERN_CANCEL_WITH_SAVEPOINT_TOLERATED_EXCEPTIONS.matcher(exceptionString).find()) {\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","date":"2020-08-20 07:30:49","endLine":166,"groupId":"101249","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"migrateJob","params":"(ClusterClient<?>clusterClient@Deadlinedeadline)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/43/bc0dd925c15cd1dc023301d8251c6c4d91a0ec.src","preCode":"\tprivate String migrateJob(ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {\n\n\t\tURL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource(\"operatorstate/\" + getMigrationSavepointName());\n\t\tif (savepointResource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Savepoint file does not exist.\");\n\t\t}\n\t\tJobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE);\n\t\tjobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile()));\n\n\t\tassertNotNull(jobToMigrate.getJobID());\n\n\t\tClientUtils.submitJob(clusterClient, jobToMigrate);\n\n\t\tCompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.RUNNING,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.RUNNING,\n\t\t\tjobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\t\r\n\t\tFile targetDirectory = tmpFolder.newFolder();\n\t\tString savepointPath = null;\n\n\t\t\r\n\t\t\r\n\t\twhile (deadline.hasTimeLeft() && savepointPath == null) {\n\t\t\ttry {\n\t\t\t\tsavepointPath = clusterClient.cancelWithSavepoint(\n\t\t\t\t\tjobToMigrate.getJobID(),\n\t\t\t\t\ttargetDirectory.getAbsolutePath()).get();\n\t\t\t} catch (Exception e) {\n\t\t\t\tString exceptionString = ExceptionUtils.stringifyException(e);\n\t\t\t\tif (!PATTERN_CANCEL_WITH_SAVEPOINT_TOLERATED_EXCEPTIONS.matcher(exceptionString).find()) {\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tassertNotNull(\"Could not take savepoint.\", savepointPath);\n\n\t\tCompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToMigrate.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.CANCELED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.CANCELED,\n\t\t\tjobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n\t\treturn savepointPath;\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":111,"status":"M"},{"authorDate":"2020-08-15 08:29:49","commitOrder":10,"curCode":"\tprivate void restoreJob(ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tclusterClient.submitJob(jobToRestore).get();\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","date":"2020-08-20 07:30:49","endLine":185,"groupId":"101249","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJob","params":"(ClusterClient<?>clusterClient@Deadlinedeadline@StringsavepointPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/43/bc0dd925c15cd1dc023301d8251c6c4d91a0ec.src","preCode":"\tprivate void restoreJob(ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {\n\t\tJobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE);\n\t\tjobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState));\n\n\t\tassertNotNull(\"Job doesn't have a JobID.\", jobToRestore.getJobID());\n\n\t\tClientUtils.submitJob(clusterClient, jobToRestore);\n\n\t\tCompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(\n\t\t\t() -> clusterClient.getJobStatus(jobToRestore.getJobID()),\n\t\t\tTime.milliseconds(50),\n\t\t\tdeadline,\n\t\t\t(jobStatus) -> jobStatus == JobStatus.FINISHED,\n\t\t\tTestingUtils.defaultScheduledExecutor());\n\t\tassertEquals(\n\t\t\tJobStatus.FINISHED,\n\t\t\tjobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/state/operator/restore/AbstractOperatorRestoreTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":168,"status":"M"}],"commitId":"dfb8a3be7f0d113032a28cf6a1b296725e5562f5","commitMessage":"@@@[FLINK-15299][test] Move ClientUtils#submitJob & ClientUtils#submitJobAndWaitForResult to test scope\n\nThis closes #11469 .\n","date":"2020-08-20 07:30:49","modifiedFileCount":"28","status":"M","submitter":"tison"}]
