[{"authorTime":"2020-12-10 22:07:57","codes":[{"authorDate":"2021-08-10 20:57:29","commitOrder":3,"curCode":"    public void testCustomManagedMemoryWeights() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        final Configuration configuration = new Configuration();\n        configuration.set(ExecutionOptions.SORTED_INPUTS_MEMORY, MemorySize.ofMebiBytes(42));\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig(),\n                        configuration);\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n\n        final Map<ManagedMemoryUseCase, Integer> expectedOperatorWeights = new HashMap<>();\n        expectedOperatorWeights.put(ManagedMemoryUseCase.OPERATOR, 42);\n        assertThat(\n                processNode.getManagedMemoryOperatorScopeUseCaseWeights(),\n                equalTo(expectedOperatorWeights));\n        assertThat(\n                processNode.getManagedMemorySlotScopeUseCases(),\n                equalTo(Collections.singleton(ManagedMemoryUseCase.STATE_BACKEND)));\n    }\n","date":"2021-08-12 21:43:12","endLine":182,"groupId":"1409","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testCustomManagedMemoryWeights","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/4b/6d74400c9a4ecf381ab6dcef96e7b1aacc6d11.src","preCode":"    public void testCustomManagedMemoryWeights() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        final Configuration configuration = new Configuration();\n        configuration.set(ExecutionOptions.SORTED_INPUTS_MEMORY, MemorySize.ofMebiBytes(42));\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig(),\n                        configuration);\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n\n        final Map<ManagedMemoryUseCase, Integer> expectedOperatorWeights = new HashMap<>();\n        expectedOperatorWeights.put(ManagedMemoryUseCase.OPERATOR, 42);\n        assertThat(\n                processNode.getManagedMemoryOperatorScopeUseCaseWeights(),\n                equalTo(expectedOperatorWeights));\n        assertThat(\n                processNode.getManagedMemorySlotScopeUseCases(),\n                equalTo(Collections.singleton(ManagedMemoryUseCase.STATE_BACKEND)));\n    }\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":154,"status":"B"},{"authorDate":"2020-12-10 22:07:57","commitOrder":3,"curCode":"    public void testDisablingStateBackendOneInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        Configuration configuration = new Configuration();\n        configuration.set(ExecutionOptions.USE_BATCH_STATE_BACKEND, false);\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig(),\n                        configuration);\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), nullValue());\n        assertThat(graph.getTimerServiceProvider(), nullValue());\n    }\n","date":"2021-01-07 19:11:45","endLine":137,"groupId":"45699","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testDisablingStateBackendOneInputTransformation","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/10/89283442f9ab8757394dcd79734e1cf2a606a3.src","preCode":"    public void testDisablingStateBackendOneInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        Configuration configuration = new Configuration();\n        configuration.set(ExecutionOptions.USE_BATCH_STATE_BACKEND, false);\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig(),\n                        configuration);\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), nullValue());\n        assertThat(graph.getTimerServiceProvider(), nullValue());\n    }\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":111,"status":"NB"}],"commitId":"3e62364b1b0d6df9553220dc197ace58c546d544","commitMessage":"@@@[FLINK-23707][streaming-java] Use consistent managed memory weights for StreamNode\n\nThis closes #16771.\n","date":"2021-08-12 21:43:12","modifiedFileCount":"9","status":"M","submitter":"Timo Walther"},{"authorTime":"2021-08-12 00:09:10","codes":[{"authorDate":"2021-08-12 00:09:10","commitOrder":4,"curCode":"    public void testCustomManagedMemoryWeights() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        final Configuration configuration = new Configuration();\n        configuration.set(ExecutionOptions.SORTED_INPUTS_MEMORY, MemorySize.ofMebiBytes(42));\n\n        StreamGraph graph = getStreamGraphInBatchMode(sink, configuration);\n        StreamNode processNode = graph.getStreamNode(process.getId());\n\n        final Map<ManagedMemoryUseCase, Integer> expectedOperatorWeights = new HashMap<>();\n        expectedOperatorWeights.put(ManagedMemoryUseCase.OPERATOR, 42);\n        assertThat(\n                processNode.getManagedMemoryOperatorScopeUseCaseWeights(),\n                equalTo(expectedOperatorWeights));\n        assertThat(\n                processNode.getManagedMemorySlotScopeUseCases(),\n                equalTo(Collections.singleton(ManagedMemoryUseCase.STATE_BACKEND)));\n    }\n","date":"2021-08-13 23:14:56","endLine":164,"groupId":"103015","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"testCustomManagedMemoryWeights","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c3/a11115c73e4b56f4512869dcc841b1eac70b24.src","preCode":"    public void testCustomManagedMemoryWeights() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        final Configuration configuration = new Configuration();\n        configuration.set(ExecutionOptions.SORTED_INPUTS_MEMORY, MemorySize.ofMebiBytes(42));\n\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig(),\n                        configuration);\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n\n        final Map<ManagedMemoryUseCase, Integer> expectedOperatorWeights = new HashMap<>();\n        expectedOperatorWeights.put(ManagedMemoryUseCase.OPERATOR, 42);\n        assertThat(\n                processNode.getManagedMemoryOperatorScopeUseCaseWeights(),\n                equalTo(expectedOperatorWeights));\n        assertThat(\n                processNode.getManagedMemorySlotScopeUseCases(),\n                equalTo(Collections.singleton(ManagedMemoryUseCase.STATE_BACKEND)));\n    }\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":144,"status":"M"},{"authorDate":"2021-08-12 00:09:10","commitOrder":4,"curCode":"    public void testDisablingStateBackendOneInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        Configuration configuration = new Configuration();\n        configuration.set(ExecutionOptions.USE_BATCH_STATE_BACKEND, false);\n\n        StreamGraph graph = getStreamGraphInBatchMode(sink, configuration);\n\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), nullValue());\n        assertThat(graph.getTimerServiceProvider(), nullValue());\n    }\n","date":"2021-08-13 23:14:56","endLine":210,"groupId":"103015","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testDisablingStateBackendOneInputTransformation","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c3/a11115c73e4b56f4512869dcc841b1eac70b24.src","preCode":"    public void testDisablingStateBackendOneInputTransformation() {\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        SingleOutputStreamOperator<Integer> process =\n                env.fromElements(1, 2).keyBy(Integer::intValue).process(DUMMY_PROCESS_FUNCTION);\n        DataStreamSink<Integer> sink = process.addSink(new DiscardingSink<>());\n\n        Configuration configuration = new Configuration();\n        configuration.set(ExecutionOptions.USE_BATCH_STATE_BACKEND, false);\n        StreamGraphGenerator graphGenerator =\n                new StreamGraphGenerator(\n                        Collections.singletonList(sink.getTransformation()),\n                        env.getConfig(),\n                        env.getCheckpointConfig(),\n                        configuration);\n        graphGenerator.setRuntimeExecutionMode(RuntimeExecutionMode.BATCH);\n\n        StreamGraph graph = graphGenerator.generate();\n        StreamNode processNode = graph.getStreamNode(process.getId());\n        assertThat(\n                processNode.getInputRequirements().get(0),\n                equalTo(StreamConfig.InputRequirement.SORTED));\n        assertThat(\n                processNode.getOperatorFactory().getChainingStrategy(),\n                equalTo(ChainingStrategy.HEAD));\n        assertThat(graph.getStateBackend(), nullValue());\n        assertThat(graph.getTimerServiceProvider(), nullValue());\n    }\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/graph/StreamGraphGeneratorBatchExecutionTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":189,"status":"M"}],"commitId":"0875db3559afdb847d02de585ad7348b39eee053","commitMessage":"@@@[FLINK-20897][table-planner] Support batch mode in StreamTableEnvironment\n\nThis enables batch mode for StreamTableEnvironment.\n\nBoth StreamExecutionEnvironment.  TableEnvironment.  and StreamTableEnvironment\nuse StreamGraphGenerator with the same configuration. Previous work ensured\nthat when execution.runtime-mode is set to BATCH all batch properties are\neither set consistently (e.g. shuffle mode) or have no impact on the pipeline\n(e.g. auto watermark interval.  state backends).\n\nMost of the changes are removing checks and ensuring that internal (e.g. values)\nand external (e.g. data stream.  table source) source transformations are set\nto BOUNDED. The latter is a complex topic as we currently use 4 different ways\nof expressing external sources:\n\n- InputFormatProvider: Boundedness needs to be explicitly set by the planner\ndue to custom formats that don't extend from FileInputFormat.\n- SourceFunctionProvider: Boundedness needs to be explicitly set by the planner\nvia custom transformation to also disable progressive watermarks.\n- DataStreamScanProvider: Boundedness needs to be explicitly set by the planner\nto ensure old behavior again. New source interfaces + FileInputFormat are fine.\n- TransformationScanProvider: Boundedness can be derived automatically and will\nonly work with new source interfaces + FileInputFormat.\n\nThis closes #16793.\n","date":"2021-08-13 23:14:56","modifiedFileCount":"18","status":"M","submitter":"Timo Walther"}]
