[{"authorTime":"2018-10-22 22:00:40","codes":[{"authorDate":"2018-11-15 18:59:24","commitOrder":3,"curCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.triggerSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2018-11-15 18:59:24","endLine":200,"groupId":"45575","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e7/067086ce1bafe2f1d05b25ce9c957cc6bd03b5.src","preCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.triggerSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":180,"status":"B"},{"authorDate":"2018-10-22 22:00:40","commitOrder":3,"curCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccesfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2018-10-24 22:04:20","endLine":219,"groupId":"3988","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2c/d2bbb60e926ca0b9e8e871673c0f019fc7309b.src","preCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccesfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":181,"status":"NB"}],"commitId":"ddb02ddd44a6ded643b31df2711e9f615d0e8087","commitMessage":"@@@[FLINK-10764][tests] Add ITCase for checkpoint path entropy injection. (#7075)\n\nAdd a test that verifies that checkpoint data on the file system has additional\nentropy added to its path.\n\nRemove code duplication in SavepointITCase.","date":"2018-11-15 18:59:24","modifiedFileCount":"1","status":"M","submitter":"Gary Yao"},{"authorTime":"2018-11-14 18:40:35","codes":[{"authorDate":"2018-11-15 18:59:24","commitOrder":4,"curCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.triggerSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2018-11-15 18:59:24","endLine":200,"groupId":"45575","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e7/067086ce1bafe2f1d05b25ce9c957cc6bd03b5.src","preCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.triggerSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":180,"status":"N"},{"authorDate":"2018-11-14 18:40:35","commitOrder":4,"curCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2018-11-15 19:40:18","endLine":259,"groupId":"3988","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/91/40570a89009a378e60c2e18c6e929823eb3f99.src","preCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccesfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":221,"status":"M"}],"commitId":"8a101ce8940ecb756524a55ac412a3c4ba8214cd","commitMessage":"@@@[hotfix][tests] Fix typo in FutureUtils#retrySuccessfulWithDelay\n","date":"2018-11-15 19:40:18","modifiedFileCount":"11","status":"M","submitter":"zentol"},{"authorTime":"2018-11-14 18:40:35","codes":[{"authorDate":"2019-02-25 22:11:55","commitOrder":5,"curCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null);\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2019-02-28 20:58:47","endLine":200,"groupId":"45575","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/5b/77f037447eb031bd7e6947c690633832545429.src","preCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.triggerSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":180,"status":"M"},{"authorDate":"2018-11-14 18:40:35","commitOrder":5,"curCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2018-11-15 19:40:18","endLine":259,"groupId":"3988","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/91/40570a89009a378e60c2e18c6e929823eb3f99.src","preCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":221,"status":"N"}],"commitId":"bc3e66532576f0f29d6542e7021d288112c94689","commitMessage":"@@@[FLINK-10881] Use cancelWithSavepoint in SavepointITCase test.\n\nThis closes #7833.\n","date":"2019-02-28 20:58:47","modifiedFileCount":"1","status":"M","submitter":"Kostas Kloudas"},{"authorTime":"2019-11-01 14:51:28","codes":[{"authorDate":"2019-11-01 14:51:28","commitOrder":6,"curCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null);\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2019-11-01 14:51:28","endLine":203,"groupId":"33302","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/03/2db60bbf8a078291105f7efea2b9846f418cc2.src","preCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null);\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":184,"status":"M"},{"authorDate":"2019-11-01 14:51:28","commitOrder":6,"curCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2019-11-01 14:51:28","endLine":261,"groupId":"3988","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/03/2db60bbf8a078291105f7efea2b9846f418cc2.src","preCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, SavepointITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":224,"status":"M"}],"commitId":"bf5235e340543b9c4551d2131e8a405bd1e9e0c0","commitMessage":"@@@[FLINK-14496][client] Exclude detach flag from ClusterClient\n\nThis closes #9972 .","date":"2019-11-01 14:51:28","modifiedFileCount":"37","status":"M","submitter":"tison"},{"authorTime":"2019-11-08 10:23:59","codes":[{"authorDate":"2019-11-08 10:23:59","commitOrder":7,"curCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2019-11-08 10:23:59","endLine":203,"groupId":"33302","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/90/9b640539fd4a3a0e2e64a8e0e634c6771fac31.src","preCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null);\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":184,"status":"M"},{"authorDate":"2019-11-08 10:23:59","commitOrder":7,"curCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2019-11-08 10:23:59","endLine":261,"groupId":"3988","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/90/9b640539fd4a3a0e2e64a8e0e634c6771fac31.src","preCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId);\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":224,"status":"M"}],"commitId":"d938c19480c220344827271ff8da729cd91735b3","commitMessage":"@@@[FLINK-14593][client] Port ClusterClient to asynchronous interface version\n\nThis closes #10069 .\n","date":"2019-11-08 10:23:59","modifiedFileCount":"27","status":"M","submitter":"tison"},{"authorTime":"2020-04-25 20:35:38","codes":[{"authorDate":"2019-11-08 10:23:59","commitOrder":8,"curCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2019-11-08 10:23:59","endLine":203,"groupId":"33302","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/90/9b640539fd4a3a0e2e64a8e0e634c6771fac31.src","preCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":184,"status":"N"},{"authorDate":"2020-04-25 20:35:38","commitOrder":8,"curCode":"\tprivate void restoreJobAndVerifyState(\n\t\tString savepointPath,\n\t\tMiniClusterResourceFactory clusterFactory,\n\t\tint parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, false));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2020-05-16 22:32:18","endLine":282,"groupId":"3988","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/be/9b706e58c587ac376e677c2d1dee1481707520.src","preCode":"\tprivate void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":242,"status":"M"}],"commitId":"c5583c75394972dd4564132e3a0896a7f4f85a19","commitMessage":"@@@[FLINK-5763][state backends] Make savepoint selfcontain and relocatable\n","date":"2020-05-16 22:32:18","modifiedFileCount":"20","status":"M","submitter":"klion26"},{"authorTime":"2020-08-15 08:29:49","codes":[{"authorDate":"2020-08-15 08:29:49","commitOrder":9,"curCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.submitJob(jobGraph).get();\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2020-08-20 07:30:49","endLine":220,"groupId":"36402","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d7/0a409f2603af9f922eaab466dac80282db80ec.src","preCode":"\tprivate String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\treturn client.cancelWithSavepoint(jobId, null).get();\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":201,"status":"M"},{"authorDate":"2020-08-15 08:29:49","commitOrder":9,"curCode":"\tprivate void restoreJobAndVerifyState(\n\t\tString savepointPath,\n\t\tMiniClusterResourceFactory clusterFactory,\n\t\tint parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, false));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.submitJob(jobGraph).get();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2020-08-20 07:30:49","endLine":281,"groupId":"30403","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d7/0a409f2603af9f922eaab466dac80282db80ec.src","preCode":"\tprivate void restoreJobAndVerifyState(\n\t\tString savepointPath,\n\t\tMiniClusterResourceFactory clusterFactory,\n\t\tint parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, false));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"M"}],"commitId":"dfb8a3be7f0d113032a28cf6a1b296725e5562f5","commitMessage":"@@@[FLINK-15299][test] Move ClientUtils#submitJob & ClientUtils#submitJobAndWaitForResult to test scope\n\nThis closes #11469 .\n","date":"2020-08-20 07:30:49","modifiedFileCount":"28","status":"M","submitter":"tison"},{"authorTime":"2020-08-15 08:29:49","codes":[{"authorDate":"2021-06-17 23:35:20","commitOrder":10,"curCode":"    private String submitJobAndTakeSavepoint(\n            MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n        final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n        final JobID jobId = jobGraph.getJobID();\n        StatefulCounter.resetForTest(parallelism);\n\n        MiniClusterWithClientResource cluster = clusterFactory.get();\n        cluster.before();\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            client.submitJob(jobGraph).get();\n\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobId);\n            StatefulCounter.getProgressLatch().await();\n\n            return client.cancelWithSavepoint(jobId, null).get();\n        } finally {\n            cluster.after();\n            StatefulCounter.resetForTest(parallelism);\n        }\n    }\n","date":"2021-06-18 16:14:24","endLine":312,"groupId":"25341","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2f/911d851e41b3a8e4fe8f7d7a67cf9c6c9d92cb.src","preCode":"    private String submitJobAndTakeSavepoint(\n            MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n        final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n        final JobID jobId = jobGraph.getJobID();\n        StatefulCounter.resetForTest(parallelism);\n\n        MiniClusterWithClientResource cluster = clusterFactory.get();\n        cluster.before();\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            client.submitJob(jobGraph).get();\n\n            StatefulCounter.getProgressLatch().await();\n\n            return client.cancelWithSavepoint(jobId, null).get();\n        } finally {\n            cluster.after();\n            StatefulCounter.resetForTest(parallelism);\n        }\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":291,"status":"M"},{"authorDate":"2020-08-15 08:29:49","commitOrder":10,"curCode":"\tprivate void restoreJobAndVerifyState(\n\t\tString savepointPath,\n\t\tMiniClusterResourceFactory clusterFactory,\n\t\tint parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, false));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.submitJob(jobGraph).get();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2020-08-20 07:30:49","endLine":281,"groupId":"30403","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d7/0a409f2603af9f922eaab466dac80282db80ec.src","preCode":"\tprivate void restoreJobAndVerifyState(\n\t\tString savepointPath,\n\t\tMiniClusterResourceFactory clusterFactory,\n\t\tint parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, false));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.submitJob(jobGraph).get();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"N"}],"commitId":"3fa698295175946085500e2f7971611b868eaed2","commitMessage":"@@@[FLINK-22593][tests] Waiting for all tasks running before triggering savepoint in SavepointITCase\n","date":"2021-06-18 16:14:24","modifiedFileCount":"2","status":"M","submitter":"Anton Kalashnikov"},{"authorTime":"2020-08-15 08:29:49","codes":[{"authorDate":"2021-08-13 08:54:07","commitOrder":11,"curCode":"    private String submitJobAndTakeSavepoint(\n            MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n        final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n        final JobID jobId = jobGraph.getJobID();\n        StatefulCounter.resetForTest(parallelism);\n\n        MiniClusterWithClientResource cluster = clusterFactory.get();\n        cluster.before();\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            client.submitJob(jobGraph).get();\n\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobId, false);\n            StatefulCounter.getProgressLatch().await();\n\n            return client.cancelWithSavepoint(jobId, null).get();\n        } finally {\n            cluster.after();\n            StatefulCounter.resetForTest(parallelism);\n        }\n    }\n","date":"2021-08-23 20:24:35","endLine":381,"groupId":"101599","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"submitJobAndTakeSavepoint","params":"(MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/cb/6426a7e159a2f01d6f2217b41ca79f11dabe1f.src","preCode":"    private String submitJobAndTakeSavepoint(\n            MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {\n        final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n        final JobID jobId = jobGraph.getJobID();\n        StatefulCounter.resetForTest(parallelism);\n\n        MiniClusterWithClientResource cluster = clusterFactory.get();\n        cluster.before();\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            client.submitJob(jobGraph).get();\n\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobId);\n            StatefulCounter.getProgressLatch().await();\n\n            return client.cancelWithSavepoint(jobId, null).get();\n        } finally {\n            cluster.after();\n            StatefulCounter.resetForTest(parallelism);\n        }\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":360,"status":"M"},{"authorDate":"2020-08-15 08:29:49","commitOrder":11,"curCode":"\tprivate void restoreJobAndVerifyState(\n\t\tString savepointPath,\n\t\tMiniClusterResourceFactory clusterFactory,\n\t\tint parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, false));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.submitJob(jobGraph).get();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","date":"2020-08-20 07:30:49","endLine":281,"groupId":"101599","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"restoreJobAndVerifyState","params":"(StringsavepointPath@MiniClusterResourceFactoryclusterFactory@intparallelism)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d7/0a409f2603af9f922eaab466dac80282db80ec.src","preCode":"\tprivate void restoreJobAndVerifyState(\n\t\tString savepointPath,\n\t\tMiniClusterResourceFactory clusterFactory,\n\t\tint parallelism) throws Exception {\n\t\tfinal JobGraph jobGraph = createJobGraph(parallelism, 0, 1000);\n\t\tjobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, false));\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\t\tStatefulCounter.resetForTest(parallelism);\n\n\t\tMiniClusterWithClientResource cluster = clusterFactory.get();\n\t\tcluster.before();\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tclient.submitJob(jobGraph).get();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getRestoreLatch().await();\n\n\t\t\t\r\n\t\t\tStatefulCounter.getProgressLatch().await();\n\n\t\t\tclient.cancel(jobId).get();\n\n\t\t\tFutureUtils.retrySuccessfulWithDelay(\n\t\t\t\t() -> client.getJobStatus(jobId),\n\t\t\t\tTime.milliseconds(50),\n\t\t\t\tDeadline.now().plus(Duration.ofSeconds(30)),\n\t\t\t\tstatus -> status == JobStatus.CANCELED,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tclient.disposeSavepoint(savepointPath)\n\t\t\t\t.get();\n\n\t\t\tassertFalse(\"Savepoint not properly cleaned up.\", new File(savepointPath).exists());\n\t\t} finally {\n\t\t\tcluster.after();\n\t\t\tStatefulCounter.resetForTest(parallelism);\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/SavepointITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":241,"status":"N"}],"commitId":"136bb52326922dfe70b3cc79fd463f9d6cfecc32","commitMessage":"@@@[FLINK-23811][tests] Handle finished subtasks in CommonTestUtils.waitForAllTaskRunning\n\nCommonTestUtils.waitForAllTaskRunning returns when all the subtasks are running AND\nthe job is running and not finished. However.  with FLIP-147.  subtasks may finish and\nthe job will still be running. So the method won't return and instead timeout.\n\nThis commit adds a flag to indicate whether to fail or proceed\nwhen a finished sub-task is encountered.\n","date":"2021-08-23 20:24:35","modifiedFileCount":"7","status":"M","submitter":"Roman Khachatryan"}]
