[{"authorTime":"2016-11-29 20:57:30","codes":[{"authorDate":"2016-11-29 20:57:30","commitOrder":1,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" ,status);\n\t\twhile(!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2016-12-02 21:28:35","endLine":146,"groupId":"30452","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/452c15152058cbd58f297c60fb0d6ec77800bb.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" ,status);\n\t\twhile(!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":50,"status":"B"},{"authorDate":"2016-11-29 20:57:30","commitOrder":1,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile(!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i=count; i<count+batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes()))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2016-12-02 21:28:35","endLine":245,"groupId":"33365","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6a/bea2a200e201da300e14e6af105d1423384491.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile(!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i=count; i<count+batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes()))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"B"}],"commitId":"de4fe3b7392948807753d65d13f3da968e6c7de0","commitMessage":"@@@[FLINK-4676] [connectors] Merge batch and streaming connectors into common Maven module.\n\nThis closes #2897.\n","date":"2016-12-02 21:28:35","modifiedFileCount":"0","status":"B","submitter":"Fabian Hueske"},{"authorTime":"2017-03-03 20:24:49","codes":[{"authorDate":"2016-11-29 20:57:30","commitOrder":2,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" ,status);\n\t\twhile(!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2016-12-02 21:28:35","endLine":146,"groupId":"30452","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/452c15152058cbd58f297c60fb0d6ec77800bb.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" ,status);\n\t\twhile(!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":50,"status":"N"},{"authorDate":"2017-03-03 20:24:49","commitOrder":2,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile(!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i=count; i<count+batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2017-03-09 20:00:55","endLine":245,"groupId":"33365","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/71/bcae358fc4d737bde8670c8699dd3f59c899d9.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile(!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i=count; i<count+batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes()))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":61,"status":"M"}],"commitId":"53fedbd2894c6c7b839d8fdcc0dbf1e6e21e631a","commitMessage":"@@@[FLINK-5824] Fix String/byte conversions without explicit encoding\n\nThis closes #3468\n","date":"2017-03-09 20:00:55","modifiedFileCount":"70","status":"M","submitter":"Dawid Wysakowicz"},{"authorTime":"2017-11-23 23:52:38","codes":[{"authorDate":"2017-11-23 23:52:38","commitOrder":3,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2017-11-28 04:15:39","endLine":149,"groupId":"30452","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/67/ddad220a9f51b469fc9e26454dde9d5ecace70.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"M"},{"authorDate":"2017-11-23 23:52:38","commitOrder":3,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2017-11-28 04:15:39","endLine":247,"groupId":"33365","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ce/f8720f8d8859940921ce2706ec90dd5b501dc4.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_MEMORY_SIZE_KEY, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":63,"status":"M"}],"commitId":"f2b804a7479dcba7980dd68a445635f4ac2198c0","commitMessage":"@@@[FLINK-8142] [config] Cleanup references to deprecated constants in ConfigConstants\n\nThis closes #5067\n","date":"2017-11-28 04:15:39","modifiedFileCount":"6","status":"M","submitter":"yew1eb"},{"authorTime":"2018-01-03 03:21:28","codes":[{"authorDate":"2018-01-03 03:21:28","commitOrder":4,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2018-01-12 19:43:28","endLine":148,"groupId":"30452","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/96/3002f1cd78471cacc4fc8279ed34af3ee70d0c.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"},{"authorDate":"2018-01-03 03:21:28","commitOrder":4,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2018-01-12 19:43:28","endLine":247,"groupId":"50845","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/93/b9caf6ec26333cd9eb34d0bc50bdb6b0ea26e0.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesisClient client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":63,"status":"M"}],"commitId":"d53a722e769e8ff6009d53208bf6702ec3e4a6f5","commitMessage":"@@@[FLINK-8271] [kinesis] Remove usage of deprecated Kinesis APIs\n\nThis closes #5171.\n","date":"2018-01-12 19:43:28","modifiedFileCount":"4","status":"M","submitter":"Bowen Li"},{"authorTime":"2018-03-21 00:01:54","codes":[{"authorDate":"2018-03-21 00:01:54","commitOrder":5,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2018-04-24 19:45:17","endLine":148,"groupId":"30452","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/40/225fb0dd368c826d1dcaea37d1092140d66331.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"},{"authorDate":"2018-03-21 00:01:54","commitOrder":5,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2018-04-24 19:45:17","endLine":247,"groupId":"50845","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/34/dcdc0b247251e76cd03cc4319e2220e8dbc479.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(ConfigConstants.TASK_MANAGER_NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":63,"status":"M"}],"commitId":"73e9f9013391a4e5be18f1cfc1f9462a78e95ca7","commitMessage":"@@@[FLINK-9033][config] Replace usages of deprecated TASK_MANAGER_NUM_TASK_SLOTS\n\nThis closes #5731.\n","date":"2018-04-24 19:45:17","modifiedFileCount":"30","status":"M","submitter":"zhouhai02"},{"authorTime":"2018-02-10 14:52:13","codes":[{"authorDate":"2018-02-10 14:52:13","commitOrder":6,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2018-07-05 21:54:54","endLine":148,"groupId":"0","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/66/00147a1f1f13dfea08ff6c861732837628f7c6.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":52,"status":"M"},{"authorDate":"2018-02-10 14:52:13","commitOrder":6,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","date":"2018-07-05 21:54:54","endLine":247,"groupId":"50845","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b2/21ae511d5d6fd403226ad50dfc27839d28cb63.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setLong(TaskManagerOptions.MANAGED_MEMORY_SIZE, 16);\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":63,"status":"M"}],"commitId":"d02167dc5eb6a6d8520955499e84dd4d06f06f6e","commitMessage":"@@@[FLINK-6469][core] Configure Memory Sizes with units\n\nThis closes #5448\n","date":"2018-07-05 21:54:54","modifiedFileCount":"59","status":"M","submitter":"yanghua"},{"authorTime":"2019-02-07 19:49:57","codes":[{"authorDate":"2019-02-07 19:49:57","commitOrder":7,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","date":"2019-02-10 16:35:45","endLine":151,"groupId":"40675","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/03/3ead6c4cc7dd08103d1b2e8da160a26bfd9d3d.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"M"},{"authorDate":"2019-02-07 19:49:57","commitOrder":7,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","date":"2019-02-10 16:35:45","endLine":250,"groupId":"50845","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/26/a422f7f261ebf539f65cf197dad30081e4941b.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, 1);\n\t\tflinkConfig.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, 8);\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tLocalFlinkMiniCluster flink = new LocalFlinkMiniCluster(flinkConfig, false);\n\t\tflink.start();\n\n\t\tfinal int flinkPort = flink.getLeaderRPCPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.stop();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"}],"commitId":"7a6337c4e84f479412780ac4b73df28a3082c195","commitMessage":"@@@[FLINK-11550][kinesis] Port manual tests\n","date":"2019-02-10 16:35:45","modifiedFileCount":"2","status":"M","submitter":"zentol"},{"authorTime":"2019-09-23 11:15:03","codes":[{"authorDate":"2019-09-23 11:15:03","commitOrder":8,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.LEGACY_MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","date":"2019-10-15 00:38:53","endLine":151,"groupId":"40675","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/89/0ac305350967fc8bc1cc8cb950a7402e47a6f5.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"M"},{"authorDate":"2019-09-23 11:15:03","commitOrder":8,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.LEGACY_MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","date":"2019-10-15 00:38:53","endLine":250,"groupId":"50845","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/8f/6880a517c84d0d266c25213fd7fcb248fbc84b.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"}],"commitId":"255f047f31bc5a89e2f2224bb6fd61ae4a4e44d8","commitMessage":"@@@[hotfix] Rename `TaskManagerOptions#MANAGED_MEMORY_SIZE` and `TaskManagerOptions#MANAGED_MEMORY_FRACTION` with prefix `LEGACY_`.\n\nThis is to avoid naming conflict with the new config options.\n","date":"2019-10-15 00:38:53","modifiedFileCount":"44","status":"M","submitter":"Xintong Song"},{"authorTime":"2019-11-14 13:04:57","codes":[{"authorDate":"2019-11-14 13:04:57","commitOrder":9,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","date":"2019-12-03 23:29:31","endLine":151,"groupId":"40675","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/03/3ead6c4cc7dd08103d1b2e8da160a26bfd9d3d.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.LEGACY_MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":53,"status":"M"},{"authorDate":"2019-11-14 13:04:57","commitOrder":9,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","date":"2019-12-03 23:29:31","endLine":250,"groupId":"50845","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/26/a422f7f261ebf539f65cf197dad30081e4941b.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.LEGACY_MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":64,"status":"M"}],"commitId":"ffe323e1d23aa2c042650e8c3184da04b70c184a","commitMessage":"@@@[FLINK-13986][core][config] Remove legacy config option TaskManagerOptions#LEGACY_MANAGED_MEMORY_SIZE.\n","date":"2019-12-03 23:29:31","modifiedFileCount":"33","status":"M","submitter":"Xintong Song"},{"authorTime":"2019-12-24 15:40:07","codes":[{"authorDate":"2019-12-24 15:40:07","commitOrder":10,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.set(TaskManagerOptions.MANAGED_MEMORY_SIZE, MemorySize.parse(\"16m\"));\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","date":"2020-01-03 17:49:05","endLine":152,"groupId":"10541","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f8/aa693771af631f0ddcbcb8a84d4257859c0242.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tProperties configProps = new Properties();\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(AWSConfigConstants.AWS_REGION, region);\n\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\" , status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tThread producerThread = KinesisEventsGeneratorProducerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 2,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tproducerError, flinkPort, flinkConfig);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 200, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 2 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\t\t\t}\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":54,"status":"M"},{"authorDate":"2019-12-24 15:40:07","commitOrder":10,"curCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.set(TaskManagerOptions.MANAGED_MEMORY_SIZE, MemorySize.parse(\"16m\"));\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","date":"2020-01-03 17:49:05","endLine":251,"groupId":"10541","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"main","params":"(String[]args)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d6/a6a15e64244ce77af510c41ca91e6aaf107834.src","preCode":"\tpublic static void main(String[] args) throws Exception {\n\t\tfinal ParameterTool pt = ParameterTool.fromArgs(args);\n\t\tLOG.info(\"Starting exactly once with stream resharding test\");\n\n\t\tfinal String streamName = \"flink-test-\" + UUID.randomUUID().toString();\n\t\tfinal String accessKey = pt.getRequired(\"accessKey\");\n\t\tfinal String secretKey = pt.getRequired(\"secretKey\");\n\t\tfinal String region = pt.getRequired(\"region\");\n\n\t\tfinal Properties configProps = new Properties();\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, accessKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, secretKey);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.AWS_REGION, region);\n\t\tconfigProps.setProperty(ConsumerConfigConstants.SHARD_DISCOVERY_INTERVAL_MILLIS, \"0\");\n\t\tfinal AmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\n\t\t\r\n\t\tclient.createStream(streamName, 1);\n\n\t\t\r\n\t\tDescribeStreamResult status = client.describeStream(streamName);\n\t\tLOG.info(\"status {}\", status);\n\t\twhile (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\")) {\n\t\t\tstatus = client.describeStream(streamName);\n\t\t\tLOG.info(\"Status of stream {}\", status);\n\t\t\tThread.sleep(1000);\n\t\t}\n\n\t\tfinal Configuration flinkConfig = new Configuration();\n\t\tflinkConfig.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, \"16m\");\n\t\tflinkConfig.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, \"0 s\");\n\n\t\tMiniClusterResource flink = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder()\n\t\t\t.setNumberTaskManagers(1)\n\t\t\t.setNumberSlotsPerTaskManager(8)\n\t\t\t.setConfiguration(flinkConfig)\n\t\t\t.build());\n\t\tflink.before();\n\n\t\tfinal int flinkPort = flink.getRestAddres().getPort();\n\n\t\ttry {\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfinal AtomicReference<Throwable> producerError = new AtomicReference<>();\n\t\t\tRunnable manualGenerate = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\tAmazonKinesis client = AWSUtil.createKinesisClient(configProps);\n\t\t\t\t\tint count = 0;\n\t\t\t\t\tfinal int batchSize = 30;\n\t\t\t\t\twhile (true) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tThread.sleep(10);\n\n\t\t\t\t\t\t\tSet<PutRecordsRequestEntry> batch = new HashSet<>();\n\t\t\t\t\t\t\tfor (int i = count; i < count + batchSize; i++) {\n\t\t\t\t\t\t\t\tif (i >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbatch.add(\n\t\t\t\t\t\t\t\t\tnew PutRecordsRequestEntry()\n\t\t\t\t\t\t\t\t\t\t.withData(ByteBuffer.wrap(((i) + \"-\" + RandomStringUtils.randomAlphabetic(12)).getBytes(ConfigConstants.DEFAULT_CHARSET)))\n\t\t\t\t\t\t\t\t\t\t.withPartitionKey(UUID.randomUUID().toString()));\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcount += batchSize;\n\n\t\t\t\t\t\t\tPutRecordsResult result = client.putRecords(new PutRecordsRequest().withStreamName(streamName).withRecords(batch));\n\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tif (result.getFailedRecordCount() > 0) {\n\t\t\t\t\t\t\t\tproducerError.set(new RuntimeException(\"The producer has failed records in one of the put batch attempts.\"));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (count >= TOTAL_EVENT_COUNT) {\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t\tproducerError.set(e);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread producerThread = new Thread(manualGenerate);\n\t\t\tproducerThread.start();\n\n\t\t\tfinal AtomicReference<Throwable> consumerError = new AtomicReference<>();\n\t\t\tThread consumerThread = ExactlyOnceValidatingConsumerThread.create(\n\t\t\t\tTOTAL_EVENT_COUNT, 10000, 2, 500, 500,\n\t\t\t\taccessKey, secretKey, region, streamName,\n\t\t\t\tconsumerError, flinkPort, flinkConfig);\n\t\t\tconsumerThread.start();\n\n\t\t\t\r\n\t\t\tRunnable splitShard = new Runnable() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(5000);\n\t\t\t\t\t\tLOG.info(\"Splitting shard ...\");\n\t\t\t\t\t\tclient.splitShard(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(0),\n\t\t\t\t\t\t\t\"170141183460469231731687303715884105727\");\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tDescribeStreamResult status;\n\t\t\t\t\t\tRandom rand = new Random();\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tstatus = null;\n\t\t\t\t\t\t\twhile (status == null) {\n\t\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\tstatus = client.describeStream(streamName);\n\t\t\t\t\t\t\t\t} catch (LimitExceededException lee) {\n\t\t\t\t\t\t\t\t\tLOG.warn(\"LimitExceededException while describing stream ... retrying ...\");\n\t\t\t\t\t\t\t\t\tThread.sleep(rand.nextInt(1200));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} while (!status.getStreamDescription().getStreamStatus().equals(\"ACTIVE\"));\n\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tThread.sleep(7000);\n\t\t\t\t\t\tLOG.info(\"Merging shards ...\");\n\t\t\t\t\t\tclient.mergeShards(\n\t\t\t\t\t\t\tstreamName,\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(1),\n\t\t\t\t\t\t\tKinesisShardIdGenerator.generateFromShardOrder(2));\n\t\t\t\t\t} catch (InterruptedException iex) {\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tThread splitShardThread = new Thread(splitShard);\n\t\t\tsplitShardThread.start();\n\n\t\t\tboolean deadlinePassed = false;\n\t\t\tlong deadline = System.currentTimeMillis() + (1000 * 5 * 60); \r\n\t\t\t\r\n\t\t\twhile ((consumerThread.isAlive() || producerThread.isAlive()) &&\n\t\t\t\t(producerError.get() == null && consumerError.get() == null)) {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (System.currentTimeMillis() >= deadline) {\n\t\t\t\t\tLOG.warn(\"Deadline passed\");\n\t\t\t\t\tdeadlinePassed = true;\n\t\t\t\t\tbreak; \r\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (producerThread.isAlive()) {\n\t\t\t\tproducerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (consumerThread.isAlive()) {\n\t\t\t\tconsumerThread.interrupt();\n\t\t\t}\n\n\t\t\tif (producerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Producer failed\", producerError.get());\n\n\t\t\t}\n\n\t\t\tif (consumerError.get() != null) {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t\tthrow new RuntimeException(\"Consumer failed\", consumerError.get());\n\t\t\t}\n\n\t\t\tif (!deadlinePassed) {\n\t\t\t\tLOG.info(\"+++ TEST passed! +++\");\n\t\t\t} else {\n\t\t\t\tLOG.info(\"+++ TEST failed! +++\");\n\t\t\t}\n\n\t\t} finally {\n\t\t\tclient.deleteStream(streamName);\n\t\t\tclient.shutdown();\n\n\t\t\t\r\n\t\t\tflink.after();\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kinesis/src/test/java/org/apache/flink/streaming/connectors/kinesis/manualtests/ManualExactlyOnceWithStreamReshardingTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":65,"status":"M"}],"commitId":"702a01663fbb5ee999282d3a0561955084ef2841","commitMessage":"@@@[FLINK-15371][core][config] Use the new type definition for config options of memory types in TaskManagerOptions.\n\nThis closes #10677.\n","date":"2020-01-03 17:49:05","modifiedFileCount":"61","status":"M","submitter":"Xintong Song"}]
