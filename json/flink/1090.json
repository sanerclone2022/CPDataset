[{"authorTime":"2020-06-05 01:16:27","codes":[{"authorDate":"2021-03-11 14:14:07","commitOrder":11,"curCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n\n        return stateFactory.create(\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory));\n    }\n","date":"2021-03-15 16:07:03","endLine":329,"groupId":"20603","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"createInternalState","params":"(@NonnullTypeSerializer<N>namespaceSerializer@@NonnullStateDescriptor<S@SV>stateDesc@@NonnullStateSnapshotTransformer.StateSnapshotTransformFactory<SEV>snapshotTransformFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b4/afabb27e7de4a14ac7bf698c0f9667c7b42ff1.src","preCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n\n        return stateFactory.create(\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory));\n    }\n","realPath":"flink-state-backends/flink-statebackend-changelog/src/main/java/org/apache/flink/state/changelog/ChangelogKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":310,"status":"B"},{"authorDate":"2020-06-05 01:16:27","commitOrder":11,"curCode":"\tprivate <N, S extends State, SV> void migrateStateValues(\n\t\tStateDescriptor<S, SV> stateDesc,\n\t\tTuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo) throws Exception {\n\n\t\tif (stateDesc.getType() == StateDescriptor.Type.MAP) {\n\t\t\tTypeSerializerSnapshot<SV> previousSerializerSnapshot = stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n\t\t\tcheckState(previousSerializerSnapshot != null, \"the previous serializer snapshot should exist.\");\n\t\t\tcheckState(previousSerializerSnapshot instanceof MapSerializerSnapshot, \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n\t\t\tTypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n\t\t\tcheckState(newSerializer instanceof MapSerializer, \"new serializer should be a MapSerializer.\");\n\n\t\t\tMapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n\t\t\tMapSerializerSnapshot<?, ?> mapSerializerSnapshot = (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n\t\t\tif (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n\t\t\t\tthrow new StateMigrationException(\n\t\t\t\t\t\"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n\t\t\t}\n\t\t}\n\n\t\tLOG.info(\n\t\t\t\"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n\t\t\tstateDesc);\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tStateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n\t\tif (stateFactory == null) {\n\t\t\tString message = String.format(\"State %s is not supported by %s\",\n\t\t\t\tstateDesc.getClass(), this.getClass());\n\t\t\tthrow new FlinkRuntimeException(message);\n\t\t}\n\t\tState state = stateFactory.createState(\n\t\t\tstateDesc,\n\t\t\tstateMetaInfo,\n\t\t\tRocksDBKeyedStateBackend.this);\n\t\tif (!(state instanceof AbstractRocksDBState)) {\n\t\t\tthrow new FlinkRuntimeException(\n\t\t\t\t\"State should be an AbstractRocksDBState but is \" + state);\n\t\t}\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tAbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n\t\tSnapshot rocksDBSnapshot = db.getSnapshot();\n\t\ttry (\n\t\t\tRocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n\t\t\tRocksDBWriteBatchWrapper batchWriter = new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())\n\t\t) {\n\t\t\titerator.seekToFirst();\n\n\t\t\tDataInputDeserializer serializedValueInput = new DataInputDeserializer();\n\t\t\tDataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n\t\t\twhile (iterator.isValid()) {\n\t\t\t\tserializedValueInput.setBuffer(iterator.value());\n\n\t\t\t\trocksDBState.migrateSerializedValue(\n\t\t\t\t\tserializedValueInput,\n\t\t\t\t\tmigratedSerializedValueOutput,\n\t\t\t\t\tstateMetaInfo.f1.getPreviousStateSerializer(),\n\t\t\t\t\tstateMetaInfo.f1.getStateSerializer());\n\n\t\t\t\tbatchWriter.put(stateMetaInfo.f0, iterator.key(), migratedSerializedValueOutput.getCopyOfBuffer());\n\n\t\t\t\tmigratedSerializedValueOutput.clear();\n\t\t\t\titerator.next();\n\t\t\t}\n\t\t} finally {\n\t\t\tdb.releaseSnapshot(rocksDBSnapshot);\n\t\t\trocksDBSnapshot.close();\n\t\t}\n\t}\n","date":"2020-06-26 22:24:49","endLine":649,"groupId":"8974","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"migrateStateValues","params":"(StateDescriptor<S@SV>stateDesc@Tuple2<ColumnFamilyHandle@RegisteredKeyValueStateBackendMetaInfo<N@SV>>stateMetaInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f0/cce0b2ffd7ad2f5ef6fb8fa73a89c8fc0abf0f.src","preCode":"\tprivate <N, S extends State, SV> void migrateStateValues(\n\t\tStateDescriptor<S, SV> stateDesc,\n\t\tTuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo) throws Exception {\n\n\t\tif (stateDesc.getType() == StateDescriptor.Type.MAP) {\n\t\t\tTypeSerializerSnapshot<SV> previousSerializerSnapshot = stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n\t\t\tcheckState(previousSerializerSnapshot != null, \"the previous serializer snapshot should exist.\");\n\t\t\tcheckState(previousSerializerSnapshot instanceof MapSerializerSnapshot, \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n\t\t\tTypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n\t\t\tcheckState(newSerializer instanceof MapSerializer, \"new serializer should be a MapSerializer.\");\n\n\t\t\tMapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n\t\t\tMapSerializerSnapshot<?, ?> mapSerializerSnapshot = (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n\t\t\tif (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n\t\t\t\tthrow new StateMigrationException(\n\t\t\t\t\t\"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n\t\t\t}\n\t\t}\n\n\t\tLOG.info(\n\t\t\t\"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n\t\t\tstateDesc);\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tStateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n\t\tif (stateFactory == null) {\n\t\t\tString message = String.format(\"State %s is not supported by %s\",\n\t\t\t\tstateDesc.getClass(), this.getClass());\n\t\t\tthrow new FlinkRuntimeException(message);\n\t\t}\n\t\tState state = stateFactory.createState(\n\t\t\tstateDesc,\n\t\t\tstateMetaInfo,\n\t\t\tRocksDBKeyedStateBackend.this);\n\t\tif (!(state instanceof AbstractRocksDBState)) {\n\t\t\tthrow new FlinkRuntimeException(\n\t\t\t\t\"State should be an AbstractRocksDBState but is \" + state);\n\t\t}\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tAbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n\t\tSnapshot rocksDBSnapshot = db.getSnapshot();\n\t\ttry (\n\t\t\tRocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n\t\t\tRocksDBWriteBatchWrapper batchWriter = new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())\n\t\t) {\n\t\t\titerator.seekToFirst();\n\n\t\t\tDataInputDeserializer serializedValueInput = new DataInputDeserializer();\n\t\t\tDataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n\t\t\twhile (iterator.isValid()) {\n\t\t\t\tserializedValueInput.setBuffer(iterator.value());\n\n\t\t\t\trocksDBState.migrateSerializedValue(\n\t\t\t\t\tserializedValueInput,\n\t\t\t\t\tmigratedSerializedValueOutput,\n\t\t\t\t\tstateMetaInfo.f1.getPreviousStateSerializer(),\n\t\t\t\t\tstateMetaInfo.f1.getStateSerializer());\n\n\t\t\t\tbatchWriter.put(stateMetaInfo.f0, iterator.key(), migratedSerializedValueOutput.getCopyOfBuffer());\n\n\t\t\t\tmigratedSerializedValueOutput.clear();\n\t\t\t\titerator.next();\n\t\t\t}\n\t\t} finally {\n\t\t\tdb.releaseSnapshot(rocksDBSnapshot);\n\t\t\trocksDBSnapshot.close();\n\t\t}\n\t}\n","realPath":"flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":577,"status":"NB"}],"commitId":"d72fa2ea588fc0f52ebd33d583187eb27972a483","commitMessage":"@@@[FLINK-21354] Introduce ChangelogStateBackend to delegate state access\n\nThis change is to wrap the existing prod state backend (Rocksdb.  Fs.  Mem) to delegate\nstate access for these state backends. In the future.  we can forward state changes to\nStateChangeLog when states are updated. In this PR.  we only support keyed-state access.\n\nThe changes include:\n1. Introduce `DelegatingStateBackend` interface for state backend delegation\n   (in the flink-runtime module)\n2. Introduce `ChangelogStateBackend` and related delegating states for\n   state delegation (in flink-state-backends module)\n3. Implement `ChangelogStateBackend`'s Loader in `StateBackendLoader`.\n   (in the flink-runtime module)\n","date":"2021-03-15 16:07:03","modifiedFileCount":"12","status":"M","submitter":"Yuan Mei"},{"authorTime":"2020-06-05 01:16:27","codes":[{"authorDate":"2021-03-29 19:17:40","commitOrder":12,"curCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter);\n        return stateFactory.create(state, kvStateChangeLogger);\n    }\n","date":"2021-06-16 16:00:53","endLine":354,"groupId":"20603","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"createInternalState","params":"(@NonnullTypeSerializer<N>namespaceSerializer@@NonnullStateDescriptor<S@SV>stateDesc@@NonnullStateSnapshotTransformer.StateSnapshotTransformFactory<SEV>snapshotTransformFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/80/5ae9502a352188071bb8ff0c0413c1bbdf472c.src","preCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n\n        return stateFactory.create(\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory));\n    }\n","realPath":"flink-state-backends/flink-statebackend-changelog/src/main/java/org/apache/flink/state/changelog/ChangelogKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":327,"status":"M"},{"authorDate":"2020-06-05 01:16:27","commitOrder":12,"curCode":"\tprivate <N, S extends State, SV> void migrateStateValues(\n\t\tStateDescriptor<S, SV> stateDesc,\n\t\tTuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo) throws Exception {\n\n\t\tif (stateDesc.getType() == StateDescriptor.Type.MAP) {\n\t\t\tTypeSerializerSnapshot<SV> previousSerializerSnapshot = stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n\t\t\tcheckState(previousSerializerSnapshot != null, \"the previous serializer snapshot should exist.\");\n\t\t\tcheckState(previousSerializerSnapshot instanceof MapSerializerSnapshot, \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n\t\t\tTypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n\t\t\tcheckState(newSerializer instanceof MapSerializer, \"new serializer should be a MapSerializer.\");\n\n\t\t\tMapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n\t\t\tMapSerializerSnapshot<?, ?> mapSerializerSnapshot = (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n\t\t\tif (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n\t\t\t\tthrow new StateMigrationException(\n\t\t\t\t\t\"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n\t\t\t}\n\t\t}\n\n\t\tLOG.info(\n\t\t\t\"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n\t\t\tstateDesc);\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tStateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n\t\tif (stateFactory == null) {\n\t\t\tString message = String.format(\"State %s is not supported by %s\",\n\t\t\t\tstateDesc.getClass(), this.getClass());\n\t\t\tthrow new FlinkRuntimeException(message);\n\t\t}\n\t\tState state = stateFactory.createState(\n\t\t\tstateDesc,\n\t\t\tstateMetaInfo,\n\t\t\tRocksDBKeyedStateBackend.this);\n\t\tif (!(state instanceof AbstractRocksDBState)) {\n\t\t\tthrow new FlinkRuntimeException(\n\t\t\t\t\"State should be an AbstractRocksDBState but is \" + state);\n\t\t}\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tAbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n\t\tSnapshot rocksDBSnapshot = db.getSnapshot();\n\t\ttry (\n\t\t\tRocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n\t\t\tRocksDBWriteBatchWrapper batchWriter = new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())\n\t\t) {\n\t\t\titerator.seekToFirst();\n\n\t\t\tDataInputDeserializer serializedValueInput = new DataInputDeserializer();\n\t\t\tDataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n\t\t\twhile (iterator.isValid()) {\n\t\t\t\tserializedValueInput.setBuffer(iterator.value());\n\n\t\t\t\trocksDBState.migrateSerializedValue(\n\t\t\t\t\tserializedValueInput,\n\t\t\t\t\tmigratedSerializedValueOutput,\n\t\t\t\t\tstateMetaInfo.f1.getPreviousStateSerializer(),\n\t\t\t\t\tstateMetaInfo.f1.getStateSerializer());\n\n\t\t\t\tbatchWriter.put(stateMetaInfo.f0, iterator.key(), migratedSerializedValueOutput.getCopyOfBuffer());\n\n\t\t\t\tmigratedSerializedValueOutput.clear();\n\t\t\t\titerator.next();\n\t\t\t}\n\t\t} finally {\n\t\t\tdb.releaseSnapshot(rocksDBSnapshot);\n\t\t\trocksDBSnapshot.close();\n\t\t}\n\t}\n","date":"2020-06-26 22:24:49","endLine":649,"groupId":"8974","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"migrateStateValues","params":"(StateDescriptor<S@SV>stateDesc@Tuple2<ColumnFamilyHandle@RegisteredKeyValueStateBackendMetaInfo<N@SV>>stateMetaInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f0/cce0b2ffd7ad2f5ef6fb8fa73a89c8fc0abf0f.src","preCode":"\tprivate <N, S extends State, SV> void migrateStateValues(\n\t\tStateDescriptor<S, SV> stateDesc,\n\t\tTuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo) throws Exception {\n\n\t\tif (stateDesc.getType() == StateDescriptor.Type.MAP) {\n\t\t\tTypeSerializerSnapshot<SV> previousSerializerSnapshot = stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n\t\t\tcheckState(previousSerializerSnapshot != null, \"the previous serializer snapshot should exist.\");\n\t\t\tcheckState(previousSerializerSnapshot instanceof MapSerializerSnapshot, \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n\t\t\tTypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n\t\t\tcheckState(newSerializer instanceof MapSerializer, \"new serializer should be a MapSerializer.\");\n\n\t\t\tMapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n\t\t\tMapSerializerSnapshot<?, ?> mapSerializerSnapshot = (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n\t\t\tif (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n\t\t\t\tthrow new StateMigrationException(\n\t\t\t\t\t\"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n\t\t\t}\n\t\t}\n\n\t\tLOG.info(\n\t\t\t\"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n\t\t\tstateDesc);\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tStateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n\t\tif (stateFactory == null) {\n\t\t\tString message = String.format(\"State %s is not supported by %s\",\n\t\t\t\tstateDesc.getClass(), this.getClass());\n\t\t\tthrow new FlinkRuntimeException(message);\n\t\t}\n\t\tState state = stateFactory.createState(\n\t\t\tstateDesc,\n\t\t\tstateMetaInfo,\n\t\t\tRocksDBKeyedStateBackend.this);\n\t\tif (!(state instanceof AbstractRocksDBState)) {\n\t\t\tthrow new FlinkRuntimeException(\n\t\t\t\t\"State should be an AbstractRocksDBState but is \" + state);\n\t\t}\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tAbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n\t\tSnapshot rocksDBSnapshot = db.getSnapshot();\n\t\ttry (\n\t\t\tRocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n\t\t\tRocksDBWriteBatchWrapper batchWriter = new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())\n\t\t) {\n\t\t\titerator.seekToFirst();\n\n\t\t\tDataInputDeserializer serializedValueInput = new DataInputDeserializer();\n\t\t\tDataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n\t\t\twhile (iterator.isValid()) {\n\t\t\t\tserializedValueInput.setBuffer(iterator.value());\n\n\t\t\t\trocksDBState.migrateSerializedValue(\n\t\t\t\t\tserializedValueInput,\n\t\t\t\t\tmigratedSerializedValueOutput,\n\t\t\t\t\tstateMetaInfo.f1.getPreviousStateSerializer(),\n\t\t\t\t\tstateMetaInfo.f1.getStateSerializer());\n\n\t\t\t\tbatchWriter.put(stateMetaInfo.f0, iterator.key(), migratedSerializedValueOutput.getCopyOfBuffer());\n\n\t\t\t\tmigratedSerializedValueOutput.clear();\n\t\t\t\titerator.next();\n\t\t\t}\n\t\t} finally {\n\t\t\tdb.releaseSnapshot(rocksDBSnapshot);\n\t\t\trocksDBSnapshot.close();\n\t\t}\n\t}\n","realPath":"flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":577,"status":"N"}],"commitId":"fb3b7f76e062deb87760fe8a157ce29097576d21","commitMessage":"@@@[FLINK-21355][state/changelog] Log changes (no metadata)\n","date":"2021-06-16 16:00:53","modifiedFileCount":"11","status":"M","submitter":"Roman Khachatryan"},{"authorTime":"2020-06-05 01:16:27","codes":[{"authorDate":"2021-03-29 19:28:58","commitOrder":13,"curCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta);\n        return stateFactory.create(state, kvStateChangeLogger);\n    }\n","date":"2021-06-19 00:29:44","endLine":367,"groupId":"20603","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"createInternalState","params":"(@NonnullTypeSerializer<N>namespaceSerializer@@NonnullStateDescriptor<S@SV>stateDesc@@NonnullStateSnapshotTransformer.StateSnapshotTransformFactory<SEV>snapshotTransformFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e2/34e97db9f830ac0e50878626b29db682f8661c.src","preCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter);\n        return stateFactory.create(state, kvStateChangeLogger);\n    }\n","realPath":"flink-state-backends/flink-statebackend-changelog/src/main/java/org/apache/flink/state/changelog/ChangelogKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":331,"status":"M"},{"authorDate":"2020-06-05 01:16:27","commitOrder":13,"curCode":"\tprivate <N, S extends State, SV> void migrateStateValues(\n\t\tStateDescriptor<S, SV> stateDesc,\n\t\tTuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo) throws Exception {\n\n\t\tif (stateDesc.getType() == StateDescriptor.Type.MAP) {\n\t\t\tTypeSerializerSnapshot<SV> previousSerializerSnapshot = stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n\t\t\tcheckState(previousSerializerSnapshot != null, \"the previous serializer snapshot should exist.\");\n\t\t\tcheckState(previousSerializerSnapshot instanceof MapSerializerSnapshot, \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n\t\t\tTypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n\t\t\tcheckState(newSerializer instanceof MapSerializer, \"new serializer should be a MapSerializer.\");\n\n\t\t\tMapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n\t\t\tMapSerializerSnapshot<?, ?> mapSerializerSnapshot = (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n\t\t\tif (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n\t\t\t\tthrow new StateMigrationException(\n\t\t\t\t\t\"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n\t\t\t}\n\t\t}\n\n\t\tLOG.info(\n\t\t\t\"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n\t\t\tstateDesc);\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tStateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n\t\tif (stateFactory == null) {\n\t\t\tString message = String.format(\"State %s is not supported by %s\",\n\t\t\t\tstateDesc.getClass(), this.getClass());\n\t\t\tthrow new FlinkRuntimeException(message);\n\t\t}\n\t\tState state = stateFactory.createState(\n\t\t\tstateDesc,\n\t\t\tstateMetaInfo,\n\t\t\tRocksDBKeyedStateBackend.this);\n\t\tif (!(state instanceof AbstractRocksDBState)) {\n\t\t\tthrow new FlinkRuntimeException(\n\t\t\t\t\"State should be an AbstractRocksDBState but is \" + state);\n\t\t}\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tAbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n\t\tSnapshot rocksDBSnapshot = db.getSnapshot();\n\t\ttry (\n\t\t\tRocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n\t\t\tRocksDBWriteBatchWrapper batchWriter = new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())\n\t\t) {\n\t\t\titerator.seekToFirst();\n\n\t\t\tDataInputDeserializer serializedValueInput = new DataInputDeserializer();\n\t\t\tDataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n\t\t\twhile (iterator.isValid()) {\n\t\t\t\tserializedValueInput.setBuffer(iterator.value());\n\n\t\t\t\trocksDBState.migrateSerializedValue(\n\t\t\t\t\tserializedValueInput,\n\t\t\t\t\tmigratedSerializedValueOutput,\n\t\t\t\t\tstateMetaInfo.f1.getPreviousStateSerializer(),\n\t\t\t\t\tstateMetaInfo.f1.getStateSerializer());\n\n\t\t\t\tbatchWriter.put(stateMetaInfo.f0, iterator.key(), migratedSerializedValueOutput.getCopyOfBuffer());\n\n\t\t\t\tmigratedSerializedValueOutput.clear();\n\t\t\t\titerator.next();\n\t\t\t}\n\t\t} finally {\n\t\t\tdb.releaseSnapshot(rocksDBSnapshot);\n\t\t\trocksDBSnapshot.close();\n\t\t}\n\t}\n","date":"2020-06-26 22:24:49","endLine":649,"groupId":"8974","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"migrateStateValues","params":"(StateDescriptor<S@SV>stateDesc@Tuple2<ColumnFamilyHandle@RegisteredKeyValueStateBackendMetaInfo<N@SV>>stateMetaInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f0/cce0b2ffd7ad2f5ef6fb8fa73a89c8fc0abf0f.src","preCode":"\tprivate <N, S extends State, SV> void migrateStateValues(\n\t\tStateDescriptor<S, SV> stateDesc,\n\t\tTuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo) throws Exception {\n\n\t\tif (stateDesc.getType() == StateDescriptor.Type.MAP) {\n\t\t\tTypeSerializerSnapshot<SV> previousSerializerSnapshot = stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n\t\t\tcheckState(previousSerializerSnapshot != null, \"the previous serializer snapshot should exist.\");\n\t\t\tcheckState(previousSerializerSnapshot instanceof MapSerializerSnapshot, \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n\t\t\tTypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n\t\t\tcheckState(newSerializer instanceof MapSerializer, \"new serializer should be a MapSerializer.\");\n\n\t\t\tMapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n\t\t\tMapSerializerSnapshot<?, ?> mapSerializerSnapshot = (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n\t\t\tif (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n\t\t\t\tthrow new StateMigrationException(\n\t\t\t\t\t\"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n\t\t\t}\n\t\t}\n\n\t\tLOG.info(\n\t\t\t\"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n\t\t\tstateDesc);\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tStateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n\t\tif (stateFactory == null) {\n\t\t\tString message = String.format(\"State %s is not supported by %s\",\n\t\t\t\tstateDesc.getClass(), this.getClass());\n\t\t\tthrow new FlinkRuntimeException(message);\n\t\t}\n\t\tState state = stateFactory.createState(\n\t\t\tstateDesc,\n\t\t\tstateMetaInfo,\n\t\t\tRocksDBKeyedStateBackend.this);\n\t\tif (!(state instanceof AbstractRocksDBState)) {\n\t\t\tthrow new FlinkRuntimeException(\n\t\t\t\t\"State should be an AbstractRocksDBState but is \" + state);\n\t\t}\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tAbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n\t\tSnapshot rocksDBSnapshot = db.getSnapshot();\n\t\ttry (\n\t\t\tRocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n\t\t\tRocksDBWriteBatchWrapper batchWriter = new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())\n\t\t) {\n\t\t\titerator.seekToFirst();\n\n\t\t\tDataInputDeserializer serializedValueInput = new DataInputDeserializer();\n\t\t\tDataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n\t\t\twhile (iterator.isValid()) {\n\t\t\t\tserializedValueInput.setBuffer(iterator.value());\n\n\t\t\t\trocksDBState.migrateSerializedValue(\n\t\t\t\t\tserializedValueInput,\n\t\t\t\t\tmigratedSerializedValueOutput,\n\t\t\t\t\tstateMetaInfo.f1.getPreviousStateSerializer(),\n\t\t\t\t\tstateMetaInfo.f1.getStateSerializer());\n\n\t\t\t\tbatchWriter.put(stateMetaInfo.f0, iterator.key(), migratedSerializedValueOutput.getCopyOfBuffer());\n\n\t\t\t\tmigratedSerializedValueOutput.clear();\n\t\t\t\titerator.next();\n\t\t\t}\n\t\t} finally {\n\t\t\tdb.releaseSnapshot(rocksDBSnapshot);\n\t\t\trocksDBSnapshot.close();\n\t\t}\n\t}\n","realPath":"flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":577,"status":"N"}],"commitId":"b31f4bde84caa4664cfa305f7890c9a35ff43821","commitMessage":"@@@[FLINK-22808][state/changelog] Log metadata\n","date":"2021-06-19 00:29:44","modifiedFileCount":"4","status":"M","submitter":"Roman Khachatryan"},{"authorTime":"2021-06-17 16:28:02","codes":[{"authorDate":"2021-06-17 16:28:02","commitOrder":14,"curCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta);\n        return stateFactory.create(state, kvStateChangeLogger);\n    }\n","date":"2021-06-21 10:50:44","endLine":362,"groupId":"20603","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"createInternalState","params":"(@NonnullTypeSerializer<N>namespaceSerializer@@NonnullStateDescriptor<S@SV>stateDesc@@NonnullStateSnapshotTransformer.StateSnapshotTransformFactory<SEV>snapshotTransformFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ab/e7568228e7bf99efefbf84b6de3499fd131362.src","preCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta);\n        return stateFactory.create(state, kvStateChangeLogger);\n    }\n","realPath":"flink-state-backends/flink-statebackend-changelog/src/main/java/org/apache/flink/state/changelog/ChangelogKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":326,"status":"M"},{"authorDate":"2021-06-17 16:28:02","commitOrder":14,"curCode":"    private <N, S extends State, SV> void migrateStateValues(\n            StateDescriptor<S, SV> stateDesc,\n            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n            throws Exception {\n\n        if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n            TypeSerializerSnapshot<SV> previousSerializerSnapshot =\n                    stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n            checkState(\n                    previousSerializerSnapshot != null,\n                    \"the previous serializer snapshot should exist.\");\n            checkState(\n                    previousSerializerSnapshot instanceof MapSerializerSnapshot,\n                    \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n            TypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n            checkState(\n                    newSerializer instanceof MapSerializer,\n                    \"new serializer should be a MapSerializer.\");\n\n            MapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n            MapSerializerSnapshot<?, ?> mapSerializerSnapshot =\n                    (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n            if (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n                throw new StateMigrationException(\n                        \"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n            }\n        }\n\n        LOG.info(\n                \"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n                stateDesc);\n\n        \r\n        \r\n        \r\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        State state =\n                stateFactory.createState(stateDesc, stateMetaInfo, RocksDBKeyedStateBackend.this);\n        if (!(state instanceof AbstractRocksDBState)) {\n            throw new FlinkRuntimeException(\n                    \"State should be an AbstractRocksDBState but is \" + state);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n        Snapshot rocksDBSnapshot = db.getSnapshot();\n        try (RocksIteratorWrapper iterator =\n                        RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                RocksDBWriteBatchWrapper batchWriter =\n                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n            iterator.seekToFirst();\n\n            DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n            DataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n            while (iterator.isValid()) {\n                serializedValueInput.setBuffer(iterator.value());\n\n                rocksDBState.migrateSerializedValue(\n                        serializedValueInput,\n                        migratedSerializedValueOutput,\n                        stateMetaInfo.f1.getPreviousStateSerializer(),\n                        stateMetaInfo.f1.getStateSerializer());\n\n                batchWriter.put(\n                        stateMetaInfo.f0,\n                        iterator.key(),\n                        migratedSerializedValueOutput.getCopyOfBuffer());\n\n                migratedSerializedValueOutput.clear();\n                iterator.next();\n            }\n        } finally {\n            db.releaseSnapshot(rocksDBSnapshot);\n            rocksDBSnapshot.close();\n        }\n    }\n","date":"2021-06-21 10:50:44","endLine":805,"groupId":"20603","id":8,"instanceNumber":2,"isCurCommit":1,"methodName":"migrateStateValues","params":"(StateDescriptor<S@SV>stateDesc@Tuple2<ColumnFamilyHandle@RegisteredKeyValueStateBackendMetaInfo<N@SV>>stateMetaInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ea/83250b5dd4dea8c26ee9f3bea8d955cce239d0.src","preCode":"    private <N, S extends State, SV> void migrateStateValues(\n            StateDescriptor<S, SV> stateDesc,\n            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n            throws Exception {\n\n        if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n            TypeSerializerSnapshot<SV> previousSerializerSnapshot =\n                    stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n            checkState(\n                    previousSerializerSnapshot != null,\n                    \"the previous serializer snapshot should exist.\");\n            checkState(\n                    previousSerializerSnapshot instanceof MapSerializerSnapshot,\n                    \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n            TypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n            checkState(\n                    newSerializer instanceof MapSerializer,\n                    \"new serializer should be a MapSerializer.\");\n\n            MapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n            MapSerializerSnapshot<?, ?> mapSerializerSnapshot =\n                    (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n            if (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n                throw new StateMigrationException(\n                        \"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n            }\n        }\n\n        LOG.info(\n                \"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n                stateDesc);\n\n        \r\n        \r\n        \r\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getClass());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        State state =\n                stateFactory.createState(stateDesc, stateMetaInfo, RocksDBKeyedStateBackend.this);\n        if (!(state instanceof AbstractRocksDBState)) {\n            throw new FlinkRuntimeException(\n                    \"State should be an AbstractRocksDBState but is \" + state);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n        Snapshot rocksDBSnapshot = db.getSnapshot();\n        try (RocksIteratorWrapper iterator =\n                        RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                RocksDBWriteBatchWrapper batchWriter =\n                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n            iterator.seekToFirst();\n\n            DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n            DataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n            while (iterator.isValid()) {\n                serializedValueInput.setBuffer(iterator.value());\n\n                rocksDBState.migrateSerializedValue(\n                        serializedValueInput,\n                        migratedSerializedValueOutput,\n                        stateMetaInfo.f1.getPreviousStateSerializer(),\n                        stateMetaInfo.f1.getStateSerializer());\n\n                batchWriter.put(\n                        stateMetaInfo.f0,\n                        iterator.key(),\n                        migratedSerializedValueOutput.getCopyOfBuffer());\n\n                migratedSerializedValueOutput.clear();\n                iterator.next();\n            }\n        } finally {\n            db.releaseSnapshot(rocksDBSnapshot);\n            rocksDBSnapshot.close();\n        }\n    }\n","realPath":"flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":721,"status":"M"}],"commitId":"73c103b6b117fe3996eedfb9d04e926f00c70996","commitMessage":"@@@[FLINK-23018][state] Enable state factories to handle extended state descriptors\n","date":"2021-06-21 10:50:44","modifiedFileCount":"7","status":"M","submitter":"Yun Tang"},{"authorTime":"2021-06-17 16:28:02","codes":[{"authorDate":"2021-06-04 00:32:37","commitOrder":15,"curCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta);\n        return stateFactory.create(\n                state,\n                kvStateChangeLogger,\n                keyedStateBackend );\n    }\n","date":"2021-06-30 04:52:13","endLine":493,"groupId":"20603","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"createInternalState","params":"(@NonnullTypeSerializer<N>namespaceSerializer@@NonnullStateDescriptor<S@SV>stateDesc@@NonnullStateSnapshotTransformer.StateSnapshotTransformFactory<SEV>snapshotTransformFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f7/a83f09429260c5d3186cb8a6979aaf075940e1.src","preCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta);\n        return stateFactory.create(state, kvStateChangeLogger);\n    }\n","realPath":"flink-state-backends/flink-statebackend-changelog/src/main/java/org/apache/flink/state/changelog/ChangelogKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":454,"status":"M"},{"authorDate":"2021-06-17 16:28:02","commitOrder":15,"curCode":"    private <N, S extends State, SV> void migrateStateValues(\n            StateDescriptor<S, SV> stateDesc,\n            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n            throws Exception {\n\n        if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n            TypeSerializerSnapshot<SV> previousSerializerSnapshot =\n                    stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n            checkState(\n                    previousSerializerSnapshot != null,\n                    \"the previous serializer snapshot should exist.\");\n            checkState(\n                    previousSerializerSnapshot instanceof MapSerializerSnapshot,\n                    \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n            TypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n            checkState(\n                    newSerializer instanceof MapSerializer,\n                    \"new serializer should be a MapSerializer.\");\n\n            MapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n            MapSerializerSnapshot<?, ?> mapSerializerSnapshot =\n                    (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n            if (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n                throw new StateMigrationException(\n                        \"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n            }\n        }\n\n        LOG.info(\n                \"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n                stateDesc);\n\n        \r\n        \r\n        \r\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        State state =\n                stateFactory.createState(stateDesc, stateMetaInfo, RocksDBKeyedStateBackend.this);\n        if (!(state instanceof AbstractRocksDBState)) {\n            throw new FlinkRuntimeException(\n                    \"State should be an AbstractRocksDBState but is \" + state);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n        Snapshot rocksDBSnapshot = db.getSnapshot();\n        try (RocksIteratorWrapper iterator =\n                        RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                RocksDBWriteBatchWrapper batchWriter =\n                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n            iterator.seekToFirst();\n\n            DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n            DataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n            while (iterator.isValid()) {\n                serializedValueInput.setBuffer(iterator.value());\n\n                rocksDBState.migrateSerializedValue(\n                        serializedValueInput,\n                        migratedSerializedValueOutput,\n                        stateMetaInfo.f1.getPreviousStateSerializer(),\n                        stateMetaInfo.f1.getStateSerializer());\n\n                batchWriter.put(\n                        stateMetaInfo.f0,\n                        iterator.key(),\n                        migratedSerializedValueOutput.getCopyOfBuffer());\n\n                migratedSerializedValueOutput.clear();\n                iterator.next();\n            }\n        } finally {\n            db.releaseSnapshot(rocksDBSnapshot);\n            rocksDBSnapshot.close();\n        }\n    }\n","date":"2021-06-21 10:50:44","endLine":805,"groupId":"20603","id":10,"instanceNumber":2,"isCurCommit":1,"methodName":"migrateStateValues","params":"(StateDescriptor<S@SV>stateDesc@Tuple2<ColumnFamilyHandle@RegisteredKeyValueStateBackendMetaInfo<N@SV>>stateMetaInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ea/83250b5dd4dea8c26ee9f3bea8d955cce239d0.src","preCode":"    private <N, S extends State, SV> void migrateStateValues(\n            StateDescriptor<S, SV> stateDesc,\n            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n            throws Exception {\n\n        if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n            TypeSerializerSnapshot<SV> previousSerializerSnapshot =\n                    stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n            checkState(\n                    previousSerializerSnapshot != null,\n                    \"the previous serializer snapshot should exist.\");\n            checkState(\n                    previousSerializerSnapshot instanceof MapSerializerSnapshot,\n                    \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n            TypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n            checkState(\n                    newSerializer instanceof MapSerializer,\n                    \"new serializer should be a MapSerializer.\");\n\n            MapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n            MapSerializerSnapshot<?, ?> mapSerializerSnapshot =\n                    (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n            if (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n                throw new StateMigrationException(\n                        \"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n            }\n        }\n\n        LOG.info(\n                \"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n                stateDesc);\n\n        \r\n        \r\n        \r\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        State state =\n                stateFactory.createState(stateDesc, stateMetaInfo, RocksDBKeyedStateBackend.this);\n        if (!(state instanceof AbstractRocksDBState)) {\n            throw new FlinkRuntimeException(\n                    \"State should be an AbstractRocksDBState but is \" + state);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n        Snapshot rocksDBSnapshot = db.getSnapshot();\n        try (RocksIteratorWrapper iterator =\n                        RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                RocksDBWriteBatchWrapper batchWriter =\n                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n            iterator.seekToFirst();\n\n            DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n            DataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n            while (iterator.isValid()) {\n                serializedValueInput.setBuffer(iterator.value());\n\n                rocksDBState.migrateSerializedValue(\n                        serializedValueInput,\n                        migratedSerializedValueOutput,\n                        stateMetaInfo.f1.getPreviousStateSerializer(),\n                        stateMetaInfo.f1.getStateSerializer());\n\n                batchWriter.put(\n                        stateMetaInfo.f0,\n                        iterator.key(),\n                        migratedSerializedValueOutput.getCopyOfBuffer());\n\n                migratedSerializedValueOutput.clear();\n                iterator.next();\n            }\n        } finally {\n            db.releaseSnapshot(rocksDBSnapshot);\n            rocksDBSnapshot.close();\n        }\n    }\n","realPath":"flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":721,"status":"N"}],"commitId":"fe5df06c727138ef02359aa3b23ef0e4b80a57df","commitMessage":"@@@[FLINK-21356][state/changelog] Implement recovery using changelog\n\nBoth materialized and non-materialized states are read for recovery.\n\nMaterialization will be implemented in subsequent commits.\nFor now.  changelog grows indefinitely.\n","date":"2021-06-30 04:52:13","modifiedFileCount":"20","status":"M","submitter":"Roman Khachatryan"},{"authorTime":"2021-06-17 16:28:02","codes":[{"authorDate":"2021-07-06 07:01:57","commitOrder":16,"curCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta,\n                        stateDesc.getTtlConfig());\n        IS is =\n                stateFactory.create(\n                        state,\n                        kvStateChangeLogger,\n                        keyedStateBackend );\n        changelogStates.put(stateDesc.getName(), (ChangelogState) is);\n        return is;\n    }\n","date":"2021-07-09 20:08:34","endLine":506,"groupId":"20603","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"createInternalState","params":"(@NonnullTypeSerializer<N>namespaceSerializer@@NonnullStateDescriptor<S@SV>stateDesc@@NonnullStateSnapshotTransformer.StateSnapshotTransformFactory<SEV>snapshotTransformFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/bf0fe45d74aa68e03203eb96b053ded9994284.src","preCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta);\n        return stateFactory.create(\n                state,\n                kvStateChangeLogger,\n                keyedStateBackend );\n    }\n","realPath":"flink-state-backends/flink-statebackend-changelog/src/main/java/org/apache/flink/state/changelog/ChangelogKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":463,"status":"M"},{"authorDate":"2021-06-17 16:28:02","commitOrder":16,"curCode":"    private <N, S extends State, SV> void migrateStateValues(\n            StateDescriptor<S, SV> stateDesc,\n            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n            throws Exception {\n\n        if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n            TypeSerializerSnapshot<SV> previousSerializerSnapshot =\n                    stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n            checkState(\n                    previousSerializerSnapshot != null,\n                    \"the previous serializer snapshot should exist.\");\n            checkState(\n                    previousSerializerSnapshot instanceof MapSerializerSnapshot,\n                    \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n            TypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n            checkState(\n                    newSerializer instanceof MapSerializer,\n                    \"new serializer should be a MapSerializer.\");\n\n            MapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n            MapSerializerSnapshot<?, ?> mapSerializerSnapshot =\n                    (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n            if (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n                throw new StateMigrationException(\n                        \"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n            }\n        }\n\n        LOG.info(\n                \"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n                stateDesc);\n\n        \r\n        \r\n        \r\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        State state =\n                stateFactory.createState(stateDesc, stateMetaInfo, RocksDBKeyedStateBackend.this);\n        if (!(state instanceof AbstractRocksDBState)) {\n            throw new FlinkRuntimeException(\n                    \"State should be an AbstractRocksDBState but is \" + state);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n        Snapshot rocksDBSnapshot = db.getSnapshot();\n        try (RocksIteratorWrapper iterator =\n                        RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                RocksDBWriteBatchWrapper batchWriter =\n                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n            iterator.seekToFirst();\n\n            DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n            DataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n            while (iterator.isValid()) {\n                serializedValueInput.setBuffer(iterator.value());\n\n                rocksDBState.migrateSerializedValue(\n                        serializedValueInput,\n                        migratedSerializedValueOutput,\n                        stateMetaInfo.f1.getPreviousStateSerializer(),\n                        stateMetaInfo.f1.getStateSerializer());\n\n                batchWriter.put(\n                        stateMetaInfo.f0,\n                        iterator.key(),\n                        migratedSerializedValueOutput.getCopyOfBuffer());\n\n                migratedSerializedValueOutput.clear();\n                iterator.next();\n            }\n        } finally {\n            db.releaseSnapshot(rocksDBSnapshot);\n            rocksDBSnapshot.close();\n        }\n    }\n","date":"2021-06-21 10:50:44","endLine":805,"groupId":"20603","id":12,"instanceNumber":2,"isCurCommit":1,"methodName":"migrateStateValues","params":"(StateDescriptor<S@SV>stateDesc@Tuple2<ColumnFamilyHandle@RegisteredKeyValueStateBackendMetaInfo<N@SV>>stateMetaInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ea/83250b5dd4dea8c26ee9f3bea8d955cce239d0.src","preCode":"    private <N, S extends State, SV> void migrateStateValues(\n            StateDescriptor<S, SV> stateDesc,\n            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n            throws Exception {\n\n        if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n            TypeSerializerSnapshot<SV> previousSerializerSnapshot =\n                    stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n            checkState(\n                    previousSerializerSnapshot != null,\n                    \"the previous serializer snapshot should exist.\");\n            checkState(\n                    previousSerializerSnapshot instanceof MapSerializerSnapshot,\n                    \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n            TypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n            checkState(\n                    newSerializer instanceof MapSerializer,\n                    \"new serializer should be a MapSerializer.\");\n\n            MapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n            MapSerializerSnapshot<?, ?> mapSerializerSnapshot =\n                    (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n            if (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n                throw new StateMigrationException(\n                        \"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n            }\n        }\n\n        LOG.info(\n                \"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n                stateDesc);\n\n        \r\n        \r\n        \r\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        State state =\n                stateFactory.createState(stateDesc, stateMetaInfo, RocksDBKeyedStateBackend.this);\n        if (!(state instanceof AbstractRocksDBState)) {\n            throw new FlinkRuntimeException(\n                    \"State should be an AbstractRocksDBState but is \" + state);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n        Snapshot rocksDBSnapshot = db.getSnapshot();\n        try (RocksIteratorWrapper iterator =\n                        RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                RocksDBWriteBatchWrapper batchWriter =\n                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n            iterator.seekToFirst();\n\n            DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n            DataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n            while (iterator.isValid()) {\n                serializedValueInput.setBuffer(iterator.value());\n\n                rocksDBState.migrateSerializedValue(\n                        serializedValueInput,\n                        migratedSerializedValueOutput,\n                        stateMetaInfo.f1.getPreviousStateSerializer(),\n                        stateMetaInfo.f1.getStateSerializer());\n\n                batchWriter.put(\n                        stateMetaInfo.f0,\n                        iterator.key(),\n                        migratedSerializedValueOutput.getCopyOfBuffer());\n\n                migratedSerializedValueOutput.clear();\n                iterator.next();\n            }\n        } finally {\n            db.releaseSnapshot(rocksDBSnapshot);\n            rocksDBSnapshot.close();\n        }\n    }\n","realPath":"flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":721,"status":"N"}],"commitId":"f2eb6559ba87d1de0c6a5e18ba15bc55dae135f8","commitMessage":"@@@[FLINK-23277][state/changelog] Store and recover TTL metadata using changelog\n\nUpon recovery.  changelog backend creates underlying states to apply changes.\nTTL config is not available at that moment.  so states are currently created\nregardless of job TTL settings.\n\nThis change stores TTL config along with metadata (in changelog); and\nuses it on recovery.\n\nNote: values are already serialized as TTL values and serializers as TTL seralizers\nNote: upgrading TTL settings is not possible (see FLINK-23143)\n","date":"2021-07-09 20:08:34","modifiedFileCount":"6","status":"M","submitter":"Roman Khachatryan"},{"authorTime":"2021-06-17 16:28:02","codes":[{"authorDate":"2021-08-04 15:51:26","commitOrder":17,"curCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta,\n                        stateDesc.getTtlConfig(),\n                        stateDesc.getDefaultValue());\n        IS is =\n                stateFactory.create(\n                        state,\n                        kvStateChangeLogger,\n                        keyedStateBackend );\n        changelogStates.put(stateDesc.getName(), (ChangelogState) is);\n        return is;\n    }\n","date":"2021-08-07 21:20:19","endLine":517,"groupId":"1090","id":13,"instanceNumber":1,"isCurCommit":1,"methodName":"createInternalState","params":"(@NonnullTypeSerializer<N>namespaceSerializer@@NonnullStateDescriptor<S@SV>stateDesc@@NonnullStateSnapshotTransformer.StateSnapshotTransformFactory<SEV>snapshotTransformFactory)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/4d/e278ff6451778c2d36ceb3cdca4523c55020cb.src","preCode":"    public <N, SV, SEV, S extends State, IS extends S> IS createInternalState(\n            @Nonnull TypeSerializer<N> namespaceSerializer,\n            @Nonnull StateDescriptor<S, SV> stateDesc,\n            @Nonnull\n                    StateSnapshotTransformer.StateSnapshotTransformFactory<SEV>\n                            snapshotTransformFactory)\n            throws Exception {\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        RegisteredKeyValueStateBackendMetaInfo<N, SV> meta =\n                new RegisteredKeyValueStateBackendMetaInfo<>(\n                        stateDesc.getType(),\n                        stateDesc.getName(),\n                        namespaceSerializer,\n                        stateDesc.getSerializer(),\n                        (StateSnapshotTransformer.StateSnapshotTransformFactory<SV>)\n                                snapshotTransformFactory);\n\n        InternalKvState<K, N, SV> state =\n                keyedStateBackend.createInternalState(\n                        namespaceSerializer, stateDesc, snapshotTransformFactory);\n        KvStateChangeLoggerImpl<K, SV, N> kvStateChangeLogger =\n                new KvStateChangeLoggerImpl<>(\n                        state.getKeySerializer(),\n                        state.getNamespaceSerializer(),\n                        state.getValueSerializer(),\n                        keyedStateBackend.getKeyContext(),\n                        stateChangelogWriter,\n                        meta,\n                        stateDesc.getTtlConfig());\n        IS is =\n                stateFactory.create(\n                        state,\n                        kvStateChangeLogger,\n                        keyedStateBackend );\n        changelogStates.put(stateDesc.getName(), (ChangelogState) is);\n        return is;\n    }\n","realPath":"flink-state-backends/flink-statebackend-changelog/src/main/java/org/apache/flink/state/changelog/ChangelogKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":473,"status":"M"},{"authorDate":"2021-06-17 16:28:02","commitOrder":17,"curCode":"    private <N, S extends State, SV> void migrateStateValues(\n            StateDescriptor<S, SV> stateDesc,\n            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n            throws Exception {\n\n        if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n            TypeSerializerSnapshot<SV> previousSerializerSnapshot =\n                    stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n            checkState(\n                    previousSerializerSnapshot != null,\n                    \"the previous serializer snapshot should exist.\");\n            checkState(\n                    previousSerializerSnapshot instanceof MapSerializerSnapshot,\n                    \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n            TypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n            checkState(\n                    newSerializer instanceof MapSerializer,\n                    \"new serializer should be a MapSerializer.\");\n\n            MapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n            MapSerializerSnapshot<?, ?> mapSerializerSnapshot =\n                    (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n            if (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n                throw new StateMigrationException(\n                        \"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n            }\n        }\n\n        LOG.info(\n                \"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n                stateDesc);\n\n        \r\n        \r\n        \r\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        State state =\n                stateFactory.createState(stateDesc, stateMetaInfo, RocksDBKeyedStateBackend.this);\n        if (!(state instanceof AbstractRocksDBState)) {\n            throw new FlinkRuntimeException(\n                    \"State should be an AbstractRocksDBState but is \" + state);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n        Snapshot rocksDBSnapshot = db.getSnapshot();\n        try (RocksIteratorWrapper iterator =\n                        RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                RocksDBWriteBatchWrapper batchWriter =\n                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n            iterator.seekToFirst();\n\n            DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n            DataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n            while (iterator.isValid()) {\n                serializedValueInput.setBuffer(iterator.value());\n\n                rocksDBState.migrateSerializedValue(\n                        serializedValueInput,\n                        migratedSerializedValueOutput,\n                        stateMetaInfo.f1.getPreviousStateSerializer(),\n                        stateMetaInfo.f1.getStateSerializer());\n\n                batchWriter.put(\n                        stateMetaInfo.f0,\n                        iterator.key(),\n                        migratedSerializedValueOutput.getCopyOfBuffer());\n\n                migratedSerializedValueOutput.clear();\n                iterator.next();\n            }\n        } finally {\n            db.releaseSnapshot(rocksDBSnapshot);\n            rocksDBSnapshot.close();\n        }\n    }\n","date":"2021-06-21 10:50:44","endLine":805,"groupId":"1090","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"migrateStateValues","params":"(StateDescriptor<S@SV>stateDesc@Tuple2<ColumnFamilyHandle@RegisteredKeyValueStateBackendMetaInfo<N@SV>>stateMetaInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ea/83250b5dd4dea8c26ee9f3bea8d955cce239d0.src","preCode":"    private <N, S extends State, SV> void migrateStateValues(\n            StateDescriptor<S, SV> stateDesc,\n            Tuple2<ColumnFamilyHandle, RegisteredKeyValueStateBackendMetaInfo<N, SV>> stateMetaInfo)\n            throws Exception {\n\n        if (stateDesc.getType() == StateDescriptor.Type.MAP) {\n            TypeSerializerSnapshot<SV> previousSerializerSnapshot =\n                    stateMetaInfo.f1.getPreviousStateSerializerSnapshot();\n            checkState(\n                    previousSerializerSnapshot != null,\n                    \"the previous serializer snapshot should exist.\");\n            checkState(\n                    previousSerializerSnapshot instanceof MapSerializerSnapshot,\n                    \"previous serializer snapshot should be a MapSerializerSnapshot.\");\n\n            TypeSerializer<SV> newSerializer = stateMetaInfo.f1.getStateSerializer();\n            checkState(\n                    newSerializer instanceof MapSerializer,\n                    \"new serializer should be a MapSerializer.\");\n\n            MapSerializer<?, ?> mapSerializer = (MapSerializer<?, ?>) newSerializer;\n            MapSerializerSnapshot<?, ?> mapSerializerSnapshot =\n                    (MapSerializerSnapshot<?, ?>) previousSerializerSnapshot;\n            if (!checkMapStateKeySchemaCompatibility(mapSerializerSnapshot, mapSerializer)) {\n                throw new StateMigrationException(\n                        \"The new serializer for a MapState requires state migration in order for the job to proceed, since the key schema has changed. However, migration for MapState currently only allows value schema evolutions.\");\n            }\n        }\n\n        LOG.info(\n                \"Performing state migration for state {} because the state serializer's schema, i.e. serialization format, has changed.\",\n                stateDesc);\n\n        \r\n        \r\n        \r\n        StateFactory stateFactory = STATE_FACTORIES.get(stateDesc.getType());\n        if (stateFactory == null) {\n            String message =\n                    String.format(\n                            \"State %s is not supported by %s\",\n                            stateDesc.getClass(), this.getClass());\n            throw new FlinkRuntimeException(message);\n        }\n        State state =\n                stateFactory.createState(stateDesc, stateMetaInfo, RocksDBKeyedStateBackend.this);\n        if (!(state instanceof AbstractRocksDBState)) {\n            throw new FlinkRuntimeException(\n                    \"State should be an AbstractRocksDBState but is \" + state);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        AbstractRocksDBState<?, ?, SV> rocksDBState = (AbstractRocksDBState<?, ?, SV>) state;\n\n        Snapshot rocksDBSnapshot = db.getSnapshot();\n        try (RocksIteratorWrapper iterator =\n                        RocksDBOperationUtils.getRocksIterator(db, stateMetaInfo.f0, readOptions);\n                RocksDBWriteBatchWrapper batchWriter =\n                        new RocksDBWriteBatchWrapper(db, getWriteOptions(), getWriteBatchSize())) {\n            iterator.seekToFirst();\n\n            DataInputDeserializer serializedValueInput = new DataInputDeserializer();\n            DataOutputSerializer migratedSerializedValueOutput = new DataOutputSerializer(512);\n            while (iterator.isValid()) {\n                serializedValueInput.setBuffer(iterator.value());\n\n                rocksDBState.migrateSerializedValue(\n                        serializedValueInput,\n                        migratedSerializedValueOutput,\n                        stateMetaInfo.f1.getPreviousStateSerializer(),\n                        stateMetaInfo.f1.getStateSerializer());\n\n                batchWriter.put(\n                        stateMetaInfo.f0,\n                        iterator.key(),\n                        migratedSerializedValueOutput.getCopyOfBuffer());\n\n                migratedSerializedValueOutput.clear();\n                iterator.next();\n            }\n        } finally {\n            db.releaseSnapshot(rocksDBSnapshot);\n            rocksDBSnapshot.close();\n        }\n    }\n","realPath":"flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBKeyedStateBackend.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":721,"status":"N"}],"commitId":"e8daf67ce5096da791e21d0915848c78c395822d","commitMessage":"@@@[hotfix][state/changelog] Persist and restore default value\n\nThe default value of ValueState is currently always\nrestored to null by the ChangelogStateBackend.\n\nThis change writes it along with metadata and uses on recovery.\n","date":"2021-08-07 21:20:19","modifiedFileCount":"7","status":"M","submitter":"Roman Khachatryan"}]
