[{"authorTime":"2020-09-25 22:50:09","codes":[{"authorDate":"2020-09-25 22:50:09","commitOrder":1,"curCode":"\tprivate static RowFieldConverter createRowFieldConverter(LogicalType fieldType) {\n\t\tswitch (fieldType.getTypeRoot()) {\n\t\t\tcase NULL:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.nullNode();\n\t\t\tcase BOOLEAN:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.booleanNode(row.getBoolean(pos));\n\t\t\tcase TINYINT:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getByte(pos));\n\t\t\tcase SMALLINT:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getShort(pos));\n\t\t\tcase INTEGER:\n\t\t\tcase INTERVAL_YEAR_MONTH:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getInt(pos));\n\t\t\tcase BIGINT:\n\t\t\tcase INTERVAL_DAY_TIME:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getLong(pos));\n\t\t\tcase FLOAT:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getFloat(pos));\n\t\t\tcase DOUBLE:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getDouble(pos));\n\t\t\tcase CHAR:\n\t\t\tcase VARCHAR:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.textNode(row.getString(pos).toString());\n\t\t\tcase BINARY:\n\t\t\tcase VARBINARY:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.binaryNode(row.getBinary(pos));\n\t\t\tcase DATE:\n\t\t\t\treturn (csvMapper, container, row, pos) -> convertDate(row.getInt(pos), container);\n\t\t\tcase TIME_WITHOUT_TIME_ZONE:\n\t\t\t\treturn (csvMapper, container, row, pos) -> convertTime(row.getInt(pos), container);\n\t\t\tcase TIMESTAMP_WITH_TIME_ZONE:\n\t\t\t\tfinal int zonedTimestampPrecision = ((LocalZonedTimestampType) fieldType).getPrecision();\n\t\t\t\treturn (csvMapper, container, row, pos) ->\n\t\t\t\t\tconvertTimestamp(row.getTimestamp(pos, zonedTimestampPrecision), container);\n\t\t\tcase TIMESTAMP_WITHOUT_TIME_ZONE:\n\t\t\t\tfinal int timestampPrecision = ((TimestampType) fieldType).getPrecision();\n\t\t\t\treturn (csvMapper, container, row, pos) ->\n\t\t\t\t\tconvertTimestamp(row.getTimestamp(pos, timestampPrecision), container);\n\t\t\tcase DECIMAL:\n\t\t\t\treturn createDecimalRowFieldConverter((DecimalType) fieldType);\n\t\t\tcase ARRAY:\n\t\t\t\treturn createArrayRowFieldConverter((ArrayType) fieldType);\n\t\t\tcase ROW:\n\t\t\t\treturn createRowRowFieldConverter((RowType) fieldType);\n\t\t\tcase MAP:\n\t\t\tcase MULTISET:\n\t\t\tcase RAW:\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException(\"Unsupported type: \" + fieldType);\n\t\t}\n\t}\n","date":"2020-09-25 22:50:09","endLine":152,"groupId":"10371","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"createRowFieldConverter","params":"(LogicalTypefieldType)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6a/b7f74fe6cb3d2a459b12b1757d08f7f79a8ca1.src","preCode":"\tprivate static RowFieldConverter createRowFieldConverter(LogicalType fieldType) {\n\t\tswitch (fieldType.getTypeRoot()) {\n\t\t\tcase NULL:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.nullNode();\n\t\t\tcase BOOLEAN:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.booleanNode(row.getBoolean(pos));\n\t\t\tcase TINYINT:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getByte(pos));\n\t\t\tcase SMALLINT:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getShort(pos));\n\t\t\tcase INTEGER:\n\t\t\tcase INTERVAL_YEAR_MONTH:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getInt(pos));\n\t\t\tcase BIGINT:\n\t\t\tcase INTERVAL_DAY_TIME:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getLong(pos));\n\t\t\tcase FLOAT:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getFloat(pos));\n\t\t\tcase DOUBLE:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.numberNode(row.getDouble(pos));\n\t\t\tcase CHAR:\n\t\t\tcase VARCHAR:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.textNode(row.getString(pos).toString());\n\t\t\tcase BINARY:\n\t\t\tcase VARBINARY:\n\t\t\t\treturn (csvMapper, container, row, pos) -> container.binaryNode(row.getBinary(pos));\n\t\t\tcase DATE:\n\t\t\t\treturn (csvMapper, container, row, pos) -> convertDate(row.getInt(pos), container);\n\t\t\tcase TIME_WITHOUT_TIME_ZONE:\n\t\t\t\treturn (csvMapper, container, row, pos) -> convertTime(row.getInt(pos), container);\n\t\t\tcase TIMESTAMP_WITH_TIME_ZONE:\n\t\t\t\tfinal int zonedTimestampPrecision = ((LocalZonedTimestampType) fieldType).getPrecision();\n\t\t\t\treturn (csvMapper, container, row, pos) ->\n\t\t\t\t\tconvertTimestamp(row.getTimestamp(pos, zonedTimestampPrecision), container);\n\t\t\tcase TIMESTAMP_WITHOUT_TIME_ZONE:\n\t\t\t\tfinal int timestampPrecision = ((TimestampType) fieldType).getPrecision();\n\t\t\t\treturn (csvMapper, container, row, pos) ->\n\t\t\t\t\tconvertTimestamp(row.getTimestamp(pos, timestampPrecision), container);\n\t\t\tcase DECIMAL:\n\t\t\t\treturn createDecimalRowFieldConverter((DecimalType) fieldType);\n\t\t\tcase ARRAY:\n\t\t\t\treturn createArrayRowFieldConverter((ArrayType) fieldType);\n\t\t\tcase ROW:\n\t\t\t\treturn createRowRowFieldConverter((RowType) fieldType);\n\t\t\tcase MAP:\n\t\t\tcase MULTISET:\n\t\t\tcase RAW:\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException(\"Unsupported type: \" + fieldType);\n\t\t}\n\t}\n","realPath":"flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"B"},{"authorDate":"2020-09-25 22:50:09","commitOrder":1,"curCode":"\tprivate static ArrayElementConverter createDecimalArrayElementConverter(DecimalType decimalType) {\n\t\tfinal int precision = decimalType.getPrecision();\n\t\tfinal int scale = decimalType.getScale();\n\t\treturn (csvMapper, container, array, pos) -> {\n\t\t\tDecimalData decimal = array.getDecimal(pos, precision, scale);\n\t\t\treturn convertDecimal(decimal, container);\n\t\t};\n\t}\n","date":"2020-09-25 22:50:09","endLine":235,"groupId":"10368","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createDecimalArrayElementConverter","params":"(DecimalTypedecimalType)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6a/b7f74fe6cb3d2a459b12b1757d08f7f79a8ca1.src","preCode":"\tprivate static ArrayElementConverter createDecimalArrayElementConverter(DecimalType decimalType) {\n\t\tfinal int precision = decimalType.getPrecision();\n\t\tfinal int scale = decimalType.getScale();\n\t\treturn (csvMapper, container, array, pos) -> {\n\t\t\tDecimalData decimal = array.getDecimal(pos, precision, scale);\n\t\t\treturn convertDecimal(decimal, container);\n\t\t};\n\t}\n","realPath":"flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":228,"status":"B"}],"commitId":"ef4d997756756bf0e1e722af8a3fcd6995f37dc8","commitMessage":"@@@[FLINK-19098][json][csv] Make RowData CSV and JSON converters public\n\nThis closes #13303\n\nCo-authored-by: Jark Wu <jark@apache.org>","date":"2020-09-25 22:50:09","modifiedFileCount":"5","status":"B","submitter":"Brian Zhou"},{"authorTime":"2020-09-25 22:50:09","codes":[{"authorDate":"2021-03-24 17:10:23","commitOrder":2,"curCode":"    private static RowFieldConverter createRowFieldConverter(LogicalType fieldType) {\n        switch (fieldType.getTypeRoot()) {\n            case NULL:\n                return (csvMapper, container, row, pos) -> container.nullNode();\n            case BOOLEAN:\n                return (csvMapper, container, row, pos) ->\n                        container.booleanNode(row.getBoolean(pos));\n            case TINYINT:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getByte(pos));\n            case SMALLINT:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getShort(pos));\n            case INTEGER:\n            case INTERVAL_YEAR_MONTH:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getInt(pos));\n            case BIGINT:\n            case INTERVAL_DAY_TIME:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getLong(pos));\n            case FLOAT:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getFloat(pos));\n            case DOUBLE:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getDouble(pos));\n            case CHAR:\n            case VARCHAR:\n                return (csvMapper, container, row, pos) ->\n                        container.textNode(row.getString(pos).toString());\n            case BINARY:\n            case VARBINARY:\n                return (csvMapper, container, row, pos) -> container.binaryNode(row.getBinary(pos));\n            case DATE:\n                return (csvMapper, container, row, pos) -> convertDate(row.getInt(pos), container);\n            case TIME_WITHOUT_TIME_ZONE:\n                return (csvMapper, container, row, pos) -> convertTime(row.getInt(pos), container);\n            case TIMESTAMP_WITHOUT_TIME_ZONE:\n                final int timestampPrecision = ((TimestampType) fieldType).getPrecision();\n                return (csvMapper, container, row, pos) ->\n                        convertTimestamp(\n                                row.getTimestamp(pos, timestampPrecision),\n                                container,\n                                SQL_TIMESTAMP_FORMAT);\n            case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n                final int zonedTimestampPrecision =\n                        ((LocalZonedTimestampType) fieldType).getPrecision();\n                return (csvMapper, container, row, pos) ->\n                        convertTimestamp(\n                                row.getTimestamp(pos, zonedTimestampPrecision),\n                                container,\n                                SQL_TIMESTAMP_WITH_LOCAL_TIMEZONE_FORMAT);\n            case DECIMAL:\n                return createDecimalRowFieldConverter((DecimalType) fieldType);\n            case ARRAY:\n                return createArrayRowFieldConverter((ArrayType) fieldType);\n            case ROW:\n                return createRowRowFieldConverter((RowType) fieldType);\n            case MAP:\n            case MULTISET:\n            case RAW:\n            default:\n                throw new UnsupportedOperationException(\"Unsupported type: \" + fieldType);\n        }\n    }\n","date":"2021-03-27 11:07:48","endLine":163,"groupId":"102291","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"createRowFieldConverter","params":"(LogicalTypefieldType)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/69/f56d42cbe1172d6d01ce2c14c74740d5ae8eaa.src","preCode":"    private static RowFieldConverter createRowFieldConverter(LogicalType fieldType) {\n        switch (fieldType.getTypeRoot()) {\n            case NULL:\n                return (csvMapper, container, row, pos) -> container.nullNode();\n            case BOOLEAN:\n                return (csvMapper, container, row, pos) ->\n                        container.booleanNode(row.getBoolean(pos));\n            case TINYINT:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getByte(pos));\n            case SMALLINT:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getShort(pos));\n            case INTEGER:\n            case INTERVAL_YEAR_MONTH:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getInt(pos));\n            case BIGINT:\n            case INTERVAL_DAY_TIME:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getLong(pos));\n            case FLOAT:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getFloat(pos));\n            case DOUBLE:\n                return (csvMapper, container, row, pos) -> container.numberNode(row.getDouble(pos));\n            case CHAR:\n            case VARCHAR:\n                return (csvMapper, container, row, pos) ->\n                        container.textNode(row.getString(pos).toString());\n            case BINARY:\n            case VARBINARY:\n                return (csvMapper, container, row, pos) -> container.binaryNode(row.getBinary(pos));\n            case DATE:\n                return (csvMapper, container, row, pos) -> convertDate(row.getInt(pos), container);\n            case TIME_WITHOUT_TIME_ZONE:\n                return (csvMapper, container, row, pos) -> convertTime(row.getInt(pos), container);\n            case TIMESTAMP_WITH_TIME_ZONE:\n                final int zonedTimestampPrecision =\n                        ((LocalZonedTimestampType) fieldType).getPrecision();\n                return (csvMapper, container, row, pos) ->\n                        convertTimestamp(row.getTimestamp(pos, zonedTimestampPrecision), container);\n            case TIMESTAMP_WITHOUT_TIME_ZONE:\n                final int timestampPrecision = ((TimestampType) fieldType).getPrecision();\n                return (csvMapper, container, row, pos) ->\n                        convertTimestamp(row.getTimestamp(pos, timestampPrecision), container);\n            case DECIMAL:\n                return createDecimalRowFieldConverter((DecimalType) fieldType);\n            case ARRAY:\n                return createArrayRowFieldConverter((ArrayType) fieldType);\n            case ROW:\n                return createRowRowFieldConverter((RowType) fieldType);\n            case MAP:\n            case MULTISET:\n            case RAW:\n            default:\n                throw new UnsupportedOperationException(\"Unsupported type: \" + fieldType);\n        }\n    }\n","realPath":"flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":104,"status":"M"},{"authorDate":"2020-09-25 22:50:09","commitOrder":2,"curCode":"\tprivate static ArrayElementConverter createDecimalArrayElementConverter(DecimalType decimalType) {\n\t\tfinal int precision = decimalType.getPrecision();\n\t\tfinal int scale = decimalType.getScale();\n\t\treturn (csvMapper, container, array, pos) -> {\n\t\t\tDecimalData decimal = array.getDecimal(pos, precision, scale);\n\t\t\treturn convertDecimal(decimal, container);\n\t\t};\n\t}\n","date":"2020-09-25 22:50:09","endLine":235,"groupId":"102291","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"createDecimalArrayElementConverter","params":"(DecimalTypedecimalType)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6a/b7f74fe6cb3d2a459b12b1757d08f7f79a8ca1.src","preCode":"\tprivate static ArrayElementConverter createDecimalArrayElementConverter(DecimalType decimalType) {\n\t\tfinal int precision = decimalType.getPrecision();\n\t\tfinal int scale = decimalType.getScale();\n\t\treturn (csvMapper, container, array, pos) -> {\n\t\t\tDecimalData decimal = array.getDecimal(pos, precision, scale);\n\t\t\treturn convertDecimal(decimal, container);\n\t\t};\n\t}\n","realPath":"flink-formats/flink-csv/src/main/java/org/apache/flink/formats/csv/RowDataToCsvConverters.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":228,"status":"N"}],"commitId":"a5aaa0e605eb4966b5d73c987ea4d9d0bc852c6d","commitMessage":"@@@[FLINK-21947][csv] Support TIMESTAMP_LTZ type in CSV format\n\nThis closes #15356\n","date":"2021-03-27 11:07:48","modifiedFileCount":"34","status":"M","submitter":"Leonard Xu"}]
