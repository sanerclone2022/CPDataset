[{"authorTime":"2021-08-16 11:28:39","codes":[{"authorDate":"2021-03-08 09:35:30","commitOrder":2,"curCode":"    protected void setKafkaSourceOffset(\n            final StartupMode startupMode,\n            final KafkaSourceBuilder<?> kafkaSourceBuilder,\n            final Map<TopicPartition, Long> specificStartupOffsets,\n            final Long startupTimestamp) {\n        switch (startupMode) {\n            case EARLIEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.earliest());\n                break;\n            case LATEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.latest());\n                break;\n            case SPECIFIC_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.offsets(specificStartupOffsets));\n                break;\n            case GROUP_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST));\n                break;\n            case TIMESTAMP:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.timestamp(startupTimestamp));\n                break;\n        }\n    }\n","date":"2021-03-30 07:53:01","endLine":2225,"groupId":"18523","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"setKafkaSourceOffset","params":"(finalStartupModestartupMode@finalKafkaSourceBuilder<?>kafkaSourceBuilder@finalMap<TopicPartition@Long>specificStartupOffsets@finalLongstartupTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/93/e0cfef96b5b0f0e877c88de0373924f5a0b515.src","preCode":"    protected void setKafkaSourceOffset(\n            final StartupMode startupMode,\n            final KafkaSourceBuilder<?> kafkaSourceBuilder,\n            final Map<TopicPartition, Long> specificStartupOffsets,\n            final Long startupTimestamp) {\n        switch (startupMode) {\n            case EARLIEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.earliest());\n                break;\n            case LATEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.latest());\n                break;\n            case SPECIFIC_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.offsets(specificStartupOffsets));\n                break;\n            case GROUP_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST));\n                break;\n            case TIMESTAMP:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.timestamp(startupTimestamp));\n                break;\n        }\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":2200,"status":"NB"},{"authorDate":"2021-08-16 11:28:39","commitOrder":2,"curCode":"    protected KafkaSource<RowData> createKafkaSource(\n            DeserializationSchema<RowData> keyDeserialization,\n            DeserializationSchema<RowData> valueDeserialization,\n            TypeInformation<RowData> producedTypeInfo) {\n\n        final KafkaDeserializationSchema<RowData> kafkaDeserializer =\n                createKafkaDeserializationSchema(\n                        keyDeserialization, valueDeserialization, producedTypeInfo);\n\n        final KafkaSourceBuilder<RowData> kafkaSourceBuilder = KafkaSource.builder();\n\n        if (topics != null) {\n            kafkaSourceBuilder.setTopics(topics);\n        } else {\n            kafkaSourceBuilder.setTopicPattern(topicPattern);\n        }\n\n        \r\n        if (!properties.containsKey(ConsumerConfig.GROUP_ID_CONFIG)) {\n            String generatedGroupId = \"KafkaSource-\" + tableIdentifier;\n            LOG.warn(\n                    \"Property \\\"{}\\\" is required for offset commit but not set in table options. \"\n                            + \"Assigning \\\"{}\\\" as consumer group id\",\n                    ConsumerConfig.GROUP_ID_CONFIG,\n                    generatedGroupId);\n            kafkaSourceBuilder.setGroupId(generatedGroupId);\n        }\n\n        switch (startupMode) {\n            case EARLIEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.earliest());\n                break;\n            case LATEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.latest());\n                break;\n            case GROUP_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.committedOffsets());\n                break;\n            case SPECIFIC_OFFSETS:\n                Map<TopicPartition, Long> offsets = new HashMap<>();\n                specificStartupOffsets.forEach(\n                        (tp, offset) ->\n                                offsets.put(\n                                        new TopicPartition(tp.getTopic(), tp.getPartition()),\n                                        offset));\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.offsets(offsets));\n                break;\n            case TIMESTAMP:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.timestamp(startupTimestampMillis));\n                break;\n        }\n\n        kafkaSourceBuilder\n                .setProperties(properties)\n                .setDeserializer(KafkaRecordDeserializationSchema.of(kafkaDeserializer));\n\n        return kafkaSourceBuilder.build();\n    }\n","date":"2021-08-16 23:23:35","endLine":428,"groupId":"18523","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createKafkaSource","params":"(DeserializationSchema<RowData>keyDeserialization@DeserializationSchema<RowData>valueDeserialization@TypeInformation<RowData>producedTypeInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f3/2cfe0a439a608fca7f9a4cef8384b0b49f3931.src","preCode":"    protected KafkaSource<RowData> createKafkaSource(\n            DeserializationSchema<RowData> keyDeserialization,\n            DeserializationSchema<RowData> valueDeserialization,\n            TypeInformation<RowData> producedTypeInfo) {\n\n        final KafkaDeserializationSchema<RowData> kafkaDeserializer =\n                createKafkaDeserializationSchema(\n                        keyDeserialization, valueDeserialization, producedTypeInfo);\n\n        final KafkaSourceBuilder<RowData> kafkaSourceBuilder = KafkaSource.builder();\n\n        if (topics != null) {\n            kafkaSourceBuilder.setTopics(topics);\n        } else {\n            kafkaSourceBuilder.setTopicPattern(topicPattern);\n        }\n\n        \r\n        if (!properties.containsKey(ConsumerConfig.GROUP_ID_CONFIG)) {\n            String generatedGroupId = \"KafkaSource-\" + tableIdentifier;\n            LOG.warn(\n                    \"Property \\\"{}\\\" is required for offset commit but not set in table options. \"\n                            + \"Assigning \\\"{}\\\" as consumer group id\",\n                    ConsumerConfig.GROUP_ID_CONFIG,\n                    generatedGroupId);\n            kafkaSourceBuilder.setGroupId(generatedGroupId);\n        }\n\n        switch (startupMode) {\n            case EARLIEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.earliest());\n                break;\n            case LATEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.latest());\n                break;\n            case GROUP_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.committedOffsets());\n                break;\n            case SPECIFIC_OFFSETS:\n                Map<TopicPartition, Long> offsets = new HashMap<>();\n                specificStartupOffsets.forEach(\n                        (tp, offset) ->\n                                offsets.put(\n                                        new TopicPartition(tp.getTopic(), tp.getPartition()),\n                                        offset));\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.offsets(offsets));\n                break;\n            case TIMESTAMP:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.timestamp(startupTimestampMillis));\n                break;\n        }\n\n        kafkaSourceBuilder\n                .setProperties(properties)\n                .setDeserializer(KafkaRecordDeserializationSchema.of(kafkaDeserializer));\n\n        return kafkaSourceBuilder.build();\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSource.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":370,"status":"B"}],"commitId":"4c8f3a7036f5aecfba88381c50b285566bcbcbd5","commitMessage":"@@@[FLINK-22914][connector/kafka] Use FLIP-27 KafkaSource in table connector\n\nThis closes #16809\n","date":"2021-08-16 23:23:35","modifiedFileCount":"5","status":"M","submitter":"Qingsheng Ren"},{"authorTime":"2021-09-14 15:24:10","codes":[{"authorDate":"2021-03-08 09:35:30","commitOrder":3,"curCode":"    protected void setKafkaSourceOffset(\n            final StartupMode startupMode,\n            final KafkaSourceBuilder<?> kafkaSourceBuilder,\n            final Map<TopicPartition, Long> specificStartupOffsets,\n            final Long startupTimestamp) {\n        switch (startupMode) {\n            case EARLIEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.earliest());\n                break;\n            case LATEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.latest());\n                break;\n            case SPECIFIC_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.offsets(specificStartupOffsets));\n                break;\n            case GROUP_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST));\n                break;\n            case TIMESTAMP:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.timestamp(startupTimestamp));\n                break;\n        }\n    }\n","date":"2021-03-30 07:53:01","endLine":2225,"groupId":"10272","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"setKafkaSourceOffset","params":"(finalStartupModestartupMode@finalKafkaSourceBuilder<?>kafkaSourceBuilder@finalMap<TopicPartition@Long>specificStartupOffsets@finalLongstartupTimestamp)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/93/e0cfef96b5b0f0e877c88de0373924f5a0b515.src","preCode":"    protected void setKafkaSourceOffset(\n            final StartupMode startupMode,\n            final KafkaSourceBuilder<?> kafkaSourceBuilder,\n            final Map<TopicPartition, Long> specificStartupOffsets,\n            final Long startupTimestamp) {\n        switch (startupMode) {\n            case EARLIEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.earliest());\n                break;\n            case LATEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.latest());\n                break;\n            case SPECIFIC_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.offsets(specificStartupOffsets));\n                break;\n            case GROUP_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST));\n                break;\n            case TIMESTAMP:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.timestamp(startupTimestamp));\n                break;\n        }\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":2200,"status":"N"},{"authorDate":"2021-09-14 15:24:10","commitOrder":3,"curCode":"    protected KafkaSource<RowData> createKafkaSource(\n            DeserializationSchema<RowData> keyDeserialization,\n            DeserializationSchema<RowData> valueDeserialization,\n            TypeInformation<RowData> producedTypeInfo) {\n\n        final KafkaDeserializationSchema<RowData> kafkaDeserializer =\n                createKafkaDeserializationSchema(\n                        keyDeserialization, valueDeserialization, producedTypeInfo);\n\n        final KafkaSourceBuilder<RowData> kafkaSourceBuilder = KafkaSource.builder();\n\n        if (topics != null) {\n            kafkaSourceBuilder.setTopics(topics);\n        } else {\n            kafkaSourceBuilder.setTopicPattern(topicPattern);\n        }\n\n        switch (startupMode) {\n            case EARLIEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.earliest());\n                break;\n            case LATEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.latest());\n                break;\n            case GROUP_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.committedOffsets());\n                break;\n            case SPECIFIC_OFFSETS:\n                Map<TopicPartition, Long> offsets = new HashMap<>();\n                specificStartupOffsets.forEach(\n                        (tp, offset) ->\n                                offsets.put(\n                                        new TopicPartition(tp.getTopic(), tp.getPartition()),\n                                        offset));\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.offsets(offsets));\n                break;\n            case TIMESTAMP:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.timestamp(startupTimestampMillis));\n                break;\n        }\n\n        kafkaSourceBuilder\n                .setProperties(properties)\n                .setDeserializer(KafkaRecordDeserializationSchema.of(kafkaDeserializer));\n\n        return kafkaSourceBuilder.build();\n    }\n","date":"2021-09-15 20:45:59","endLine":417,"groupId":"10272","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"createKafkaSource","params":"(DeserializationSchema<RowData>keyDeserialization@DeserializationSchema<RowData>valueDeserialization@TypeInformation<RowData>producedTypeInfo)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ab/0fa131bcf808f5d8a727607154f940e8a71835.src","preCode":"    protected KafkaSource<RowData> createKafkaSource(\n            DeserializationSchema<RowData> keyDeserialization,\n            DeserializationSchema<RowData> valueDeserialization,\n            TypeInformation<RowData> producedTypeInfo) {\n\n        final KafkaDeserializationSchema<RowData> kafkaDeserializer =\n                createKafkaDeserializationSchema(\n                        keyDeserialization, valueDeserialization, producedTypeInfo);\n\n        final KafkaSourceBuilder<RowData> kafkaSourceBuilder = KafkaSource.builder();\n\n        if (topics != null) {\n            kafkaSourceBuilder.setTopics(topics);\n        } else {\n            kafkaSourceBuilder.setTopicPattern(topicPattern);\n        }\n\n        \r\n        if (!properties.containsKey(ConsumerConfig.GROUP_ID_CONFIG)) {\n            String generatedGroupId = \"KafkaSource-\" + tableIdentifier;\n            LOG.warn(\n                    \"Property \\\"{}\\\" is required for offset commit but not set in table options. \"\n                            + \"Assigning \\\"{}\\\" as consumer group id\",\n                    ConsumerConfig.GROUP_ID_CONFIG,\n                    generatedGroupId);\n            kafkaSourceBuilder.setGroupId(generatedGroupId);\n        }\n\n        switch (startupMode) {\n            case EARLIEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.earliest());\n                break;\n            case LATEST:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.latest());\n                break;\n            case GROUP_OFFSETS:\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.committedOffsets());\n                break;\n            case SPECIFIC_OFFSETS:\n                Map<TopicPartition, Long> offsets = new HashMap<>();\n                specificStartupOffsets.forEach(\n                        (tp, offset) ->\n                                offsets.put(\n                                        new TopicPartition(tp.getTopic(), tp.getPartition()),\n                                        offset));\n                kafkaSourceBuilder.setStartingOffsets(OffsetsInitializer.offsets(offsets));\n                break;\n            case TIMESTAMP:\n                kafkaSourceBuilder.setStartingOffsets(\n                        OffsetsInitializer.timestamp(startupTimestampMillis));\n                break;\n        }\n\n        kafkaSourceBuilder\n                .setProperties(properties)\n                .setDeserializer(KafkaRecordDeserializationSchema.of(kafkaDeserializer));\n\n        return kafkaSourceBuilder.build();\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicSource.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":370,"status":"M"}],"commitId":"f3ef860de6e82cce5c87b923a0096d0674c84ce7","commitMessage":"@@@[FLINK-24277][connector/kafka] Remove auto-generated group id in Kafka table source\n","date":"2021-09-15 20:45:59","modifiedFileCount":"3","status":"M","submitter":"Qingsheng Ren"}]
