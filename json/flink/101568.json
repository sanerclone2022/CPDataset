[{"authorTime":"2018-05-03 16:05:13","codes":[{"authorDate":"2018-10-05 14:30:28","commitOrder":3,"curCode":"\tpublic void testSavepoint() throws Exception {\n\t\tfinal int parallelism = 1;\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setRestartStrategy(RestartStrategies.noRestart());\n\t\tenv.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);\n\n\t\tswitch (testStateBackend) {\n\t\t\tcase StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));\n\t\t\t\tbreak;\n\t\t\tcase StateBackendLoader.MEMORY_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new MemoryStateBackend());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setMaxParallelism(parallelism);\n\n\t\tSourceFunction<Tuple2<Long, Long>> nonParallelSource =\n\t\t\tnew MigrationTestUtils.CheckpointingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\n\t\tenv.addSource(nonParallelSource)\n\t\t\t.keyBy(0)\n\t\t\t.map(new TestMapFunction())\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\texecuteAndSavepoint(\n\t\t\t\tenv,\n\t\t\t\t\"src/test/resources/\" + getSavepointPath(testMigrateVersion, testStateBackend),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS));\n\t\t} else {\n\t\t\trestoreAndExecute(\n\t\t\t\tenv,\n\t\t\t\tgetResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS));\n\t\t}\n\t}\n","date":"2018-10-10 13:25:14","endLine":141,"groupId":"39589","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/87/2a58d2304235a9d74cd78692089b6cbc3121bb.src","preCode":"\tpublic void testSavepoint() throws Exception {\n\t\tfinal int parallelism = 1;\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setRestartStrategy(RestartStrategies.noRestart());\n\t\tenv.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);\n\n\t\tswitch (testStateBackend) {\n\t\t\tcase StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));\n\t\t\t\tbreak;\n\t\t\tcase StateBackendLoader.MEMORY_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new MemoryStateBackend());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setMaxParallelism(parallelism);\n\n\t\tSourceFunction<Tuple2<Long, Long>> nonParallelSource =\n\t\t\tnew MigrationTestUtils.CheckpointingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\n\t\tenv.addSource(nonParallelSource)\n\t\t\t.keyBy(0)\n\t\t\t.map(new TestMapFunction())\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\texecuteAndSavepoint(\n\t\t\t\tenv,\n\t\t\t\t\"src/test/resources/\" + getSavepointPath(testMigrateVersion, testStateBackend),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS));\n\t\t} else {\n\t\t\trestoreAndExecute(\n\t\t\t\tenv,\n\t\t\t\tgetResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS));\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/migration/TypeSerializerSnapshotMigrationITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":100,"status":"B"},{"authorDate":"2018-05-03 16:05:13","commitOrder":3,"curCode":"\tpublic void testSavepoint() throws Exception {\n\n\t\tfinal int parallelism = 4;\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setRestartStrategy(RestartStrategies.noRestart());\n\t\tenv.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);\n\n\t\tswitch (testStateBackend) {\n\t\t\tcase StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));\n\t\t\t\tbreak;\n\t\t\tcase StateBackendLoader.MEMORY_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new MemoryStateBackend());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setMaxParallelism(parallelism);\n\n\t\tSourceFunction<Tuple2<Long, Long>> nonParallelSource;\n\t\tSourceFunction<Tuple2<Long, Long>> parallelSource;\n\t\tRichFlatMapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>> flatMap;\n\t\tOneInputStreamOperator<Tuple2<Long, Long>, Tuple2<Long, Long>> timelyOperator;\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\tnonParallelSource = new MigrationTestUtils.CheckpointingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\t\t\tparallelSource = new MigrationTestUtils.CheckpointingParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS);\n\t\t\tflatMap = new CheckpointingKeyedStateFlatMap();\n\t\t\ttimelyOperator = new CheckpointingTimelyStatefulOperator();\n\t\t} else if (executionMode == ExecutionMode.VERIFY_SAVEPOINT) {\n\t\t\tnonParallelSource = new MigrationTestUtils.CheckingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\t\t\tparallelSource = new MigrationTestUtils.CheckingParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS);\n\t\t\tflatMap = new CheckingKeyedStateFlatMap();\n\t\t\ttimelyOperator = new CheckingTimelyStatefulOperator();\n\t\t} else {\n\t\t\tthrow new IllegalStateException(\"Unknown ExecutionMode \" + executionMode);\n\t\t}\n\n\t\tenv\n\t\t\t.addSource(nonParallelSource).uid(\"CheckpointingSource1\")\n\t\t\t.keyBy(0)\n\t\t\t.flatMap(flatMap).startNewChain().uid(\"CheckpointingKeyedStateFlatMap1\")\n\t\t\t.keyBy(0)\n\t\t\t.transform(\n\t\t\t\t\"timely_stateful_operator\",\n\t\t\t\tnew TypeHint<Tuple2<Long, Long>>() {}.getTypeInfo(),\n\t\t\t\ttimelyOperator).uid(\"CheckpointingTimelyStatefulOperator1\")\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tenv\n\t\t\t.addSource(parallelSource).uid(\"CheckpointingSource2\")\n\t\t\t.keyBy(0)\n\t\t\t.flatMap(flatMap).startNewChain().uid(\"CheckpointingKeyedStateFlatMap2\")\n\t\t\t.keyBy(0)\n\t\t\t.transform(\n\t\t\t\t\"timely_stateful_operator\",\n\t\t\t\tnew TypeHint<Tuple2<Long, Long>>() {}.getTypeInfo(),\n\t\t\t\ttimelyOperator).uid(\"CheckpointingTimelyStatefulOperator2\")\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\texecuteAndSavepoint(\n\t\t\t\tenv,\n\t\t\t\t\"src/test/resources/\" + getSavepointPath(testMigrateVersion, testStateBackend),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));\n\t\t} else {\n\t\t\trestoreAndExecute(\n\t\t\t\tenv,\n\t\t\t\tgetResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.CheckingNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.CheckingParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),\n\t\t\t\tnew Tuple2<>(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));\n\t\t}\n\t}\n","date":"2018-05-18 22:28:31","endLine":174,"groupId":"44672","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c7/4f304e45a5adacb337a8abbf9cb1315a3dafe6.src","preCode":"\tpublic void testSavepoint() throws Exception {\n\n\t\tfinal int parallelism = 4;\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setRestartStrategy(RestartStrategies.noRestart());\n\t\tenv.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);\n\n\t\tswitch (testStateBackend) {\n\t\t\tcase StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));\n\t\t\t\tbreak;\n\t\t\tcase StateBackendLoader.MEMORY_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new MemoryStateBackend());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setMaxParallelism(parallelism);\n\n\t\tSourceFunction<Tuple2<Long, Long>> nonParallelSource;\n\t\tSourceFunction<Tuple2<Long, Long>> parallelSource;\n\t\tRichFlatMapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>> flatMap;\n\t\tOneInputStreamOperator<Tuple2<Long, Long>, Tuple2<Long, Long>> timelyOperator;\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\tnonParallelSource = new MigrationTestUtils.CheckpointingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\t\t\tparallelSource = new MigrationTestUtils.CheckpointingParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS);\n\t\t\tflatMap = new CheckpointingKeyedStateFlatMap();\n\t\t\ttimelyOperator = new CheckpointingTimelyStatefulOperator();\n\t\t} else if (executionMode == ExecutionMode.VERIFY_SAVEPOINT) {\n\t\t\tnonParallelSource = new MigrationTestUtils.CheckingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\t\t\tparallelSource = new MigrationTestUtils.CheckingParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS);\n\t\t\tflatMap = new CheckingKeyedStateFlatMap();\n\t\t\ttimelyOperator = new CheckingTimelyStatefulOperator();\n\t\t} else {\n\t\t\tthrow new IllegalStateException(\"Unknown ExecutionMode \" + executionMode);\n\t\t}\n\n\t\tenv\n\t\t\t.addSource(nonParallelSource).uid(\"CheckpointingSource1\")\n\t\t\t.keyBy(0)\n\t\t\t.flatMap(flatMap).startNewChain().uid(\"CheckpointingKeyedStateFlatMap1\")\n\t\t\t.keyBy(0)\n\t\t\t.transform(\n\t\t\t\t\"timely_stateful_operator\",\n\t\t\t\tnew TypeHint<Tuple2<Long, Long>>() {}.getTypeInfo(),\n\t\t\t\ttimelyOperator).uid(\"CheckpointingTimelyStatefulOperator1\")\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tenv\n\t\t\t.addSource(parallelSource).uid(\"CheckpointingSource2\")\n\t\t\t.keyBy(0)\n\t\t\t.flatMap(flatMap).startNewChain().uid(\"CheckpointingKeyedStateFlatMap2\")\n\t\t\t.keyBy(0)\n\t\t\t.transform(\n\t\t\t\t\"timely_stateful_operator\",\n\t\t\t\tnew TypeHint<Tuple2<Long, Long>>() {}.getTypeInfo(),\n\t\t\t\ttimelyOperator).uid(\"CheckpointingTimelyStatefulOperator2\")\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\texecuteAndSavepoint(\n\t\t\t\tenv,\n\t\t\t\t\"src/test/resources/\" + getSavepointPath(testMigrateVersion, testStateBackend),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));\n\t\t} else {\n\t\t\trestoreAndExecute(\n\t\t\t\tenv,\n\t\t\t\tgetResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.CheckingNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.CheckingParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),\n\t\t\t\tnew Tuple2<>(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":93,"status":"NB"}],"commitId":"ac74a0ce6297ce3754744ceb07107f6024c1a163","commitMessage":"@@@[FLINK-9377] [core] (part 6) Introduce TypeSerializerSnapshot for a smoother upgrade path\n\nThis commit deprecates TypeSerializerConfigSnapshot.  and introduces a\nTypeSerializerSnapshot interface which will eventually be the new\nreplacement.\n\nThe now-deprecated TypeSerializerConfigSnapshot differentiates in that\nwhen being written.  it wil still write along with it the prior\nserializer and return that when attempting to restore the prior\nserializer. Implementations which are upgraded to directly implement the\nnew TypeSerializerSnapshot interface are strictly required to implement\nthe restoreSerializer() method. Therefore.  once upgraded.  the prior\nserializer is no longer written.\n","date":"2018-10-10 13:25:14","modifiedFileCount":"40","status":"M","submitter":"Tzu-Li (Gordon) Tai"},{"authorTime":"2020-09-29 02:16:11","codes":[{"authorDate":"2020-09-29 02:16:11","commitOrder":4,"curCode":"\tpublic void testSavepoint() throws Exception {\n\t\tfinal int parallelism = 1;\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setRestartStrategy(RestartStrategies.noRestart());\n\n\t\tswitch (testStateBackend) {\n\t\t\tcase StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));\n\t\t\t\tbreak;\n\t\t\tcase StateBackendLoader.MEMORY_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new MemoryStateBackend());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setMaxParallelism(parallelism);\n\n\t\tSourceFunction<Tuple2<Long, Long>> nonParallelSource =\n\t\t\tnew MigrationTestUtils.CheckpointingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\n\t\tenv.addSource(nonParallelSource)\n\t\t\t.keyBy(0)\n\t\t\t.map(new TestMapFunction())\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\texecuteAndSavepoint(\n\t\t\t\tenv,\n\t\t\t\t\"src/test/resources/\" + getSavepointPath(testMigrateVersion, testStateBackend),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS));\n\t\t} else {\n\t\t\trestoreAndExecute(\n\t\t\t\tenv,\n\t\t\t\tgetResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS));\n\t\t}\n\t}\n","date":"2020-10-01 23:03:45","endLine":150,"groupId":"101568","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/3f/f379cf543fba1a9245ea840fff4f79b6cb2eb8.src","preCode":"\tpublic void testSavepoint() throws Exception {\n\t\tfinal int parallelism = 1;\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setRestartStrategy(RestartStrategies.noRestart());\n\t\tenv.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);\n\n\t\tswitch (testStateBackend) {\n\t\t\tcase StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));\n\t\t\t\tbreak;\n\t\t\tcase StateBackendLoader.MEMORY_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new MemoryStateBackend());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setMaxParallelism(parallelism);\n\n\t\tSourceFunction<Tuple2<Long, Long>> nonParallelSource =\n\t\t\tnew MigrationTestUtils.CheckpointingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\n\t\tenv.addSource(nonParallelSource)\n\t\t\t.keyBy(0)\n\t\t\t.map(new TestMapFunction())\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\texecuteAndSavepoint(\n\t\t\t\tenv,\n\t\t\t\t\"src/test/resources/\" + getSavepointPath(testMigrateVersion, testStateBackend),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS));\n\t\t} else {\n\t\t\trestoreAndExecute(\n\t\t\t\tenv,\n\t\t\t\tgetResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS));\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/migration/TypeSerializerSnapshotMigrationITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":110,"status":"M"},{"authorDate":"2020-09-29 02:16:11","commitOrder":4,"curCode":"\tpublic void testSavepoint() throws Exception {\n\n\t\tfinal int parallelism = 4;\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setRestartStrategy(RestartStrategies.noRestart());\n\n\t\tswitch (testStateBackend) {\n\t\t\tcase StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));\n\t\t\t\tbreak;\n\t\t\tcase StateBackendLoader.MEMORY_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new MemoryStateBackend());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setMaxParallelism(parallelism);\n\n\t\tSourceFunction<Tuple2<Long, Long>> nonParallelSource;\n\t\tSourceFunction<Tuple2<Long, Long>> parallelSource;\n\t\tRichFlatMapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>> flatMap;\n\t\tOneInputStreamOperator<Tuple2<Long, Long>, Tuple2<Long, Long>> timelyOperator;\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\tnonParallelSource = new MigrationTestUtils.CheckpointingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\t\t\tparallelSource = new MigrationTestUtils.CheckpointingParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS);\n\t\t\tflatMap = new CheckpointingKeyedStateFlatMap();\n\t\t\ttimelyOperator = new CheckpointingTimelyStatefulOperator();\n\t\t} else if (executionMode == ExecutionMode.VERIFY_SAVEPOINT) {\n\t\t\tnonParallelSource = new MigrationTestUtils.CheckingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\t\t\tparallelSource = new MigrationTestUtils.CheckingParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS);\n\t\t\tflatMap = new CheckingKeyedStateFlatMap();\n\t\t\ttimelyOperator = new CheckingTimelyStatefulOperator();\n\t\t} else {\n\t\t\tthrow new IllegalStateException(\"Unknown ExecutionMode \" + executionMode);\n\t\t}\n\n\t\tenv\n\t\t\t.addSource(nonParallelSource).uid(\"CheckpointingSource1\")\n\t\t\t.keyBy(0)\n\t\t\t.flatMap(flatMap).startNewChain().uid(\"CheckpointingKeyedStateFlatMap1\")\n\t\t\t.keyBy(0)\n\t\t\t.transform(\n\t\t\t\t\"timely_stateful_operator\",\n\t\t\t\tnew TypeHint<Tuple2<Long, Long>>() {}.getTypeInfo(),\n\t\t\t\ttimelyOperator).uid(\"CheckpointingTimelyStatefulOperator1\")\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tenv\n\t\t\t.addSource(parallelSource).uid(\"CheckpointingSource2\")\n\t\t\t.keyBy(0)\n\t\t\t.flatMap(flatMap).startNewChain().uid(\"CheckpointingKeyedStateFlatMap2\")\n\t\t\t.keyBy(0)\n\t\t\t.transform(\n\t\t\t\t\"timely_stateful_operator\",\n\t\t\t\tnew TypeHint<Tuple2<Long, Long>>() {}.getTypeInfo(),\n\t\t\t\ttimelyOperator).uid(\"CheckpointingTimelyStatefulOperator2\")\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\texecuteAndSavepoint(\n\t\t\t\tenv,\n\t\t\t\t\"src/test/resources/\" + getSavepointPath(testMigrateVersion, testStateBackend),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));\n\t\t} else {\n\t\t\trestoreAndExecute(\n\t\t\t\tenv,\n\t\t\t\tgetResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.CheckingNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.CheckingParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),\n\t\t\t\tnew Tuple2<>(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));\n\t\t}\n\t}\n","date":"2020-10-01 23:03:45","endLine":187,"groupId":"101568","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepoint","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2f/c2746051c3c53edaaecfa606b38863d708ed19.src","preCode":"\tpublic void testSavepoint() throws Exception {\n\n\t\tfinal int parallelism = 4;\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setRestartStrategy(RestartStrategies.noRestart());\n\t\tenv.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);\n\n\t\tswitch (testStateBackend) {\n\t\t\tcase StateBackendLoader.ROCKSDB_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new RocksDBStateBackend(new MemoryStateBackend()));\n\t\t\t\tbreak;\n\t\t\tcase StateBackendLoader.MEMORY_STATE_BACKEND_NAME:\n\t\t\t\tenv.setStateBackend(new MemoryStateBackend());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setMaxParallelism(parallelism);\n\n\t\tSourceFunction<Tuple2<Long, Long>> nonParallelSource;\n\t\tSourceFunction<Tuple2<Long, Long>> parallelSource;\n\t\tRichFlatMapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>> flatMap;\n\t\tOneInputStreamOperator<Tuple2<Long, Long>, Tuple2<Long, Long>> timelyOperator;\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\tnonParallelSource = new MigrationTestUtils.CheckpointingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\t\t\tparallelSource = new MigrationTestUtils.CheckpointingParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS);\n\t\t\tflatMap = new CheckpointingKeyedStateFlatMap();\n\t\t\ttimelyOperator = new CheckpointingTimelyStatefulOperator();\n\t\t} else if (executionMode == ExecutionMode.VERIFY_SAVEPOINT) {\n\t\t\tnonParallelSource = new MigrationTestUtils.CheckingNonParallelSourceWithListState(NUM_SOURCE_ELEMENTS);\n\t\t\tparallelSource = new MigrationTestUtils.CheckingParallelSourceWithUnionListState(NUM_SOURCE_ELEMENTS);\n\t\t\tflatMap = new CheckingKeyedStateFlatMap();\n\t\t\ttimelyOperator = new CheckingTimelyStatefulOperator();\n\t\t} else {\n\t\t\tthrow new IllegalStateException(\"Unknown ExecutionMode \" + executionMode);\n\t\t}\n\n\t\tenv\n\t\t\t.addSource(nonParallelSource).uid(\"CheckpointingSource1\")\n\t\t\t.keyBy(0)\n\t\t\t.flatMap(flatMap).startNewChain().uid(\"CheckpointingKeyedStateFlatMap1\")\n\t\t\t.keyBy(0)\n\t\t\t.transform(\n\t\t\t\t\"timely_stateful_operator\",\n\t\t\t\tnew TypeHint<Tuple2<Long, Long>>() {}.getTypeInfo(),\n\t\t\t\ttimelyOperator).uid(\"CheckpointingTimelyStatefulOperator1\")\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tenv\n\t\t\t.addSource(parallelSource).uid(\"CheckpointingSource2\")\n\t\t\t.keyBy(0)\n\t\t\t.flatMap(flatMap).startNewChain().uid(\"CheckpointingKeyedStateFlatMap2\")\n\t\t\t.keyBy(0)\n\t\t\t.transform(\n\t\t\t\t\"timely_stateful_operator\",\n\t\t\t\tnew TypeHint<Tuple2<Long, Long>>() {}.getTypeInfo(),\n\t\t\t\ttimelyOperator).uid(\"CheckpointingTimelyStatefulOperator2\")\n\t\t\t.addSink(new MigrationTestUtils.AccumulatorCountingSink<>());\n\n\t\tif (executionMode == ExecutionMode.PERFORM_SAVEPOINT) {\n\t\t\texecuteAndSavepoint(\n\t\t\t\tenv,\n\t\t\t\t\"src/test/resources/\" + getSavepointPath(testMigrateVersion, testStateBackend),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));\n\t\t} else {\n\t\t\trestoreAndExecute(\n\t\t\t\tenv,\n\t\t\t\tgetResourceFilename(getSavepointPath(testMigrateVersion, testStateBackend)),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.CheckingNonParallelSourceWithListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, 1),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.CheckingParallelSourceWithUnionListState.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, parallelism),\n\t\t\t\tnew Tuple2<>(CheckingKeyedStateFlatMap.SUCCESSFUL_RESTORE_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESS_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_EVENT_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(CheckingTimelyStatefulOperator.SUCCESSFUL_PROCESSING_TIME_CHECK_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2),\n\t\t\t\tnew Tuple2<>(MigrationTestUtils.AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR, NUM_SOURCE_ELEMENTS * 2));\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/utils/StatefulJobSavepointMigrationITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":107,"status":"M"}],"commitId":"cb4de07a4004b46702edf7809f8a556866fe3da1","commitMessage":"@@@[FLINK-19317] Remove unnecessary calls to setStreamTimeCharacteristic (java)\n\nI'm just removing calls the set EventTime because that's the new default\nnow.\n\nI'm also removing most calls to set ProcessingTime because it's not\nneeded for making processing-time timers/windows work. I only left it\nfor some tests that check specific failure behavior.\n\nI removed calls to set IngestionTime and replaced them by an explicit\nIngestionTimeWatermarkStrategy. I duplicated the same\nIngestionTimeWatermarkStrategy in all the examples/tests because I\nexplicitly didn't want to add an IngestionTimeWatermarkStrategy in one\nof the core packages so that it is not discoverable because I think we\nshouldn't encourage users to use ingestion time.\n","date":"2020-10-01 23:03:45","modifiedFileCount":"30","status":"M","submitter":"Aljoscha Krettek"}]
