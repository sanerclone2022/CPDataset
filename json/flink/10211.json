[{"authorTime":"2020-11-04 10:54:31","codes":[{"authorDate":"2020-11-04 10:54:31","commitOrder":1,"curCode":"\tpublic void testSourceSinkWithKeyAndPartialValue() throws Exception {\n\t\t\r\n\t\t\r\n\t\tfinal String topic = \"key_partial_value_topic_\" + format;\n\t\tcreateTestTopic(topic, 1, 1); \r\n\n\t\t\r\n\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n\t\t\r\n\t\t\r\n\t\tfinal String createTable = String.format(\n\t\t\t\"CREATE TABLE upsert_kafka (\\n\"\n\t\t\t\t+ \"  `k_user_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `name` STRING,\\n\"\n\t\t\t\t+ \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n\t\t\t\t+ \"  `k_event_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `user_id` INT,\\n\"\n\t\t\t\t+ \"  `payload` STRING,\\n\"\n\t\t\t\t+ \"  PRIMARY KEY (k_event_id, k_user_id) NOT ENFORCED\"\n\t\t\t\t+ \") WITH (\\n\"\n\t\t\t\t+ \"  'connector' = 'upsert-kafka',\\n\"\n\t\t\t\t+ \"  'topic' = '%s',\\n\"\n\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n\t\t\t\t+ \"  'key.format' = '%s',\\n\"\n\t\t\t\t+ \"  'key.fields-prefix' = 'k_',\\n\"\n\t\t\t\t+ \"  'value.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.fields-include' = 'EXCEPT_KEY'\\n\"\n\t\t\t\t+ \")\",\n\t\t\ttopic,\n\t\t\tbootstraps,\n\t\t\tformat,\n\t\t\tformat);\n\n\t\ttEnv.executeSql(createTable);\n\n\t\tString initialValues = \"INSERT INTO upsert_kafka\\n\"\n\t\t\t+ \"VALUES\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 41, 'payload 1'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 42, 'payload 2'),\\n\"\n\t\t\t+ \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 43, 'payload 3'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-11 13:12:11.123', 101, 42, 'payload')\";\n\t\ttEnv.executeSql(initialValues).await();\n\n\t\t\r\n\n\t\tfinal List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n\t\tfinal List<Row> expected = Arrays.asList(\n\t\t\tchangelogRow(\"+I\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, 41, \"payload 1\"),\n\t\t\tchangelogRow(\"+I\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, 42, \"payload 2\"),\n\t\t\tchangelogRow(\"+I\", 3L, \"name 3\", LocalDateTime.parse(\"2020-03-10T13:12:11.123\"), 102L, 43, \"payload 3\"),\n\t\t\tchangelogRow(\"-U\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, 42, \"payload 2\"),\n\t\t\tchangelogRow(\"+U\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-11T13:12:11.123\"), 101L, 42, \"payload\")\n\t\t);\n\n\t\tassertThat(result, deepEqualTo(expected, true));\n\n\t\t\r\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2020-11-05 21:08:26","endLine":181,"groupId":"33927","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSourceSinkWithKeyAndPartialValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/90/52a1769009b549c3d90d47a626252f0f799829.src","preCode":"\tpublic void testSourceSinkWithKeyAndPartialValue() throws Exception {\n\t\t\r\n\t\t\r\n\t\tfinal String topic = \"key_partial_value_topic_\" + format;\n\t\tcreateTestTopic(topic, 1, 1); \r\n\n\t\t\r\n\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n\t\t\r\n\t\t\r\n\t\tfinal String createTable = String.format(\n\t\t\t\"CREATE TABLE upsert_kafka (\\n\"\n\t\t\t\t+ \"  `k_user_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `name` STRING,\\n\"\n\t\t\t\t+ \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n\t\t\t\t+ \"  `k_event_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `user_id` INT,\\n\"\n\t\t\t\t+ \"  `payload` STRING,\\n\"\n\t\t\t\t+ \"  PRIMARY KEY (k_event_id, k_user_id) NOT ENFORCED\"\n\t\t\t\t+ \") WITH (\\n\"\n\t\t\t\t+ \"  'connector' = 'upsert-kafka',\\n\"\n\t\t\t\t+ \"  'topic' = '%s',\\n\"\n\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n\t\t\t\t+ \"  'key.format' = '%s',\\n\"\n\t\t\t\t+ \"  'key.fields-prefix' = 'k_',\\n\"\n\t\t\t\t+ \"  'value.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.fields-include' = 'EXCEPT_KEY'\\n\"\n\t\t\t\t+ \")\",\n\t\t\ttopic,\n\t\t\tbootstraps,\n\t\t\tformat,\n\t\t\tformat);\n\n\t\ttEnv.executeSql(createTable);\n\n\t\tString initialValues = \"INSERT INTO upsert_kafka\\n\"\n\t\t\t+ \"VALUES\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 41, 'payload 1'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 42, 'payload 2'),\\n\"\n\t\t\t+ \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 43, 'payload 3'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-11 13:12:11.123', 101, 42, 'payload')\";\n\t\ttEnv.executeSql(initialValues).await();\n\n\t\t\r\n\n\t\tfinal List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n\t\tfinal List<Row> expected = Arrays.asList(\n\t\t\tchangelogRow(\"+I\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, 41, \"payload 1\"),\n\t\t\tchangelogRow(\"+I\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, 42, \"payload 2\"),\n\t\t\tchangelogRow(\"+I\", 3L, \"name 3\", LocalDateTime.parse(\"2020-03-10T13:12:11.123\"), 102L, 43, \"payload 3\"),\n\t\t\tchangelogRow(\"-U\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, 42, \"payload 2\"),\n\t\t\tchangelogRow(\"+U\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-11T13:12:11.123\"), 101L, 42, \"payload\")\n\t\t);\n\n\t\tassertThat(result, deepEqualTo(expected, true));\n\n\t\t\r\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaTableITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":120,"status":"B"},{"authorDate":"2020-11-04 10:54:31","commitOrder":1,"curCode":"\tpublic void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n\t\t\r\n\t\t\r\n\t\tfinal String topic = \"key_full_value_topic_\" + format;\n\t\tcreateTestTopic(topic, 1, 1); \r\n\n\t\t\r\n\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tfinal String createTable = String.format(\n\t\t\t\"CREATE TABLE upsert_kafka (\\n\"\n\t\t\t\t+ \"  `user_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `name` STRING,\\n\"\n\t\t\t\t+ \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n\t\t\t\t+ \"  `event_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `payload` STRING,\\n\"\n\t\t\t\t+ \"  PRIMARY KEY (event_id, user_id) NOT ENFORCED\"\n\t\t\t\t+ \") WITH (\\n\"\n\t\t\t\t+ \"  'connector' = 'upsert-kafka',\\n\"\n\t\t\t\t+ \"  'topic' = '%s',\\n\"\n\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n\t\t\t\t+ \"  'key.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.fields-include' = 'ALL'\\n\"\n\t\t\t\t+ \")\",\n\t\t\ttopic,\n\t\t\tbootstraps,\n\t\t\tformat,\n\t\t\tformat);\n\n\t\ttEnv.executeSql(createTable);\n\n\t\tString initialValues = \"INSERT INTO upsert_kafka\\n\"\n\t\t\t+ \"VALUES\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 'payload 1'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 'payload 2'),\\n\"\n\t\t\t+ \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 'payload 3'),\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-11 13:12:11.123', 100, 'payload')\";\n\t\ttEnv.executeSql(initialValues).await();\n\n\t\t\r\n\n\t\tfinal List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n\t\tfinal List<Row> expected = Arrays.asList(\n\t\t\tchangelogRow(\"+I\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, \"payload 1\"),\n\t\t\tchangelogRow(\"+I\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, \"payload 2\"),\n\t\t\tchangelogRow(\"+I\", 3L, \"name 3\", LocalDateTime.parse(\"2020-03-10T13:12:11.123\"), 102L, \"payload 3\"),\n\t\t\tchangelogRow(\"-U\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, \"payload 1\"),\n\t\t\tchangelogRow(\"+U\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-11T13:12:11.123\"), 100L, \"payload\")\n\t\t);\n\n\t\tassertThat(result, deepEqualTo(expected, true));\n\n\t\t\r\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2020-11-05 21:08:26","endLine":245,"groupId":"33927","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testKafkaSourceSinkWithKeyAndFullValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/90/52a1769009b549c3d90d47a626252f0f799829.src","preCode":"\tpublic void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n\t\t\r\n\t\t\r\n\t\tfinal String topic = \"key_full_value_topic_\" + format;\n\t\tcreateTestTopic(topic, 1, 1); \r\n\n\t\t\r\n\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tfinal String createTable = String.format(\n\t\t\t\"CREATE TABLE upsert_kafka (\\n\"\n\t\t\t\t+ \"  `user_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `name` STRING,\\n\"\n\t\t\t\t+ \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n\t\t\t\t+ \"  `event_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `payload` STRING,\\n\"\n\t\t\t\t+ \"  PRIMARY KEY (event_id, user_id) NOT ENFORCED\"\n\t\t\t\t+ \") WITH (\\n\"\n\t\t\t\t+ \"  'connector' = 'upsert-kafka',\\n\"\n\t\t\t\t+ \"  'topic' = '%s',\\n\"\n\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n\t\t\t\t+ \"  'key.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.fields-include' = 'ALL'\\n\"\n\t\t\t\t+ \")\",\n\t\t\ttopic,\n\t\t\tbootstraps,\n\t\t\tformat,\n\t\t\tformat);\n\n\t\ttEnv.executeSql(createTable);\n\n\t\tString initialValues = \"INSERT INTO upsert_kafka\\n\"\n\t\t\t+ \"VALUES\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 'payload 1'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 'payload 2'),\\n\"\n\t\t\t+ \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 'payload 3'),\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-11 13:12:11.123', 100, 'payload')\";\n\t\ttEnv.executeSql(initialValues).await();\n\n\t\t\r\n\n\t\tfinal List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n\t\tfinal List<Row> expected = Arrays.asList(\n\t\t\tchangelogRow(\"+I\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, \"payload 1\"),\n\t\t\tchangelogRow(\"+I\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, \"payload 2\"),\n\t\t\tchangelogRow(\"+I\", 3L, \"name 3\", LocalDateTime.parse(\"2020-03-10T13:12:11.123\"), 102L, \"payload 3\"),\n\t\t\tchangelogRow(\"-U\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, \"payload 1\"),\n\t\t\tchangelogRow(\"+U\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-11T13:12:11.123\"), 100L, \"payload\")\n\t\t);\n\n\t\tassertThat(result, deepEqualTo(expected, true));\n\n\t\t\r\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaTableITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":184,"status":"B"}],"commitId":"9cc5e07c43fdae37c5f2afd617091931c92626d6","commitMessage":"@@@[FLINK-19858][upsert-kafka] Introduce the upsert-kafka table factory\n\nThis closes #13850\n","date":"2020-11-05 21:08:26","modifiedFileCount":"10","status":"B","submitter":"Shengkai"},{"authorTime":"2020-11-05 14:14:21","codes":[{"authorDate":"2020-11-04 10:54:31","commitOrder":2,"curCode":"\tpublic void testSourceSinkWithKeyAndPartialValue() throws Exception {\n\t\t\r\n\t\t\r\n\t\tfinal String topic = \"key_partial_value_topic_\" + format;\n\t\tcreateTestTopic(topic, 1, 1); \r\n\n\t\t\r\n\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n\t\t\r\n\t\t\r\n\t\tfinal String createTable = String.format(\n\t\t\t\"CREATE TABLE upsert_kafka (\\n\"\n\t\t\t\t+ \"  `k_user_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `name` STRING,\\n\"\n\t\t\t\t+ \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n\t\t\t\t+ \"  `k_event_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `user_id` INT,\\n\"\n\t\t\t\t+ \"  `payload` STRING,\\n\"\n\t\t\t\t+ \"  PRIMARY KEY (k_event_id, k_user_id) NOT ENFORCED\"\n\t\t\t\t+ \") WITH (\\n\"\n\t\t\t\t+ \"  'connector' = 'upsert-kafka',\\n\"\n\t\t\t\t+ \"  'topic' = '%s',\\n\"\n\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n\t\t\t\t+ \"  'key.format' = '%s',\\n\"\n\t\t\t\t+ \"  'key.fields-prefix' = 'k_',\\n\"\n\t\t\t\t+ \"  'value.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.fields-include' = 'EXCEPT_KEY'\\n\"\n\t\t\t\t+ \")\",\n\t\t\ttopic,\n\t\t\tbootstraps,\n\t\t\tformat,\n\t\t\tformat);\n\n\t\ttEnv.executeSql(createTable);\n\n\t\tString initialValues = \"INSERT INTO upsert_kafka\\n\"\n\t\t\t+ \"VALUES\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 41, 'payload 1'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 42, 'payload 2'),\\n\"\n\t\t\t+ \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 43, 'payload 3'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-11 13:12:11.123', 101, 42, 'payload')\";\n\t\ttEnv.executeSql(initialValues).await();\n\n\t\t\r\n\n\t\tfinal List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n\t\tfinal List<Row> expected = Arrays.asList(\n\t\t\tchangelogRow(\"+I\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, 41, \"payload 1\"),\n\t\t\tchangelogRow(\"+I\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, 42, \"payload 2\"),\n\t\t\tchangelogRow(\"+I\", 3L, \"name 3\", LocalDateTime.parse(\"2020-03-10T13:12:11.123\"), 102L, 43, \"payload 3\"),\n\t\t\tchangelogRow(\"-U\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, 42, \"payload 2\"),\n\t\t\tchangelogRow(\"+U\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-11T13:12:11.123\"), 101L, 42, \"payload\")\n\t\t);\n\n\t\tassertThat(result, deepEqualTo(expected, true));\n\n\t\t\r\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2020-11-05 21:08:26","endLine":181,"groupId":"33927","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSourceSinkWithKeyAndPartialValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/90/52a1769009b549c3d90d47a626252f0f799829.src","preCode":"\tpublic void testSourceSinkWithKeyAndPartialValue() throws Exception {\n\t\t\r\n\t\t\r\n\t\tfinal String topic = \"key_partial_value_topic_\" + format;\n\t\tcreateTestTopic(topic, 1, 1); \r\n\n\t\t\r\n\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n\t\t\r\n\t\t\r\n\t\tfinal String createTable = String.format(\n\t\t\t\"CREATE TABLE upsert_kafka (\\n\"\n\t\t\t\t+ \"  `k_user_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `name` STRING,\\n\"\n\t\t\t\t+ \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n\t\t\t\t+ \"  `k_event_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `user_id` INT,\\n\"\n\t\t\t\t+ \"  `payload` STRING,\\n\"\n\t\t\t\t+ \"  PRIMARY KEY (k_event_id, k_user_id) NOT ENFORCED\"\n\t\t\t\t+ \") WITH (\\n\"\n\t\t\t\t+ \"  'connector' = 'upsert-kafka',\\n\"\n\t\t\t\t+ \"  'topic' = '%s',\\n\"\n\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n\t\t\t\t+ \"  'key.format' = '%s',\\n\"\n\t\t\t\t+ \"  'key.fields-prefix' = 'k_',\\n\"\n\t\t\t\t+ \"  'value.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.fields-include' = 'EXCEPT_KEY'\\n\"\n\t\t\t\t+ \")\",\n\t\t\ttopic,\n\t\t\tbootstraps,\n\t\t\tformat,\n\t\t\tformat);\n\n\t\ttEnv.executeSql(createTable);\n\n\t\tString initialValues = \"INSERT INTO upsert_kafka\\n\"\n\t\t\t+ \"VALUES\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 41, 'payload 1'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 42, 'payload 2'),\\n\"\n\t\t\t+ \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 43, 'payload 3'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-11 13:12:11.123', 101, 42, 'payload')\";\n\t\ttEnv.executeSql(initialValues).await();\n\n\t\t\r\n\n\t\tfinal List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n\t\tfinal List<Row> expected = Arrays.asList(\n\t\t\tchangelogRow(\"+I\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, 41, \"payload 1\"),\n\t\t\tchangelogRow(\"+I\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, 42, \"payload 2\"),\n\t\t\tchangelogRow(\"+I\", 3L, \"name 3\", LocalDateTime.parse(\"2020-03-10T13:12:11.123\"), 102L, 43, \"payload 3\"),\n\t\t\tchangelogRow(\"-U\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, 42, \"payload 2\"),\n\t\t\tchangelogRow(\"+U\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-11T13:12:11.123\"), 101L, 42, \"payload\")\n\t\t);\n\n\t\tassertThat(result, deepEqualTo(expected, true));\n\n\t\t\r\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaTableITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":120,"status":"N"},{"authorDate":"2020-11-05 14:14:21","commitOrder":2,"curCode":"\tpublic void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n\t\t\r\n\t\t\r\n\t\tfinal String topic = \"key_full_value_topic_\" + format;\n\t\tcreateTestTopic(topic, 1, 1); \r\n\n\t\t\r\n\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tfinal String createTable = String.format(\n\t\t\t\"CREATE TABLE upsert_kafka (\\n\"\n\t\t\t\t+ \"  `user_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `name` STRING,\\n\"\n\t\t\t\t+ \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n\t\t\t\t+ \"  `event_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `payload` STRING,\\n\"\n\t\t\t\t+ \"  PRIMARY KEY (event_id, user_id) NOT ENFORCED\"\n\t\t\t\t+ \") WITH (\\n\"\n\t\t\t\t+ \"  'connector' = 'upsert-kafka',\\n\"\n\t\t\t\t+ \"  'topic' = '%s',\\n\"\n\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n\t\t\t\t+ \"  'key.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.fields-include' = 'ALL',\\n\"\n\t\t\t\t+ \"  'sink.parallelism' = '4'\"  \r\n\t\t\t\t+ \")\",\n\t\t\ttopic,\n\t\t\tbootstraps,\n\t\t\tformat,\n\t\t\tformat);\n\n\t\ttEnv.executeSql(createTable);\n\n\t\tString initialValues = \"INSERT INTO upsert_kafka\\n\"\n\t\t\t+ \"VALUES\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 'payload 1'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 'payload 2'),\\n\"\n\t\t\t+ \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 'payload 3'),\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-11 13:12:11.123', 100, 'payload')\";\n\t\ttEnv.executeSql(initialValues).await();\n\n\t\t\r\n\n\t\tfinal List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n\t\tfinal List<Row> expected = Arrays.asList(\n\t\t\tchangelogRow(\"+I\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, \"payload 1\"),\n\t\t\tchangelogRow(\"+I\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, \"payload 2\"),\n\t\t\tchangelogRow(\"+I\", 3L, \"name 3\", LocalDateTime.parse(\"2020-03-10T13:12:11.123\"), 102L, \"payload 3\"),\n\t\t\tchangelogRow(\"-U\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, \"payload 1\"),\n\t\t\tchangelogRow(\"+U\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-11T13:12:11.123\"), 100L, \"payload\")\n\t\t);\n\n\t\tassertThat(result, deepEqualTo(expected, true));\n\n\t\t\r\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2020-11-05 21:08:28","endLine":245,"groupId":"33927","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testKafkaSourceSinkWithKeyAndFullValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/98/048d1573f091f73bff1820abce43e9b2401863.src","preCode":"\tpublic void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n\t\t\r\n\t\t\r\n\t\tfinal String topic = \"key_full_value_topic_\" + format;\n\t\tcreateTestTopic(topic, 1, 1); \r\n\n\t\t\r\n\t\tString bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tfinal String createTable = String.format(\n\t\t\t\"CREATE TABLE upsert_kafka (\\n\"\n\t\t\t\t+ \"  `user_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `name` STRING,\\n\"\n\t\t\t\t+ \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n\t\t\t\t+ \"  `event_id` BIGINT,\\n\"\n\t\t\t\t+ \"  `payload` STRING,\\n\"\n\t\t\t\t+ \"  PRIMARY KEY (event_id, user_id) NOT ENFORCED\"\n\t\t\t\t+ \") WITH (\\n\"\n\t\t\t\t+ \"  'connector' = 'upsert-kafka',\\n\"\n\t\t\t\t+ \"  'topic' = '%s',\\n\"\n\t\t\t\t+ \"  'properties.bootstrap.servers' = '%s',\\n\"\n\t\t\t\t+ \"  'key.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.format' = '%s',\\n\"\n\t\t\t\t+ \"  'value.fields-include' = 'ALL'\\n\"\n\t\t\t\t+ \")\",\n\t\t\ttopic,\n\t\t\tbootstraps,\n\t\t\tformat,\n\t\t\tformat);\n\n\t\ttEnv.executeSql(createTable);\n\n\t\tString initialValues = \"INSERT INTO upsert_kafka\\n\"\n\t\t\t+ \"VALUES\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 'payload 1'),\\n\"\n\t\t\t+ \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 'payload 2'),\\n\"\n\t\t\t+ \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 'payload 3'),\\n\"\n\t\t\t+ \" (1, 'name 1', TIMESTAMP '2020-03-11 13:12:11.123', 100, 'payload')\";\n\t\ttEnv.executeSql(initialValues).await();\n\n\t\t\r\n\n\t\tfinal List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n\t\tfinal List<Row> expected = Arrays.asList(\n\t\t\tchangelogRow(\"+I\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, \"payload 1\"),\n\t\t\tchangelogRow(\"+I\", 2L, \"name 2\", LocalDateTime.parse(\"2020-03-09T13:12:11.123\"), 101L, \"payload 2\"),\n\t\t\tchangelogRow(\"+I\", 3L, \"name 3\", LocalDateTime.parse(\"2020-03-10T13:12:11.123\"), 102L, \"payload 3\"),\n\t\t\tchangelogRow(\"-U\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-08T13:12:11.123\"), 100L, \"payload 1\"),\n\t\t\tchangelogRow(\"+U\", 1L, \"name 1\", LocalDateTime.parse(\"2020-03-11T13:12:11.123\"), 100L, \"payload\")\n\t\t);\n\n\t\tassertThat(result, deepEqualTo(expected, true));\n\n\t\t\r\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaTableITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":183,"status":"M"}],"commitId":"f504bf576863442bab21f4293d763246cc5fe94e","commitMessage":"@@@[hotfix][upsert-kafka] Support sink parallelism on upsert-kafka sink\n","date":"2020-11-05 21:08:28","modifiedFileCount":"4","status":"M","submitter":"Jark Wu"},{"authorTime":"2021-04-14 17:15:05","codes":[{"authorDate":"2021-04-14 17:15:05","commitOrder":3,"curCode":"    public void testSourceSinkWithKeyAndPartialValue() throws Exception {\n        \r\n        \r\n        final String topic = \"key_partial_value_topic_\" + format;\n        createTestTopic(topic, 1, 1); \r\n\n        \r\n        String bootstraps = getBootstrapServers();\n\n        \r\n        \r\n        final String createTable =\n                String.format(\n                        \"CREATE TABLE upsert_kafka (\\n\"\n                                + \"  `k_user_id` BIGINT,\\n\"\n                                + \"  `name` STRING,\\n\"\n                                + \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n                                + \"  `k_event_id` BIGINT,\\n\"\n                                + \"  `user_id` INT,\\n\"\n                                + \"  `payload` STRING,\\n\"\n                                + \"  PRIMARY KEY (k_event_id, k_user_id) NOT ENFORCED\"\n                                + \") WITH (\\n\"\n                                + \"  'connector' = 'upsert-kafka',\\n\"\n                                + \"  'topic' = '%s',\\n\"\n                                + \"  'properties.bootstrap.servers' = '%s',\\n\"\n                                + \"  'key.format' = '%s',\\n\"\n                                + \"  'key.fields-prefix' = 'k_',\\n\"\n                                + \"  'value.format' = '%s',\\n\"\n                                + \"  'value.fields-include' = 'EXCEPT_KEY'\\n\"\n                                + \")\",\n                        topic, bootstraps, format, format);\n\n        tEnv.executeSql(createTable);\n\n        String initialValues =\n                \"INSERT INTO upsert_kafka\\n\"\n                        + \"VALUES\\n\"\n                        + \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 41, 'payload 1'),\\n\"\n                        + \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 42, 'payload 2'),\\n\"\n                        + \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 43, 'payload 3'),\\n\"\n                        + \" (2, 'name 2', TIMESTAMP '2020-03-11 13:12:11.123', 101, 42, 'payload')\";\n        tEnv.executeSql(initialValues).await();\n\n        \r\n\n        final List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n        final List<Row> expected =\n                Arrays.asList(\n                        changelogRow(\n                                \"+I\",\n                                1L,\n                                \"name 1\",\n                                LocalDateTime.parse(\"2020-03-08T13:12:11.123\"),\n                                100L,\n                                41,\n                                \"payload 1\"),\n                        changelogRow(\n                                \"+I\",\n                                2L,\n                                \"name 2\",\n                                LocalDateTime.parse(\"2020-03-09T13:12:11.123\"),\n                                101L,\n                                42,\n                                \"payload 2\"),\n                        changelogRow(\n                                \"+I\",\n                                3L,\n                                \"name 3\",\n                                LocalDateTime.parse(\"2020-03-10T13:12:11.123\"),\n                                102L,\n                                43,\n                                \"payload 3\"),\n                        changelogRow(\n                                \"-U\",\n                                2L,\n                                \"name 2\",\n                                LocalDateTime.parse(\"2020-03-09T13:12:11.123\"),\n                                101L,\n                                42,\n                                \"payload 2\"),\n                        changelogRow(\n                                \"+U\",\n                                2L,\n                                \"name 2\",\n                                LocalDateTime.parse(\"2020-03-11T13:12:11.123\"),\n                                101L,\n                                42,\n                                \"payload\"));\n\n        assertThat(result, deepEqualTo(expected, true));\n\n        \r\n\n        deleteTestTopic(topic);\n    }\n","date":"2021-04-14 17:15:05","endLine":197,"groupId":"10211","id":5,"instanceNumber":1,"isCurCommit":1,"methodName":"testSourceSinkWithKeyAndPartialValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/4f/9d4853fafa514b9335b645fc1712318da8f2b1.src","preCode":"    public void testSourceSinkWithKeyAndPartialValue() throws Exception {\n        \r\n        \r\n        final String topic = \"key_partial_value_topic_\" + format;\n        createTestTopic(topic, 1, 1); \r\n\n        \r\n        String bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n        \r\n        \r\n        final String createTable =\n                String.format(\n                        \"CREATE TABLE upsert_kafka (\\n\"\n                                + \"  `k_user_id` BIGINT,\\n\"\n                                + \"  `name` STRING,\\n\"\n                                + \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n                                + \"  `k_event_id` BIGINT,\\n\"\n                                + \"  `user_id` INT,\\n\"\n                                + \"  `payload` STRING,\\n\"\n                                + \"  PRIMARY KEY (k_event_id, k_user_id) NOT ENFORCED\"\n                                + \") WITH (\\n\"\n                                + \"  'connector' = 'upsert-kafka',\\n\"\n                                + \"  'topic' = '%s',\\n\"\n                                + \"  'properties.bootstrap.servers' = '%s',\\n\"\n                                + \"  'key.format' = '%s',\\n\"\n                                + \"  'key.fields-prefix' = 'k_',\\n\"\n                                + \"  'value.format' = '%s',\\n\"\n                                + \"  'value.fields-include' = 'EXCEPT_KEY'\\n\"\n                                + \")\",\n                        topic, bootstraps, format, format);\n\n        tEnv.executeSql(createTable);\n\n        String initialValues =\n                \"INSERT INTO upsert_kafka\\n\"\n                        + \"VALUES\\n\"\n                        + \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 41, 'payload 1'),\\n\"\n                        + \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 42, 'payload 2'),\\n\"\n                        + \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 43, 'payload 3'),\\n\"\n                        + \" (2, 'name 2', TIMESTAMP '2020-03-11 13:12:11.123', 101, 42, 'payload')\";\n        tEnv.executeSql(initialValues).await();\n\n        \r\n\n        final List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n        final List<Row> expected =\n                Arrays.asList(\n                        changelogRow(\n                                \"+I\",\n                                1L,\n                                \"name 1\",\n                                LocalDateTime.parse(\"2020-03-08T13:12:11.123\"),\n                                100L,\n                                41,\n                                \"payload 1\"),\n                        changelogRow(\n                                \"+I\",\n                                2L,\n                                \"name 2\",\n                                LocalDateTime.parse(\"2020-03-09T13:12:11.123\"),\n                                101L,\n                                42,\n                                \"payload 2\"),\n                        changelogRow(\n                                \"+I\",\n                                3L,\n                                \"name 3\",\n                                LocalDateTime.parse(\"2020-03-10T13:12:11.123\"),\n                                102L,\n                                43,\n                                \"payload 3\"),\n                        changelogRow(\n                                \"-U\",\n                                2L,\n                                \"name 2\",\n                                LocalDateTime.parse(\"2020-03-09T13:12:11.123\"),\n                                101L,\n                                42,\n                                \"payload 2\"),\n                        changelogRow(\n                                \"+U\",\n                                2L,\n                                \"name 2\",\n                                LocalDateTime.parse(\"2020-03-11T13:12:11.123\"),\n                                101L,\n                                42,\n                                \"payload\"));\n\n        assertThat(result, deepEqualTo(expected, true));\n\n        \r\n\n        deleteTestTopic(topic);\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaTableITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"M"},{"authorDate":"2021-04-14 17:15:05","commitOrder":3,"curCode":"    public void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n        \r\n        \r\n        final String topic = \"key_full_value_topic_\" + format;\n        createTestTopic(topic, 1, 1); \r\n\n        \r\n        String bootstraps = getBootstrapServers();\n\n        \r\n        \r\n        \r\n        \r\n        final String createTable =\n                String.format(\n                        \"CREATE TABLE upsert_kafka (\\n\"\n                                + \"  `user_id` BIGINT,\\n\"\n                                + \"  `name` STRING,\\n\"\n                                + \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n                                + \"  `event_id` BIGINT,\\n\"\n                                + \"  `payload` STRING,\\n\"\n                                + \"  PRIMARY KEY (event_id, user_id) NOT ENFORCED\"\n                                + \") WITH (\\n\"\n                                + \"  'connector' = 'upsert-kafka',\\n\"\n                                + \"  'topic' = '%s',\\n\"\n                                + \"  'properties.bootstrap.servers' = '%s',\\n\"\n                                + \"  'key.format' = '%s',\\n\"\n                                + \"  'value.format' = '%s',\\n\"\n                                + \"  'value.fields-include' = 'ALL',\\n\"\n                                + \"  'sink.parallelism' = '4'\" \r\n                                \r\n                                + \")\",\n                        topic, bootstraps, format, format);\n\n        tEnv.executeSql(createTable);\n\n        String initialValues =\n                \"INSERT INTO upsert_kafka\\n\"\n                        + \"VALUES\\n\"\n                        + \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 'payload 1'),\\n\"\n                        + \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 'payload 2'),\\n\"\n                        + \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 'payload 3'),\\n\"\n                        + \" (1, 'name 1', TIMESTAMP '2020-03-11 13:12:11.123', 100, 'payload')\";\n        tEnv.executeSql(initialValues).await();\n\n        \r\n\n        final List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n        final List<Row> expected =\n                Arrays.asList(\n                        changelogRow(\n                                \"+I\",\n                                1L,\n                                \"name 1\",\n                                LocalDateTime.parse(\"2020-03-08T13:12:11.123\"),\n                                100L,\n                                \"payload 1\"),\n                        changelogRow(\n                                \"+I\",\n                                2L,\n                                \"name 2\",\n                                LocalDateTime.parse(\"2020-03-09T13:12:11.123\"),\n                                101L,\n                                \"payload 2\"),\n                        changelogRow(\n                                \"+I\",\n                                3L,\n                                \"name 3\",\n                                LocalDateTime.parse(\"2020-03-10T13:12:11.123\"),\n                                102L,\n                                \"payload 3\"),\n                        changelogRow(\n                                \"-U\",\n                                1L,\n                                \"name 1\",\n                                LocalDateTime.parse(\"2020-03-08T13:12:11.123\"),\n                                100L,\n                                \"payload 1\"),\n                        changelogRow(\n                                \"+U\",\n                                1L,\n                                \"name 1\",\n                                LocalDateTime.parse(\"2020-03-11T13:12:11.123\"),\n                                100L,\n                                \"payload\"));\n\n        assertThat(result, deepEqualTo(expected, true));\n\n        \r\n\n        deleteTestTopic(topic);\n    }\n","date":"2021-04-14 17:15:05","endLine":292,"groupId":"10211","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"testKafkaSourceSinkWithKeyAndFullValue","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/4f/9d4853fafa514b9335b645fc1712318da8f2b1.src","preCode":"    public void testKafkaSourceSinkWithKeyAndFullValue() throws Exception {\n        \r\n        \r\n        final String topic = \"key_full_value_topic_\" + format;\n        createTestTopic(topic, 1, 1); \r\n\n        \r\n        String bootstraps = standardProps.getProperty(\"bootstrap.servers\");\n\n        \r\n        \r\n        \r\n        \r\n        final String createTable =\n                String.format(\n                        \"CREATE TABLE upsert_kafka (\\n\"\n                                + \"  `user_id` BIGINT,\\n\"\n                                + \"  `name` STRING,\\n\"\n                                + \"  `timestamp` TIMESTAMP(3) METADATA,\\n\"\n                                + \"  `event_id` BIGINT,\\n\"\n                                + \"  `payload` STRING,\\n\"\n                                + \"  PRIMARY KEY (event_id, user_id) NOT ENFORCED\"\n                                + \") WITH (\\n\"\n                                + \"  'connector' = 'upsert-kafka',\\n\"\n                                + \"  'topic' = '%s',\\n\"\n                                + \"  'properties.bootstrap.servers' = '%s',\\n\"\n                                + \"  'key.format' = '%s',\\n\"\n                                + \"  'value.format' = '%s',\\n\"\n                                + \"  'value.fields-include' = 'ALL',\\n\"\n                                + \"  'sink.parallelism' = '4'\" \r\n                                \r\n                                + \")\",\n                        topic, bootstraps, format, format);\n\n        tEnv.executeSql(createTable);\n\n        String initialValues =\n                \"INSERT INTO upsert_kafka\\n\"\n                        + \"VALUES\\n\"\n                        + \" (1, 'name 1', TIMESTAMP '2020-03-08 13:12:11.123', 100, 'payload 1'),\\n\"\n                        + \" (2, 'name 2', TIMESTAMP '2020-03-09 13:12:11.123', 101, 'payload 2'),\\n\"\n                        + \" (3, 'name 3', TIMESTAMP '2020-03-10 13:12:11.123', 102, 'payload 3'),\\n\"\n                        + \" (1, 'name 1', TIMESTAMP '2020-03-11 13:12:11.123', 100, 'payload')\";\n        tEnv.executeSql(initialValues).await();\n\n        \r\n\n        final List<Row> result = collectRows(tEnv.sqlQuery(\"SELECT * FROM upsert_kafka\"), 5);\n\n        final List<Row> expected =\n                Arrays.asList(\n                        changelogRow(\n                                \"+I\",\n                                1L,\n                                \"name 1\",\n                                LocalDateTime.parse(\"2020-03-08T13:12:11.123\"),\n                                100L,\n                                \"payload 1\"),\n                        changelogRow(\n                                \"+I\",\n                                2L,\n                                \"name 2\",\n                                LocalDateTime.parse(\"2020-03-09T13:12:11.123\"),\n                                101L,\n                                \"payload 2\"),\n                        changelogRow(\n                                \"+I\",\n                                3L,\n                                \"name 3\",\n                                LocalDateTime.parse(\"2020-03-10T13:12:11.123\"),\n                                102L,\n                                \"payload 3\"),\n                        changelogRow(\n                                \"-U\",\n                                1L,\n                                \"name 1\",\n                                LocalDateTime.parse(\"2020-03-08T13:12:11.123\"),\n                                100L,\n                                \"payload 1\"),\n                        changelogRow(\n                                \"+U\",\n                                1L,\n                                \"name 1\",\n                                LocalDateTime.parse(\"2020-03-11T13:12:11.123\"),\n                                100L,\n                                \"payload\"));\n\n        assertThat(result, deepEqualTo(expected, true));\n\n        \r\n\n        deleteTestTopic(topic);\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaTableITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":200,"status":"M"}],"commitId":"e0e11f62470061914dc00cd2504edbd7d43baf8e","commitMessage":"@@@[FLINK-21431][kafka] Use testcontainers for Kafka table IT cases\n\nThis closes #15578","date":"2021-04-14 17:15:05","modifiedFileCount":"3","status":"M","submitter":"Leonard Xu"}]
