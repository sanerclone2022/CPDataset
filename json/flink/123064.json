[{"authorTime":"2018-07-17 17:52:02","codes":[{"authorDate":"2018-07-17 17:52:02","commitOrder":2,"curCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","date":"2018-07-20 22:12:29","endLine":271,"groupId":"7885","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testCommitStagedFilesInCorrectOrder","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6e/942e95d4637be2f65487bc44c9ba5bcb627e5b.src","preCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/LocalStreamingFileSinkTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"MB"},{"authorDate":"2018-07-17 17:52:02","commitOrder":2,"curCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.create()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal Bucketer<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactory<>());\n\t}\n","date":"2018-07-20 22:12:29","endLine":78,"groupId":"40999","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createRescalingTestSink","params":"(FileoutDir@inttotalParallelism@inttaskIdx@longinactivityInterval@longpartMaxSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/18/4e23ee458b40a144fa0c79c614aed46fc48d1e.src","preCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.create()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal Bucketer<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactory<>());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/TestUtils.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":47,"status":"B"}],"commitId":"b56c75ca375049b1d2c80d2d0945ae1ae04eb39e","commitMessage":"@@@[FLINK-9903] [DataStream API] Refactor StreamingFileSink / add bulk encoders\n\n* Add supports for bulk encoders.\n* Expose more options in the rolling policy and\n* Allows to return any object as bucket id from the bucketer.\n","date":"2018-07-20 22:12:29","modifiedFileCount":"14","status":"M","submitter":"kkloudas"},{"authorTime":"2018-07-20 23:03:16","codes":[{"authorDate":"2018-07-17 17:52:02","commitOrder":3,"curCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","date":"2018-07-20 22:12:29","endLine":271,"groupId":"7885","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testCommitStagedFilesInCorrectOrder","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6e/942e95d4637be2f65487bc44c9ba5bcb627e5b.src","preCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/LocalStreamingFileSinkTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"N"},{"authorDate":"2018-07-20 23:03:16","commitOrder":3,"curCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.create()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal Bucketer<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactory<>());\n\t}\n","date":"2018-07-23 20:15:02","endLine":78,"groupId":"40999","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"createRescalingTestSink","params":"(FileoutDir@inttotalParallelism@inttaskIdx@longinactivityInterval@longpartMaxSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/95/89c5acb82774a11196c8a57f42d9e99476dd41.src","preCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.create()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal Bucketer<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactory<>());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/TestUtils.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":47,"status":"M"}],"commitId":"9e348d32c5182ea0a3c2b0dfd03560806b029d9d","commitMessage":"@@@[FLINK-9921][DataStream API] Update RollingPolicy interface\n","date":"2018-07-23 20:15:02","modifiedFileCount":"8","status":"M","submitter":"kkloudas"},{"authorTime":"2018-07-30 17:37:41","codes":[{"authorDate":"2018-07-17 17:52:02","commitOrder":4,"curCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","date":"2018-07-20 22:12:29","endLine":271,"groupId":"7885","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testCommitStagedFilesInCorrectOrder","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6e/942e95d4637be2f65487bc44c9ba5bcb627e5b.src","preCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/LocalStreamingFileSinkTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"N"},{"authorDate":"2018-07-30 17:37:41","commitOrder":4,"curCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.create()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal BucketAssigner<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","date":"2018-08-03 00:58:33","endLine":77,"groupId":"40999","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"createRescalingTestSink","params":"(FileoutDir@inttotalParallelism@inttaskIdx@longinactivityInterval@longpartMaxSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/bf/bc12043ee963714a0a5a333a140243ca671d59.src","preCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.create()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal Bucketer<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactory<>());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/TestUtils.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":46,"status":"M"}],"commitId":"1b0baa162bd87efd69040eb787de8d6624f14c85","commitMessage":"@@@[FLINK-10029][DataStream API] Refactoring the StreamingFileSink code.\n","date":"2018-08-03 00:58:33","modifiedFileCount":"17","status":"M","submitter":"kkloudas"},{"authorTime":"2019-08-27 18:30:22","codes":[{"authorDate":"2018-07-17 17:52:02","commitOrder":5,"curCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","date":"2018-07-20 22:12:29","endLine":271,"groupId":"7885","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testCommitStagedFilesInCorrectOrder","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6e/942e95d4637be2f65487bc44c9ba5bcb627e5b.src","preCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/LocalStreamingFileSinkTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"N"},{"authorDate":"2019-08-27 18:30:22","commitOrder":5,"curCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal BucketAssigner<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","date":"2019-08-27 18:56:34","endLine":87,"groupId":"40999","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"createRescalingTestSink","params":"(FileoutDir@inttotalParallelism@inttaskIdx@longinactivityInterval@longpartMaxSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/55/ba6d33e183748c193954247d49672c3f2c0b4c.src","preCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.create()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal BucketAssigner<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/TestUtils.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":56,"status":"M"}],"commitId":"ba151c6b278ac7b25b7c514711639cdbd270e1fd","commitMessage":"@@@[FLINK-13832] Rename DefaultRollingPolicy create to builder\n\nCloses #9527\n","date":"2019-08-27 18:56:34","modifiedFileCount":"7","status":"M","submitter":"Gyula Fora"},{"authorTime":"2019-08-30 15:44:27","codes":[{"authorDate":"2018-07-17 17:52:02","commitOrder":6,"curCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","date":"2018-07-20 22:12:29","endLine":271,"groupId":"7885","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testCommitStagedFilesInCorrectOrder","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6e/942e95d4637be2f65487bc44c9ba5bcb627e5b.src","preCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/LocalStreamingFileSinkTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"N"},{"authorDate":"2019-08-30 15:44:27","commitOrder":6,"curCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\treturn createRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tnew TupleToStringBucketer(),\n\t\t\t\tnew Tuple2Encoder(),\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","date":"2019-09-23 17:43:14","endLine":83,"groupId":"15897","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"createRescalingTestSink","params":"(FileoutDir@inttotalParallelism@inttaskIdx@longinactivityInterval@longpartMaxSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c1/7a2d6a24ab305a749e2852c80148d9a6fcb96a.src","preCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\tfinal BucketAssigner<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer();\n\n\t\tfinal Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {\n\t\t\tstream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8));\n\t\t\tstream.write('\\n');\n\t\t};\n\n\t\treturn createCustomRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tbucketer,\n\t\t\t\tencoder,\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/TestUtils.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"}],"commitId":"adfe011bc6fed36e30b3078bd3b6dbc0953f2ddf","commitMessage":"@@@[FLINK-13864][fs-connector] Make StreamingFileSink extensible\n\nThis PR makes the StreamingFileSink protected and the builders\nmutable so that they can be subclassed. In order for the user\nto subclass the StreamingFileSink.  he has to override the\nforRowFormat/forBulkFormat depending on his needs and the\ncorresponding builder so its the build() method returns the\nsubclass and not the original StreamingFileSink.\n","date":"2019-09-23 17:43:14","modifiedFileCount":"4","status":"M","submitter":"Ying"},{"authorTime":"2020-12-28 21:30:59","codes":[{"authorDate":"2018-07-17 17:52:02","commitOrder":7,"curCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","date":"2018-07-20 22:12:29","endLine":271,"groupId":"123064","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testCommitStagedFilesInCorrectOrder","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/6e/942e95d4637be2f65487bc44c9ba5bcb627e5b.src","preCode":"\tpublic void testCommitStagedFilesInCorrectOrder() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\n\t\t\r\n\t\ttry (OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness = TestUtils.createRescalingTestSink(\n\t\t\t\toutDir, 1, 0, 100L, 10L)) {\n\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 2), 2L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 3), 3L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.snapshot(1L, 1L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 4), 4L));\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 5), 5L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 6), 6L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);                    \r\n\n\t\t\ttestHarness.snapshot(2L, 2L);\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 7), 7L));\n\t\t\tTestUtils.checkLocalFs(outDir, 4, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\n\t\t\ttestHarness.snapshot(3L, 3L);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 1);\n\n\t\t\tint fileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-1.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-2.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().contains(\".part-0-3.inprogress\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(3L);\t\t\t\t\t\t\t\r\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\tfileCounter = 0;\n\t\t\tfor (Map.Entry<File, String> fileContents : TestUtils.getFileContentByPath(outDir).entrySet()) {\n\t\t\t\tif (fileContents.getKey().getName().equals(\"part-0-0\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@1\\ntest1@2\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-1\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@3\\ntest1@4\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-2\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@5\\ntest1@6\\n\", fileContents.getValue());\n\t\t\t\t} else if (fileContents.getKey().getName().equals(\"part-0-3\")) {\n\t\t\t\t\tfileCounter++;\n\t\t\t\t\tAssert.assertEquals(\"test1@7\\n\", fileContents.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t\tAssert.assertEquals(4L, fileCounter);\n\t\t}\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/LocalStreamingFileSinkTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":186,"status":"N"},{"authorDate":"2020-12-28 21:30:59","commitOrder":7,"curCode":"            createRescalingTestSink(\n                    File outDir,\n                    int totalParallelism,\n                    int taskIdx,\n                    long inactivityInterval,\n                    long partMaxSize)\n                    throws Exception {\n\n        final RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n                DefaultRollingPolicy.builder()\n                        .withMaxPartSize(partMaxSize)\n                        .withRolloverInterval(inactivityInterval)\n                        .withInactivityInterval(inactivityInterval)\n                        .build();\n\n        return createRescalingTestSink(\n                outDir,\n                totalParallelism,\n                taskIdx,\n                10L,\n                new TupleToStringBucketer(),\n                new Tuple2Encoder(),\n                rollingPolicy,\n                new DefaultBucketFactoryImpl<>());\n    }\n","date":"2020-12-28 21:35:13","endLine":84,"groupId":"123064","id":12,"instanceNumber":2,"isCurCommit":1,"methodName":"createRescalingTestSink","params":"(FileoutDir@inttotalParallelism@inttaskIdx@longinactivityInterval@longpartMaxSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e2/143bee07235996d5c021a7cb9be45ef618b738.src","preCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\treturn createRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tnew TupleToStringBucketer(),\n\t\t\t\tnew Tuple2Encoder(),\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/TestUtils.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"}],"commitId":"c6997c97c575d334679915c328792b8a3067cfb5","commitMessage":"@@@[FLINK-20651] Format code with Spotless/google-java-format\n","date":"2020-12-28 21:35:13","modifiedFileCount":"11013","status":"M","submitter":"Rufus Refactor"}]
