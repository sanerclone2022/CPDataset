[{"authorTime":"2019-08-30 15:44:27","codes":[{"authorDate":"2019-08-30 15:44:27","commitOrder":5,"curCode":"\tpublic void testClosingWithCustomizedBucketer() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\t\tfinal long partMaxSize = 2L;\n\t\tfinal long inactivityInterval = 100L;\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, Integer> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\ttry (\n\t\t\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness =\n\t\t\t\t\t\tTestUtils.createCustomizedRescalingTestSink(outDir, 1, 0, 100L, new TupleToIntegerBucketer(), new Tuple2Encoder(), rollingPolicy, new DefaultBucketFactoryImpl<>());\n\t\t) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test2\", 2), 1L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test3\", 3), 1L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);\n\n\t\t\ttestHarness.snapshot(0L, 1L);\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0L);\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 3);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test4\", 4), 10L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 3);\n\n\t\t\ttestHarness.snapshot(1L, 0L);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\n\t\t}\n\n\t\t\r\n\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\r\n\t\tMap<File, String> contents = TestUtils.getFileContentByPath(outDir);\n\t\tfor (Map.Entry<File, String> fileContents : contents.entrySet()) {\n\t\t\tInteger bucketId = Integer.parseInt(fileContents.getKey().getParentFile().getName());\n\n\t\t\tAssert.assertTrue(bucketId >= 1 && bucketId <= 4);\n\t\t\tAssert.assertEquals(String.format(\"test%d@%d\\n\", bucketId, bucketId), fileContents.getValue());\n\t\t}\n\t}\n","date":"2019-09-23 17:43:14","endLine":466,"groupId":"3385","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testClosingWithCustomizedBucketer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/82/033756791d4922d06613417bfffeeb783e831b.src","preCode":"\tpublic void testClosingWithCustomizedBucketer() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\t\tfinal long partMaxSize = 2L;\n\t\tfinal long inactivityInterval = 100L;\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, Integer> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\ttry (\n\t\t\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness =\n\t\t\t\t\t\tTestUtils.createCustomizedRescalingTestSink(outDir, 1, 0, 100L, new TupleToIntegerBucketer(), new Tuple2Encoder(), rollingPolicy, new DefaultBucketFactoryImpl<>());\n\t\t) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test2\", 2), 1L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test3\", 3), 1L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);\n\n\t\t\ttestHarness.snapshot(0L, 1L);\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0L);\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 3);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test4\", 4), 10L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 3);\n\n\t\t\ttestHarness.snapshot(1L, 0L);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\n\t\t}\n\n\t\t\r\n\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\r\n\t\tMap<File, String> contents = TestUtils.getFileContentByPath(outDir);\n\t\tfor (Map.Entry<File, String> fileContents : contents.entrySet()) {\n\t\t\tInteger bucketId = Integer.parseInt(fileContents.getKey().getParentFile().getName());\n\n\t\t\tAssert.assertTrue(bucketId >= 1 && bucketId <= 4);\n\t\t\tAssert.assertEquals(String.format(\"test%d@%d\\n\", bucketId, bucketId), fileContents.getValue());\n\t\t}\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/LocalStreamingFileSinkTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"B"},{"authorDate":"2019-08-30 15:44:27","commitOrder":5,"curCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\treturn createRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tnew TupleToStringBucketer(),\n\t\t\t\tnew Tuple2Encoder(),\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","date":"2019-09-23 17:43:14","endLine":83,"groupId":"15897","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"createRescalingTestSink","params":"(FileoutDir@inttotalParallelism@inttaskIdx@longinactivityInterval@longpartMaxSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c1/7a2d6a24ab305a749e2852c80148d9a6fcb96a.src","preCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\treturn createRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tnew TupleToStringBucketer(),\n\t\t\t\tnew Tuple2Encoder(),\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/TestUtils.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"MB"}],"commitId":"adfe011bc6fed36e30b3078bd3b6dbc0953f2ddf","commitMessage":"@@@[FLINK-13864][fs-connector] Make StreamingFileSink extensible\n\nThis PR makes the StreamingFileSink protected and the builders\nmutable so that they can be subclassed. In order for the user\nto subclass the StreamingFileSink.  he has to override the\nforRowFormat/forBulkFormat depending on his needs and the\ncorresponding builder so its the build() method returns the\nsubclass and not the original StreamingFileSink.\n","date":"2019-09-23 17:43:14","modifiedFileCount":"4","status":"M","submitter":"Ying"},{"authorTime":"2020-12-28 21:30:59","codes":[{"authorDate":"2019-08-30 15:44:27","commitOrder":6,"curCode":"\tpublic void testClosingWithCustomizedBucketer() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\t\tfinal long partMaxSize = 2L;\n\t\tfinal long inactivityInterval = 100L;\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, Integer> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\ttry (\n\t\t\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness =\n\t\t\t\t\t\tTestUtils.createCustomizedRescalingTestSink(outDir, 1, 0, 100L, new TupleToIntegerBucketer(), new Tuple2Encoder(), rollingPolicy, new DefaultBucketFactoryImpl<>());\n\t\t) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test2\", 2), 1L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test3\", 3), 1L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);\n\n\t\t\ttestHarness.snapshot(0L, 1L);\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0L);\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 3);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test4\", 4), 10L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 3);\n\n\t\t\ttestHarness.snapshot(1L, 0L);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\n\t\t}\n\n\t\t\r\n\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\r\n\t\tMap<File, String> contents = TestUtils.getFileContentByPath(outDir);\n\t\tfor (Map.Entry<File, String> fileContents : contents.entrySet()) {\n\t\t\tInteger bucketId = Integer.parseInt(fileContents.getKey().getParentFile().getName());\n\n\t\t\tAssert.assertTrue(bucketId >= 1 && bucketId <= 4);\n\t\t\tAssert.assertEquals(String.format(\"test%d@%d\\n\", bucketId, bucketId), fileContents.getValue());\n\t\t}\n\t}\n","date":"2019-09-23 17:43:14","endLine":466,"groupId":"123067","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testClosingWithCustomizedBucketer","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/82/033756791d4922d06613417bfffeeb783e831b.src","preCode":"\tpublic void testClosingWithCustomizedBucketer() throws Exception {\n\t\tfinal File outDir = TEMP_FOLDER.newFolder();\n\t\tfinal long partMaxSize = 2L;\n\t\tfinal long inactivityInterval = 100L;\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, Integer> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\ttry (\n\t\t\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> testHarness =\n\t\t\t\t\t\tTestUtils.createCustomizedRescalingTestSink(outDir, 1, 0, 100L, new TupleToIntegerBucketer(), new Tuple2Encoder(), rollingPolicy, new DefaultBucketFactoryImpl<>());\n\t\t) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\n\t\t\ttestHarness.setProcessingTime(0L);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test1\", 1), 1L));\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test2\", 2), 1L));\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\t\r\n\t\t\ttestHarness.setProcessingTime(101L);\n\t\t\tTestUtils.checkLocalFs(outDir, 2, 0);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test3\", 3), 1L));\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);\n\n\t\t\ttestHarness.snapshot(0L, 1L);\n\t\t\tTestUtils.checkLocalFs(outDir, 3, 0);\n\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0L);\n\t\t\tTestUtils.checkLocalFs(outDir, 0, 3);\n\n\t\t\ttestHarness.processElement(new StreamRecord<>(Tuple2.of(\"test4\", 4), 10L));\n\t\t\tTestUtils.checkLocalFs(outDir, 1, 3);\n\n\t\t\ttestHarness.snapshot(1L, 0L);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(1L);\n\t\t}\n\n\t\t\r\n\t\tTestUtils.checkLocalFs(outDir, 0, 4);\n\n\t\t\r\n\t\tMap<File, String> contents = TestUtils.getFileContentByPath(outDir);\n\t\tfor (Map.Entry<File, String> fileContents : contents.entrySet()) {\n\t\t\tInteger bucketId = Integer.parseInt(fileContents.getKey().getParentFile().getName());\n\n\t\t\tAssert.assertTrue(bucketId >= 1 && bucketId <= 4);\n\t\t\tAssert.assertEquals(String.format(\"test%d@%d\\n\", bucketId, bucketId), fileContents.getValue());\n\t\t}\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/LocalStreamingFileSinkTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":410,"status":"N"},{"authorDate":"2020-12-28 21:30:59","commitOrder":6,"curCode":"            createRescalingTestSink(\n                    File outDir,\n                    int totalParallelism,\n                    int taskIdx,\n                    long inactivityInterval,\n                    long partMaxSize)\n                    throws Exception {\n\n        final RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n                DefaultRollingPolicy.builder()\n                        .withMaxPartSize(partMaxSize)\n                        .withRolloverInterval(inactivityInterval)\n                        .withInactivityInterval(inactivityInterval)\n                        .build();\n\n        return createRescalingTestSink(\n                outDir,\n                totalParallelism,\n                taskIdx,\n                10L,\n                new TupleToStringBucketer(),\n                new Tuple2Encoder(),\n                rollingPolicy,\n                new DefaultBucketFactoryImpl<>());\n    }\n","date":"2020-12-28 21:35:13","endLine":84,"groupId":"123067","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"createRescalingTestSink","params":"(FileoutDir@inttotalParallelism@inttaskIdx@longinactivityInterval@longpartMaxSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e2/143bee07235996d5c021a7cb9be45ef618b738.src","preCode":"\tstatic OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(\n\t\t\tFile outDir,\n\t\t\tint totalParallelism,\n\t\t\tint taskIdx,\n\t\t\tlong inactivityInterval,\n\t\t\tlong partMaxSize) throws Exception {\n\n\t\tfinal RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy =\n\t\t\t\tDefaultRollingPolicy\n\t\t\t\t\t\t.builder()\n\t\t\t\t\t\t.withMaxPartSize(partMaxSize)\n\t\t\t\t\t\t.withRolloverInterval(inactivityInterval)\n\t\t\t\t\t\t.withInactivityInterval(inactivityInterval)\n\t\t\t\t\t\t.build();\n\n\t\treturn createRescalingTestSink(\n\t\t\t\toutDir,\n\t\t\t\ttotalParallelism,\n\t\t\t\ttaskIdx,\n\t\t\t\t10L,\n\t\t\t\tnew TupleToStringBucketer(),\n\t\t\t\tnew Tuple2Encoder(),\n\t\t\t\trollingPolicy,\n\t\t\t\tnew DefaultBucketFactoryImpl<>());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/api/functions/sink/filesystem/TestUtils.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"M"}],"commitId":"c6997c97c575d334679915c328792b8a3067cfb5","commitMessage":"@@@[FLINK-20651] Format code with Spotless/google-java-format\n","date":"2020-12-28 21:35:13","modifiedFileCount":"11013","status":"M","submitter":"Rufus Refactor"}]
