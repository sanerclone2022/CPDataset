[{"authorTime":"2020-05-16 02:06:46","codes":[{"authorDate":"2020-05-16 02:06:40","commitOrder":2,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createSinkFormat(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-05-17 22:34:39","endLine":150,"groupId":"26657","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/40/76b63df89376ee706aaf5732cef782f46dc254.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createSinkFormat(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"NB"},{"authorDate":"2020-05-16 02:06:46","commitOrder":2,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createSinkFormat(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-05-17 22:34:47","endLine":150,"groupId":"26657","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ea/df659f90dd4d15b7922b69d894e87d6e5de48f.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createSinkFormat(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"B"}],"commitId":"ccd2d531d1cb577113d5021efd6277031eeef9d1","commitMessage":"@@@[FLINK-17027] Introduce a new Elasticsearch 6 connector with new property keys\n\nThis closes #12184\n","date":"2020-05-17 22:34:47","modifiedFileCount":"0","status":"M","submitter":"Dawid Wysakowicz"},{"authorTime":"2020-06-01 10:32:40","codes":[{"authorDate":"2020-06-01 10:32:40","commitOrder":3,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-06-01 10:32:40","endLine":150,"groupId":"26657","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/40/8673ef4b61ba48a987f974a5ee7d2db52d8642.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createSinkFormat(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"},{"authorDate":"2020-06-01 10:32:40","commitOrder":3,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-06-01 10:32:40","endLine":150,"groupId":"26657","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/be/dfbef8c7c0589e322e62378740130a627a6243.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createSinkFormat(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"}],"commitId":"64de78e36500b5a8c8720639ded4d1c5f963ad41","commitMessage":"@@@[FLINK-17887][table][connector] Improve interface of ScanFormatFactory and SinkFormatFactory\n\n\nWe improved the interfaces with the following changes:\n1. Have a common interface DynamicTableSource.Context.  and make Context of ScanTableSource and LookupTableSource extend it.  and rename them to LookupContext and ScanContext\n2. Change parameter of ScanFormat.createScanFormat from ScanTableSource.Context to DynamicTableSource.Context\n3. Rename ScanFormat.createScanFormat to DecodingFormat#createRuntimeDecoder()\n4. Rename SinkFormat.createSinkFormat to EncodingFormat#createRuntimeEncoder()\n5. Rename ScanFormatFactory to DecodingFormatFactory\n6. Rename SinkFormatFactory to EncodingFormatFactory\n\nThis closes #12320","date":"2020-06-01 10:32:40","modifiedFileCount":"48","status":"M","submitter":"Jark Wu"},{"authorTime":"2020-06-02 23:09:26","codes":[{"authorDate":"2020-06-02 23:09:26","commitOrder":4,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-06-04 15:13:30","endLine":151,"groupId":"26657","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/7a/a52eaf21d4c49bf2bbc00c417499f4a126b64d.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"},{"authorDate":"2020-06-02 23:09:26","commitOrder":4,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-06-04 15:13:30","endLine":151,"groupId":"26657","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/68/0cb2c3eac4f89bed6c5348627c56f3d80d06de.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\tconfig.getPathPrefix()\n\t\t\t\t.ifPresent(pathPrefix -> builder.setRestClientFactory(new DefaultRestClientFactory(pathPrefix)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"}],"commitId":"640a56fee9d777ff2acb69ab6d77275e7373415d","commitMessage":"@@@[FLINK-18006] Always overwrite RestClientFactory in ElasticsearchXDynamicSink\n\nWe always overwrite the RestClientFactory in order to workaround an\nissue with shading classes in lambdas deserialization method. That way\nwe never use the default lambda from ElasticsearchSink$Builder which\ncannot be deserialized when used from a\nflink-sql-connector-elasticsearch module due to shading.\n\nThis closes #12455\n","date":"2020-06-04 15:13:30","modifiedFileCount":"2","status":"M","submitter":"Dawid Wysakowicz"},{"authorTime":"2020-06-09 10:47:15","codes":[{"authorDate":"2020-06-09 10:47:15","commitOrder":5,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tbuilder.setBulkFlushMaxActions(config.getBulkFlushMaxActions());\n\t\t\tbuilder.setBulkFlushMaxSizeMb((int) (config.getBulkFlushMaxByteSize() >> 20));\n\t\t\tbuilder.setBulkFlushInterval(config.getBulkFlushInterval());\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-06-11 17:02:46","endLine":151,"groupId":"42397","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/22/13ce8a6baf294c101e1f8165ff03cd9f20c4c8.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"},{"authorDate":"2020-06-09 10:47:15","commitOrder":5,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tbuilder.setBulkFlushMaxActions(config.getBulkFlushMaxActions());\n\t\t\tbuilder.setBulkFlushMaxSizeMb((int) (config.getBulkFlushMaxByteSize() >> 20));\n\t\t\tbuilder.setBulkFlushInterval(config.getBulkFlushInterval());\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-06-11 17:02:46","endLine":151,"groupId":"42397","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/4e/9a8f85f784ae36a956d46fba5f8d3ce7ec1ab2.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tconfig.getBulkFlushMaxActions().ifPresent(builder::setBulkFlushMaxActions);\n\t\t\tconfig.getBulkFlushMaxSize().ifPresent(builder::setBulkFlushMaxSizeMb);\n\t\t\tconfig.getBulkFlushInterval().ifPresent(builder::setBulkFlushInterval);\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":112,"status":"M"}],"commitId":"3d764dc7b21dde54e0bcd61e51546daa77ce3f12","commitMessage":"@@@[FLINK-16495][elasticsearch][table] Improve default flush strategy for new Elasticsearch sink for better out-of-box\n\nThe default flush strategy for old Elasticsearch sink is no flush interval and 5MB buffered size and 1000 rows.\nThe new default flush strategy for new Elasticsearch sink is '1s' flush interval and '1000' buffered rows and '2mb' buffered size.\n\nThis closes #12536\n","date":"2020-06-11 17:02:46","modifiedFileCount":"12","status":"M","submitter":"Jark Wu"},{"authorTime":"2020-07-10 16:41:08","codes":[{"authorDate":"2020-07-10 16:41:08","commitOrder":6,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tbuilder.setBulkFlushMaxActions(config.getBulkFlushMaxActions());\n\t\t\tbuilder.setBulkFlushMaxSizeMb((int) (config.getBulkFlushMaxByteSize() >> 20));\n\t\t\tbuilder.setBulkFlushInterval(config.getBulkFlushInterval());\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tif (config.getUsername().isPresent()\n\t\t\t\t&& config.getPassword().isPresent()\n\t\t\t\t&& !StringUtils.isNullOrWhitespaceOnly(config.getUsername().get())\n\t\t\t\t&& !StringUtils.isNullOrWhitespaceOnly(config.getPassword().get())) {\n\t\t\t\tbuilder.setRestClientFactory(new AuthRestClientFactory(config.getPathPrefix().orElse(null), config.getUsername().get(), config.getPassword().get()));\n\t\t\t} else {\n\t\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\t\t\t}\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-07-10 16:41:08","endLine":163,"groupId":"10833","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/52/efbe1c43b1d4d2e0af0ca0708fbca6190d892e.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tnull, \r\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tbuilder.setBulkFlushMaxActions(config.getBulkFlushMaxActions());\n\t\t\tbuilder.setBulkFlushMaxSizeMb((int) (config.getBulkFlushMaxByteSize() >> 20));\n\t\t\tbuilder.setBulkFlushInterval(config.getBulkFlushInterval());\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":117,"status":"M"},{"authorDate":"2020-07-10 16:41:08","commitOrder":6,"curCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tbuilder.setBulkFlushMaxActions(config.getBulkFlushMaxActions());\n\t\t\tbuilder.setBulkFlushMaxSizeMb((int) (config.getBulkFlushMaxByteSize() >> 20));\n\t\t\tbuilder.setBulkFlushInterval(config.getBulkFlushInterval());\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tif (config.getUsername().isPresent()\n\t\t\t\t&& config.getPassword().isPresent()\n\t\t\t\t&& !StringUtils.isNullOrWhitespaceOnly(config.getUsername().get())\n\t\t\t\t&& !StringUtils.isNullOrWhitespaceOnly(config.getPassword().get())) {\n\t\t\t\tbuilder.setRestClientFactory(new AuthRestClientFactory(config.getPathPrefix().orElse(null), config.getUsername().get(), config.getPassword().get()));\n\t\t\t} else {\n\t\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\t\t\t}\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","date":"2020-07-10 16:41:08","endLine":163,"groupId":"10833","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"getSinkRuntimeProvider","params":"(Contextcontext)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/81/97817e2368a9d19bb694507533bb7dc4d2bb8c.src","preCode":"\tpublic SinkFunctionProvider getSinkRuntimeProvider(Context context) {\n\t\treturn () -> {\n\t\t\tSerializationSchema<RowData> format = this.format.createRuntimeEncoder(context, schema.toRowDataType());\n\n\t\t\tfinal RowElasticsearchSinkFunction upsertFunction =\n\t\t\t\tnew RowElasticsearchSinkFunction(\n\t\t\t\t\tIndexGeneratorFactory.createIndexGenerator(config.getIndex(), schema),\n\t\t\t\t\tconfig.getDocumentType(),\n\t\t\t\t\tformat,\n\t\t\t\t\tXContentType.JSON,\n\t\t\t\t\tREQUEST_FACTORY,\n\t\t\t\t\tKeyExtractor.createKeyExtractor(schema, config.getKeyDelimiter())\n\t\t\t\t);\n\n\t\t\tfinal ElasticsearchSink.Builder<RowData> builder = builderProvider.createBuilder(\n\t\t\t\tconfig.getHosts(),\n\t\t\t\tupsertFunction);\n\n\t\t\tbuilder.setFailureHandler(config.getFailureHandler());\n\t\t\tbuilder.setBulkFlushMaxActions(config.getBulkFlushMaxActions());\n\t\t\tbuilder.setBulkFlushMaxSizeMb((int) (config.getBulkFlushMaxByteSize() >> 20));\n\t\t\tbuilder.setBulkFlushInterval(config.getBulkFlushInterval());\n\t\t\tbuilder.setBulkFlushBackoff(config.isBulkFlushBackoffEnabled());\n\t\t\tconfig.getBulkFlushBackoffType().ifPresent(builder::setBulkFlushBackoffType);\n\t\t\tconfig.getBulkFlushBackoffRetries().ifPresent(builder::setBulkFlushBackoffRetries);\n\t\t\tconfig.getBulkFlushBackoffDelay().ifPresent(builder::setBulkFlushBackoffDelay);\n\n\t\t\t\r\n\t\t\t\r\n\t\t\tbuilder.setRestClientFactory(new DefaultRestClientFactory(config.getPathPrefix().orElse(null)));\n\n\t\t\tfinal ElasticsearchSink<RowData> sink = builder.build();\n\n\t\t\tif (config.isDisableFlushOnCheckpoint()) {\n\t\t\t\tsink.disableFlushOnCheckpoint();\n\t\t\t}\n\n\t\t\treturn sink;\n\t\t};\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/main/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSink.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":117,"status":"M"}],"commitId":"ee653778689023ddfdf007d5bde1daad8fbbc081","commitMessage":"@@@[FLINK-18361][es][table] Support username and password options for new Elasticsearch connector\n\nCo-authored-by: zhisheng17 <zhisheng2018@gmail.com>\n\nThis closes #12715","date":"2020-07-10 16:41:08","modifiedFileCount":"10","status":"M","submitter":"Yangze Guo"}]
