[{"authorTime":"2016-10-19 00:32:17","codes":[{"authorDate":"2016-11-01 07:21:04","commitOrder":7,"curCode":"\tpublic void testDeltaEvictorEvictAfter() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\t\tfinal int TRIGGER_COUNT = 2;\n\t\tfinal boolean EVICT_AFTER = true;\n\t\tfinal int THRESHOLD = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(TRIGGER_COUNT),\n\t\t\tDeltaEvictor.of(THRESHOLD, new DeltaFunction<Tuple2<String, Integer>>() {\n\t\t\t\t@Override\n\t\t\t\tpublic double getDelta(Tuple2<String, Integer> oldDataPoint, Tuple2<String, Integer> newDataPoint) {\n\t\t\t\t\treturn newDataPoint.f1 - oldDataPoint.f1;\n\t\t\t\t}\n\t\t\t}, EVICT_AFTER),\n\t\t\t0);\n\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 5), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 5), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 6), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 5), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 15), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 9), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 10), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 16), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 22), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","date":"2016-11-15 17:05:24","endLine":520,"groupId":"22200","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testDeltaEvictorEvictAfter","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/46/495b006ca440e63c228acaf80f51d7c9dbfa85.src","preCode":"\tpublic void testDeltaEvictorEvictAfter() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\t\tfinal int TRIGGER_COUNT = 2;\n\t\tfinal boolean EVICT_AFTER = true;\n\t\tfinal int THRESHOLD = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(TRIGGER_COUNT),\n\t\t\tDeltaEvictor.of(THRESHOLD, new DeltaFunction<Tuple2<String, Integer>>() {\n\t\t\t\t@Override\n\t\t\t\tpublic double getDelta(Tuple2<String, Integer> oldDataPoint, Tuple2<String, Integer> newDataPoint) {\n\t\t\t\t\treturn newDataPoint.f1 - oldDataPoint.f1;\n\t\t\t\t}\n\t\t\t}, EVICT_AFTER),\n\t\t\t0);\n\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 5), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 5), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 6), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 5), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 15), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 9), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 10), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 16), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 22), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperatorTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":450,"status":"B"},{"authorDate":"2016-10-19 00:32:17","commitOrder":7,"curCode":"\tpublic void testCountTriggerWithApply() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\n\t\tfinal int WINDOW_SIZE = 4;\n\t\tfinal int WINDOW_SLIDE = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(WINDOW_SLIDE),\n\t\t\tCountEvictor.of(WINDOW_SIZE),\n\t\t\t0);\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\t\r\n\n\t\t\r\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","date":"2016-10-22 00:10:48","endLine":203,"groupId":"22200","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountTriggerWithApply","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/3d09081c02f2fdcfd77fa47ec9aeec3154f9d8.src","preCode":"\tpublic void testCountTriggerWithApply() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\n\t\tfinal int WINDOW_SIZE = 4;\n\t\tfinal int WINDOW_SLIDE = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(WINDOW_SLIDE),\n\t\t\tCountEvictor.of(WINDOW_SIZE),\n\t\t\t0);\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\t\r\n\n\t\t\r\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperatorTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":133,"status":"NB"}],"commitId":"74bb7bb63919ce6de5736d52e4e5a254cf9b6509","commitMessage":"@@@[FLINK-4174] Enhance evictor functionality\n","date":"2016-11-15 17:05:24","modifiedFileCount":"7","status":"M","submitter":"Vishnu Viswanath"},{"authorTime":"2017-03-01 22:36:17","codes":[{"authorDate":"2017-03-01 22:36:17","commitOrder":8,"curCode":"\tpublic void testDeltaEvictorEvictAfter() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\t\tfinal int TRIGGER_COUNT = 2;\n\t\tfinal boolean EVICT_AFTER = true;\n\t\tfinal int THRESHOLD = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(TRIGGER_COUNT),\n\t\t\tDeltaEvictor.of(THRESHOLD, new DeltaFunction<Tuple2<String, Integer>>() {\n\t\t\t\t@Override\n\t\t\t\tpublic double getDelta(Tuple2<String, Integer> oldDataPoint, Tuple2<String, Integer> newDataPoint) {\n\t\t\t\t\treturn newDataPoint.f1 - oldDataPoint.f1;\n\t\t\t\t}\n\t\t\t}, EVICT_AFTER),\n\t\t\t0,\n\t\t\tnull );\n\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 5), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 5), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 6), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 5), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 15), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 9), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 10), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 16), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 22), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","date":"2017-03-18 14:44:17","endLine":524,"groupId":"22200","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testDeltaEvictorEvictAfter","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e9/d63de69bbeae0402a9a2e8bb8f21a76e8fff02.src","preCode":"\tpublic void testDeltaEvictorEvictAfter() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\t\tfinal int TRIGGER_COUNT = 2;\n\t\tfinal boolean EVICT_AFTER = true;\n\t\tfinal int THRESHOLD = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(TRIGGER_COUNT),\n\t\t\tDeltaEvictor.of(THRESHOLD, new DeltaFunction<Tuple2<String, Integer>>() {\n\t\t\t\t@Override\n\t\t\t\tpublic double getDelta(Tuple2<String, Integer> oldDataPoint, Tuple2<String, Integer> newDataPoint) {\n\t\t\t\t\treturn newDataPoint.f1 - oldDataPoint.f1;\n\t\t\t\t}\n\t\t\t}, EVICT_AFTER),\n\t\t\t0);\n\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 5), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 5), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 6), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 5), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 15), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 9), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 10), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 16), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 22), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperatorTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":453,"status":"M"},{"authorDate":"2017-03-01 22:36:17","commitOrder":8,"curCode":"\tpublic void testCountTriggerWithApply() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\n\t\tfinal int WINDOW_SIZE = 4;\n\t\tfinal int WINDOW_SLIDE = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(WINDOW_SLIDE),\n\t\t\tCountEvictor.of(WINDOW_SIZE),\n\t\t\t0,\n\t\t\tnull );\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\t\r\n\n\t\t\r\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","date":"2017-03-18 14:44:17","endLine":670,"groupId":"22200","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountTriggerWithApply","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e9/d63de69bbeae0402a9a2e8bb8f21a76e8fff02.src","preCode":"\tpublic void testCountTriggerWithApply() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\n\t\tfinal int WINDOW_SIZE = 4;\n\t\tfinal int WINDOW_SLIDE = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(WINDOW_SLIDE),\n\t\t\tCountEvictor.of(WINDOW_SIZE),\n\t\t\t0);\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\t\r\n\n\t\t\r\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperatorTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":599,"status":"M"}],"commitId":"07a15d0e1647c79ae010ca6df5b1830a4087dd56","commitMessage":"@@@[FLINK-4460] Provide late-data output for window operations\n\nWe use side outputs to emit dropped late data.\n","date":"2017-03-18 14:44:17","modifiedFileCount":"8","status":"M","submitter":"Chen Qin"},{"authorTime":"2017-05-17 20:01:04","codes":[{"authorDate":"2017-05-17 20:01:04","commitOrder":9,"curCode":"\tpublic void testDeltaEvictorEvictAfter() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\t\tfinal int triggerCount = 2;\n\t\tfinal boolean evictAfter = true;\n\t\tfinal int threshold = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(triggerCount),\n\t\t\tDeltaEvictor.of(threshold, new DeltaFunction<Tuple2<String, Integer>>() {\n\t\t\t\t@Override\n\t\t\t\tpublic double getDelta(Tuple2<String, Integer> oldDataPoint, Tuple2<String, Integer> newDataPoint) {\n\t\t\t\t\treturn newDataPoint.f1 - oldDataPoint.f1;\n\t\t\t\t}\n\t\t\t}, evictAfter),\n\t\t\t0,\n\t\t\tnull );\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 5), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 5), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 6), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 5), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 15), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 9), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 10), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 16), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 22), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","date":"2017-05-23 04:22:24","endLine":501,"groupId":"22200","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testDeltaEvictorEvictAfter","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/8d/65bb4bac1ae5467b1737fae6b31ddf06c0f2dd.src","preCode":"\tpublic void testDeltaEvictorEvictAfter() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\t\tfinal int TRIGGER_COUNT = 2;\n\t\tfinal boolean EVICT_AFTER = true;\n\t\tfinal int THRESHOLD = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(TRIGGER_COUNT),\n\t\t\tDeltaEvictor.of(THRESHOLD, new DeltaFunction<Tuple2<String, Integer>>() {\n\t\t\t\t@Override\n\t\t\t\tpublic double getDelta(Tuple2<String, Integer> oldDataPoint, Tuple2<String, Integer> newDataPoint) {\n\t\t\t\t\treturn newDataPoint.f1 - oldDataPoint.f1;\n\t\t\t\t}\n\t\t\t}, EVICT_AFTER),\n\t\t\t0,\n\t\t\tnull );\n\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 5), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 5), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 6), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 5), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 15), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 9), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 10), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 16), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 22), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperatorTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":433,"status":"M"},{"authorDate":"2017-05-17 20:01:04","commitOrder":9,"curCode":"\tpublic void testCountTriggerWithApply() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\n\t\tfinal int windowSize = 4;\n\t\tfinal int windowSlide = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(windowSlide),\n\t\t\tCountEvictor.of(windowSize),\n\t\t\t0,\n\t\t\tnull );\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\t\r\n\n\t\t\r\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","date":"2017-05-23 04:22:24","endLine":642,"groupId":"22200","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountTriggerWithApply","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/8d/65bb4bac1ae5467b1737fae6b31ddf06c0f2dd.src","preCode":"\tpublic void testCountTriggerWithApply() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\n\t\tfinal int WINDOW_SIZE = 4;\n\t\tfinal int WINDOW_SLIDE = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(WINDOW_SLIDE),\n\t\t\tCountEvictor.of(WINDOW_SIZE),\n\t\t\t0,\n\t\t\tnull );\n\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\t\r\n\n\t\t\r\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperatorTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":576,"status":"M"}],"commitId":"12b4185c6c09101b64e12a84c33dc4d28f95cff9","commitMessage":"@@@[FLINK-6603] [streaming] Enable checkstyle on test sources\n\nUpdates / reverts the import order by sections:\n- org.apache.flink.*\n- all other imports\n- javax.*\n- java.*\n- static imports\n\nAdds EmptyLineSeparator to enforce an extra newline (not enforced\nbetween field or local variable declarations).\n\nThis closes #3941\n","date":"2017-05-23 04:22:24","modifiedFileCount":"395","status":"M","submitter":"Greg Hogan"},{"authorTime":"2018-05-04 23:15:51","codes":[{"authorDate":"2018-05-04 23:15:51","commitOrder":10,"curCode":"\tpublic void testDeltaEvictorEvictAfter() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\t\tfinal int triggerCount = 2;\n\t\tfinal boolean evictAfter = true;\n\t\tfinal int threshold = 2;\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(STRING_INT_TUPLE.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(triggerCount),\n\t\t\tDeltaEvictor.of(threshold, new DeltaFunction<Tuple2<String, Integer>>() {\n\t\t\t\t@Override\n\t\t\t\tpublic double getDelta(Tuple2<String, Integer> oldDataPoint, Tuple2<String, Integer> newDataPoint) {\n\t\t\t\t\treturn newDataPoint.f1 - oldDataPoint.f1;\n\t\t\t\t}\n\t\t\t}, evictAfter),\n\t\t\t0,\n\t\t\tnull );\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 5), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 5), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 6), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 5), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 15), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 9), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 10), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 16), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 22), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","date":"2018-05-05 00:48:16","endLine":486,"groupId":"102872","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testDeltaEvictorEvictAfter","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/71/0c0b4629735a8654fd44cbb5a4e9cbb9a8f324.src","preCode":"\tpublic void testDeltaEvictorEvictAfter() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\t\tfinal int triggerCount = 2;\n\t\tfinal boolean evictAfter = true;\n\t\tfinal int threshold = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(triggerCount),\n\t\t\tDeltaEvictor.of(threshold, new DeltaFunction<Tuple2<String, Integer>>() {\n\t\t\t\t@Override\n\t\t\t\tpublic double getDelta(Tuple2<String, Integer> oldDataPoint, Tuple2<String, Integer> newDataPoint) {\n\t\t\t\t\treturn newDataPoint.f1 - oldDataPoint.f1;\n\t\t\t\t}\n\t\t\t}, evictAfter),\n\t\t\t0,\n\t\t\tnull );\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 5), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 5), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 6), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 5), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 15), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 9), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 10), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 16), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 22), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperatorTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":420,"status":"M"},{"authorDate":"2018-05-04 23:15:51","commitOrder":10,"curCode":"\tpublic void testCountTriggerWithApply() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\n\t\tfinal int windowSize = 4;\n\t\tfinal int windowSlide = 2;\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(STRING_INT_TUPLE.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(windowSlide),\n\t\t\tCountEvictor.of(windowSize),\n\t\t\t0,\n\t\t\tnull );\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\t\r\n\n\t\t\r\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","date":"2018-05-05 00:48:16","endLine":623,"groupId":"102872","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testCountTriggerWithApply","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/71/0c0b4629735a8654fd44cbb5a4e9cbb9a8f324.src","preCode":"\tpublic void testCountTriggerWithApply() throws Exception {\n\t\tAtomicInteger closeCalled = new AtomicInteger(0);\n\n\t\tfinal int windowSize = 4;\n\t\tfinal int windowSlide = 2;\n\n\t\tTypeInformation<Tuple2<String, Integer>> inputType = TypeInfoParser.parse(\"Tuple2<String, Integer>\");\n\n\t\t@SuppressWarnings({\"unchecked\", \"rawtypes\"})\n\t\tTypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n\t\t\t\t(TypeSerializer<StreamRecord<Tuple2<String, Integer>>>) new StreamElementSerializer(inputType.createSerializer(new ExecutionConfig()));\n\n\t\tListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n\t\t\t\tnew ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n\t\tEvictingWindowOperator<String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow> operator = new EvictingWindowOperator<>(\n\t\t\tGlobalWindows.create(),\n\t\t\tnew GlobalWindow.Serializer(),\n\t\t\tnew TupleKeySelector(),\n\t\t\tBasicTypeInfo.STRING_TYPE_INFO.createSerializer(new ExecutionConfig()),\n\t\t\tstateDesc,\n\t\t\tnew InternalIterableWindowFunction<>(new RichSumReducer<GlobalWindow>(closeCalled)),\n\t\t\tCountTrigger.of(windowSlide),\n\t\t\tCountEvictor.of(windowSize),\n\t\t\t0,\n\t\t\tnull );\n\n\t\tOneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>> testHarness =\n\t\t\t\tnew KeyedOneInputStreamOperatorTestHarness<>(operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n\t\tlong initialTime = 0L;\n\t\tConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n\t\ttestHarness.open();\n\n\t\t\r\n\n\t\t\r\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3000));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 3999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 20));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 999));\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1998));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), initialTime + 10999));\n\t\ttestHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), initialTime + 1000));\n\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n\t\texpectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n\t\tTestHarnessUtil.assertOutputEqualsSorted(\"Output was not correct.\", expectedOutput, testHarness.getOutput(), new ResultSortComparator());\n\n\t\ttestHarness.close();\n\n\t\tAssert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n\t}\n","realPath":"flink-streaming-java/src/test/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperatorTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":559,"status":"M"}],"commitId":"c8fa8d025684c2225824c54a7285bbfdec7cfddc","commitMessage":"@@@[FLINK-9292] [core] Remove TypeInfoParser (part 1)\n","date":"2018-05-05 00:48:16","modifiedFileCount":"26","status":"M","submitter":"Stephan Ewen"}]
