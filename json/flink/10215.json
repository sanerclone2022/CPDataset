[{"authorTime":"2021-01-15 22:42:20","codes":[{"authorDate":"2021-01-15 22:42:20","commitOrder":1,"curCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", KafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SCHEMA_DATA_TYPE.getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SCHEMA, options);\n        final Set<String> avroFormats = new HashSet<>();\n        avroFormats.add(AVRO_CONFLUENT);\n        avroFormats.add(DEBEZIUM_AVRO_CONFLUENT);\n\n        if (avroFormats.contains(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedValueEncoder;\n            if (AVRO_CONFLUENT.equals(valueFormat)) {\n                expectedValueEncoder = createConfluentAvroSerSchema(rowType, expectedValueSubject);\n            } else {\n                expectedValueEncoder = createDebeziumAvroSerSchema(rowType, expectedValueSubject);\n            }\n            assertEquals(expectedValueEncoder, actualValueEncoder);\n        }\n\n        if (avroFormats.contains(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedKeyEncoder;\n            if (AVRO_CONFLUENT.equals(keyFormat)) {\n                expectedKeyEncoder = createConfluentAvroSerSchema(rowType, expectedKeySubject);\n            } else {\n                expectedKeyEncoder = createDebeziumAvroSerSchema(rowType, expectedKeySubject);\n            }\n            assertEquals(expectedKeyEncoder, actualKeyEncoder);\n        }\n    }\n","date":"2021-01-15 22:42:20","endLine":600,"groupId":"43476","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"verifyEncoderSubject","params":"(Consumer<Map<String@String>>optionModifier@StringexpectedValueSubject@StringexpectedKeySubject)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b7/1943f9bf936b685ca659f40ccea283919fbb35.src","preCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", KafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SCHEMA_DATA_TYPE.getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SCHEMA, options);\n        final Set<String> avroFormats = new HashSet<>();\n        avroFormats.add(AVRO_CONFLUENT);\n        avroFormats.add(DEBEZIUM_AVRO_CONFLUENT);\n\n        if (avroFormats.contains(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedValueEncoder;\n            if (AVRO_CONFLUENT.equals(valueFormat)) {\n                expectedValueEncoder = createConfluentAvroSerSchema(rowType, expectedValueSubject);\n            } else {\n                expectedValueEncoder = createDebeziumAvroSerSchema(rowType, expectedValueSubject);\n            }\n            assertEquals(expectedValueEncoder, actualValueEncoder);\n        }\n\n        if (avroFormats.contains(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedKeyEncoder;\n            if (AVRO_CONFLUENT.equals(keyFormat)) {\n                expectedKeyEncoder = createConfluentAvroSerSchema(rowType, expectedKeySubject);\n            } else {\n                expectedKeyEncoder = createDebeziumAvroSerSchema(rowType, expectedKeySubject);\n            }\n            assertEquals(expectedKeyEncoder, actualKeyEncoder);\n        }\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":551,"status":"B"},{"authorDate":"2021-01-15 22:42:20","commitOrder":1,"curCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", UpsertKafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", SINK_TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SINK_SCHEMA.toRowDataType().getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createActualSink(SINK_SCHEMA, options);\n\n        if (AVRO_CONFLUENT.equals(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedValueSubject),\n                    actualValueEncoder);\n        }\n\n        if (AVRO_CONFLUENT.equals(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedKeySubject), actualKeyEncoder);\n        }\n    }\n","date":"2021-01-15 22:42:20","endLine":321,"groupId":"20512","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"verifyEncoderSubject","params":"(Consumer<Map<String@String>>optionModifier@StringexpectedValueSubject@StringexpectedKeySubject)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/93/a30f12bc902ddbe43d72dd3c57f967f9c9353b.src","preCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", UpsertKafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", SINK_TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SINK_SCHEMA.toRowDataType().getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createActualSink(SINK_SCHEMA, options);\n\n        if (AVRO_CONFLUENT.equals(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedValueSubject),\n                    actualValueEncoder);\n        }\n\n        if (AVRO_CONFLUENT.equals(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedKeySubject), actualKeyEncoder);\n        }\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":284,"status":"B"}],"commitId":"3786d3b1e55e063c7453d9813335dc5c2906bf7b","commitMessage":"@@@[FLINK-20348][kafka] Make \"schema-registry.subject\" optional for avro-confluent format when used with kafka\n\nThis closes #14530\n\nCo-authored-by: zhuxiaoshang <zhushang@qutoutiao.net>","date":"2021-01-15 22:42:20","modifiedFileCount":"7","status":"B","submitter":"zhuxiaoshang"},{"authorTime":"2021-03-18 19:13:17","codes":[{"authorDate":"2021-01-15 22:42:20","commitOrder":2,"curCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", KafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SCHEMA_DATA_TYPE.getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SCHEMA, options);\n        final Set<String> avroFormats = new HashSet<>();\n        avroFormats.add(AVRO_CONFLUENT);\n        avroFormats.add(DEBEZIUM_AVRO_CONFLUENT);\n\n        if (avroFormats.contains(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedValueEncoder;\n            if (AVRO_CONFLUENT.equals(valueFormat)) {\n                expectedValueEncoder = createConfluentAvroSerSchema(rowType, expectedValueSubject);\n            } else {\n                expectedValueEncoder = createDebeziumAvroSerSchema(rowType, expectedValueSubject);\n            }\n            assertEquals(expectedValueEncoder, actualValueEncoder);\n        }\n\n        if (avroFormats.contains(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedKeyEncoder;\n            if (AVRO_CONFLUENT.equals(keyFormat)) {\n                expectedKeyEncoder = createConfluentAvroSerSchema(rowType, expectedKeySubject);\n            } else {\n                expectedKeyEncoder = createDebeziumAvroSerSchema(rowType, expectedKeySubject);\n            }\n            assertEquals(expectedKeyEncoder, actualKeyEncoder);\n        }\n    }\n","date":"2021-01-15 22:42:20","endLine":600,"groupId":"43476","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"verifyEncoderSubject","params":"(Consumer<Map<String@String>>optionModifier@StringexpectedValueSubject@StringexpectedKeySubject)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b7/1943f9bf936b685ca659f40ccea283919fbb35.src","preCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", KafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SCHEMA_DATA_TYPE.getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SCHEMA, options);\n        final Set<String> avroFormats = new HashSet<>();\n        avroFormats.add(AVRO_CONFLUENT);\n        avroFormats.add(DEBEZIUM_AVRO_CONFLUENT);\n\n        if (avroFormats.contains(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedValueEncoder;\n            if (AVRO_CONFLUENT.equals(valueFormat)) {\n                expectedValueEncoder = createConfluentAvroSerSchema(rowType, expectedValueSubject);\n            } else {\n                expectedValueEncoder = createDebeziumAvroSerSchema(rowType, expectedValueSubject);\n            }\n            assertEquals(expectedValueEncoder, actualValueEncoder);\n        }\n\n        if (avroFormats.contains(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedKeyEncoder;\n            if (AVRO_CONFLUENT.equals(keyFormat)) {\n                expectedKeyEncoder = createConfluentAvroSerSchema(rowType, expectedKeySubject);\n            } else {\n                expectedKeyEncoder = createDebeziumAvroSerSchema(rowType, expectedKeySubject);\n            }\n            assertEquals(expectedKeyEncoder, actualKeyEncoder);\n        }\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":551,"status":"N"},{"authorDate":"2021-03-18 19:13:17","commitOrder":2,"curCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", UpsertKafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", SINK_TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SINK_SCHEMA.toSinkRowDataType().getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SINK_SCHEMA, options);\n\n        if (AVRO_CONFLUENT.equals(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toSinkRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedValueSubject),\n                    actualValueEncoder);\n        }\n\n        if (AVRO_CONFLUENT.equals(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toSinkRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedKeySubject), actualKeyEncoder);\n        }\n    }\n","date":"2021-03-24 04:35:35","endLine":325,"groupId":"20512","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"verifyEncoderSubject","params":"(Consumer<Map<String@String>>optionModifier@StringexpectedValueSubject@StringexpectedKeySubject)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d0/5845ee2118da97c22951328d6daca8d02cb380.src","preCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", UpsertKafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", SINK_TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SINK_SCHEMA.toRowDataType().getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createActualSink(SINK_SCHEMA, options);\n\n        if (AVRO_CONFLUENT.equals(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedValueSubject),\n                    actualValueEncoder);\n        }\n\n        if (AVRO_CONFLUENT.equals(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedKeySubject), actualKeyEncoder);\n        }\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":288,"status":"M"}],"commitId":"73338e22bd0567169ce2636c8f9e3b87df783385","commitMessage":"@@@[FLINK-21913][table][connectors] Update DynamicTableFactory.Context to use ResolvedCatalogTable\n\nThis closes #15316.\n","date":"2021-03-24 04:35:35","modifiedFileCount":"45","status":"M","submitter":"Timo Walther"},{"authorTime":"2021-06-30 19:55:22","codes":[{"authorDate":"2021-06-30 19:55:22","commitOrder":3,"curCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", KafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SCHEMA_DATA_TYPE.getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(),\n                        options.get(KafkaConnectorOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaConnectorOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SCHEMA, options);\n        final Set<String> avroFormats = new HashSet<>();\n        avroFormats.add(AVRO_CONFLUENT);\n        avroFormats.add(DEBEZIUM_AVRO_CONFLUENT);\n\n        if (avroFormats.contains(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedValueEncoder;\n            if (AVRO_CONFLUENT.equals(valueFormat)) {\n                expectedValueEncoder = createConfluentAvroSerSchema(rowType, expectedValueSubject);\n            } else {\n                expectedValueEncoder = createDebeziumAvroSerSchema(rowType, expectedValueSubject);\n            }\n            assertEquals(expectedValueEncoder, actualValueEncoder);\n        }\n\n        if (avroFormats.contains(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedKeyEncoder;\n            if (AVRO_CONFLUENT.equals(keyFormat)) {\n                expectedKeyEncoder = createConfluentAvroSerSchema(rowType, expectedKeySubject);\n            } else {\n                expectedKeyEncoder = createDebeziumAvroSerSchema(rowType, expectedKeySubject);\n            }\n            assertEquals(expectedKeyEncoder, actualKeyEncoder);\n        }\n    }\n","date":"2021-07-12 18:56:18","endLine":609,"groupId":"10215","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"verifyEncoderSubject","params":"(Consumer<Map<String@String>>optionModifier@StringexpectedValueSubject@StringexpectedKeySubject)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c9/c739b7c9c5f4841dcd53002aaa0aa0df987454.src","preCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", KafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SCHEMA_DATA_TYPE.getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SCHEMA, options);\n        final Set<String> avroFormats = new HashSet<>();\n        avroFormats.add(AVRO_CONFLUENT);\n        avroFormats.add(DEBEZIUM_AVRO_CONFLUENT);\n\n        if (avroFormats.contains(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedValueEncoder;\n            if (AVRO_CONFLUENT.equals(valueFormat)) {\n                expectedValueEncoder = createConfluentAvroSerSchema(rowType, expectedValueSubject);\n            } else {\n                expectedValueEncoder = createDebeziumAvroSerSchema(rowType, expectedValueSubject);\n            }\n            assertEquals(expectedValueEncoder, actualValueEncoder);\n        }\n\n        if (avroFormats.contains(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SCHEMA_DATA_TYPE);\n            final SerializationSchema<RowData> expectedKeyEncoder;\n            if (AVRO_CONFLUENT.equals(keyFormat)) {\n                expectedKeyEncoder = createConfluentAvroSerSchema(rowType, expectedKeySubject);\n            } else {\n                expectedKeyEncoder = createDebeziumAvroSerSchema(rowType, expectedKeySubject);\n            }\n            assertEquals(expectedKeyEncoder, actualKeyEncoder);\n        }\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/KafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":559,"status":"M"},{"authorDate":"2021-06-30 19:55:22","commitOrder":3,"curCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", UpsertKafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", SINK_TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SINK_SCHEMA.toSinkRowDataType().getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(),\n                        options.get(KafkaConnectorOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaConnectorOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SINK_SCHEMA, options);\n\n        if (AVRO_CONFLUENT.equals(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toSinkRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedValueSubject),\n                    actualValueEncoder);\n        }\n\n        if (AVRO_CONFLUENT.equals(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toSinkRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedKeySubject), actualKeyEncoder);\n        }\n    }\n","date":"2021-07-12 18:56:18","endLine":360,"groupId":"10215","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"verifyEncoderSubject","params":"(Consumer<Map<String@String>>optionModifier@StringexpectedValueSubject@StringexpectedKeySubject)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f7/a62f95af0681818d13e0f60773b8fd442a68d8.src","preCode":"    private void verifyEncoderSubject(\n            Consumer<Map<String, String>> optionModifier,\n            String expectedValueSubject,\n            String expectedKeySubject) {\n        Map<String, String> options = new HashMap<>();\n        \r\n        options.put(\"connector\", UpsertKafkaDynamicTableFactory.IDENTIFIER);\n        options.put(\"topic\", SINK_TOPIC);\n        options.put(\"properties.group.id\", \"dummy\");\n        options.put(\"properties.bootstrap.servers\", \"dummy\");\n        optionModifier.accept(options);\n\n        final RowType rowType = (RowType) SINK_SCHEMA.toSinkRowDataType().getLogicalType();\n        final String valueFormat =\n                options.getOrDefault(\n                        FactoryUtil.FORMAT.key(), options.get(KafkaOptions.VALUE_FORMAT.key()));\n        final String keyFormat = options.get(KafkaOptions.KEY_FORMAT.key());\n\n        KafkaDynamicSink sink = (KafkaDynamicSink) createTableSink(SINK_SCHEMA, options);\n\n        if (AVRO_CONFLUENT.equals(valueFormat)) {\n            SerializationSchema<RowData> actualValueEncoder =\n                    sink.valueEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toSinkRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedValueSubject),\n                    actualValueEncoder);\n        }\n\n        if (AVRO_CONFLUENT.equals(keyFormat)) {\n            assert sink.keyEncodingFormat != null;\n            SerializationSchema<RowData> actualKeyEncoder =\n                    sink.keyEncodingFormat.createRuntimeEncoder(\n                            new SinkRuntimeProviderContext(false), SINK_SCHEMA.toSinkRowDataType());\n            assertEquals(\n                    createConfluentAvroSerSchema(rowType, expectedKeySubject), actualKeyEncoder);\n        }\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":322,"status":"M"}],"commitId":"5703e2f40150782943429092c8c3cb00ba719124","commitMessage":"@@@[FLINK-23064][connector-kafka] Expose connector options as PublicEvolving\n\nThis closes #16334.\n","date":"2021-07-12 18:56:18","modifiedFileCount":"4","status":"M","submitter":"Ingo B?rk"}]
