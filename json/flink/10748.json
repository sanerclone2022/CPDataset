[{"authorTime":"2021-08-25 03:58:09","codes":[{"authorDate":"2021-08-25 03:58:09","commitOrder":1,"curCode":"    private void assertSourceMetrics(\n            InMemoryReporter reporter,\n            long processedRecordsPerSubtask,\n            long numTotalPerSubtask,\n            int parallelism,\n            int numSplits,\n            boolean hasTimestamps) {\n        List<OperatorMetricGroup> groups = reporter.findOperatorMetricGroups(\"MetricTestingSource\");\n        assertThat(groups, hasSize(parallelism));\n\n        int subtaskWithMetrics = 0;\n        for (OperatorMetricGroup group : groups) {\n            Map<String, Metric> metrics = reporter.getMetricsByGroup(group);\n            \r\n            if (group.getIOMetricGroup().getNumRecordsInCounter().getCount() == 0) {\n                \r\n                assertThat(metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG), nullValue());\n                assertThat(metrics.get(MetricNames.WATERMARK_LAG), nullValue());\n                continue;\n            }\n            subtaskWithMetrics++;\n            \r\n            assertThat(\n                    group.getIOMetricGroup().getNumRecordsInCounter(),\n                    isCounter(equalTo(processedRecordsPerSubtask)));\n            assertThat(\n                    group.getIOMetricGroup().getNumBytesInCounter(),\n                    isCounter(\n                            equalTo(\n                                    processedRecordsPerSubtask\n                                            * MockRecordEmitter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.NUM_RECORDS_IN_ERRORS),\n                    isCounter(equalTo(processedRecordsPerSubtask / 2)));\n            if (hasTimestamps) {\n                \r\n                assertThat(\n                        metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG),\n                        isGauge(isCloseTo(EVENTTIME_LAG, EVENTTIME_EPSILON)));\n                \r\n                \r\n                assertThat(\n                        metrics.get(MetricNames.WATERMARK_LAG),\n                        isGauge(isCloseTo(EVENTTIME_LAG, EVENTTIME_EPSILON)));\n                \r\n                Long watermarkLag =\n                        ((Gauge<Long>) metrics.get(MetricNames.WATERMARK_LAG)).getValue()\n                                - ((Gauge<Long>)\n                                                metrics.get(\n                                                        MetricNames.CURRENT_EMIT_EVENT_TIME_LAG))\n                                        .getValue();\n                \r\n                assertThat(watermarkLag, isCloseTo(WATERMARK_LAG, WATERMARK_EPSILON));\n            } else {\n                \r\n                assertThat(metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG), nullValue());\n                assertThat(metrics.get(MetricNames.WATERMARK_LAG), nullValue());\n            }\n\n            long pendingRecords = numTotalPerSubtask - processedRecordsPerSubtask;\n            assertThat(metrics.get(MetricNames.PENDING_RECORDS), isGauge(equalTo(pendingRecords)));\n            assertThat(\n                    metrics.get(MetricNames.PENDING_BYTES),\n                    isGauge(equalTo(pendingRecords * MockRecordEmitter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(metrics.get(MetricNames.SOURCE_IDLE_TIME), isGauge(equalTo(0L)));\n        }\n        assertThat(subtaskWithMetrics, equalTo(numSplits));\n    }\n","date":"2021-08-27 17:24:22","endLine":240,"groupId":"17573","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"assertSourceMetrics","params":"(InMemoryReporterreporter@longprocessedRecordsPerSubtask@longnumTotalPerSubtask@intparallelism@intnumSplits@booleanhasTimestamps)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/39/9fe96a21fe7114740bc82ceace4c237dd4675f.src","preCode":"    private void assertSourceMetrics(\n            InMemoryReporter reporter,\n            long processedRecordsPerSubtask,\n            long numTotalPerSubtask,\n            int parallelism,\n            int numSplits,\n            boolean hasTimestamps) {\n        List<OperatorMetricGroup> groups = reporter.findOperatorMetricGroups(\"MetricTestingSource\");\n        assertThat(groups, hasSize(parallelism));\n\n        int subtaskWithMetrics = 0;\n        for (OperatorMetricGroup group : groups) {\n            Map<String, Metric> metrics = reporter.getMetricsByGroup(group);\n            \r\n            if (group.getIOMetricGroup().getNumRecordsInCounter().getCount() == 0) {\n                \r\n                assertThat(metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG), nullValue());\n                assertThat(metrics.get(MetricNames.WATERMARK_LAG), nullValue());\n                continue;\n            }\n            subtaskWithMetrics++;\n            \r\n            assertThat(\n                    group.getIOMetricGroup().getNumRecordsInCounter(),\n                    isCounter(equalTo(processedRecordsPerSubtask)));\n            assertThat(\n                    group.getIOMetricGroup().getNumBytesInCounter(),\n                    isCounter(\n                            equalTo(\n                                    processedRecordsPerSubtask\n                                            * MockRecordEmitter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.NUM_RECORDS_IN_ERRORS),\n                    isCounter(equalTo(processedRecordsPerSubtask / 2)));\n            if (hasTimestamps) {\n                \r\n                assertThat(\n                        metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG),\n                        isGauge(isCloseTo(EVENTTIME_LAG, EVENTTIME_EPSILON)));\n                \r\n                \r\n                assertThat(\n                        metrics.get(MetricNames.WATERMARK_LAG),\n                        isGauge(isCloseTo(EVENTTIME_LAG, EVENTTIME_EPSILON)));\n                \r\n                Long watermarkLag =\n                        ((Gauge<Long>) metrics.get(MetricNames.WATERMARK_LAG)).getValue()\n                                - ((Gauge<Long>)\n                                                metrics.get(\n                                                        MetricNames.CURRENT_EMIT_EVENT_TIME_LAG))\n                                        .getValue();\n                \r\n                assertThat(watermarkLag, isCloseTo(WATERMARK_LAG, WATERMARK_EPSILON));\n            } else {\n                \r\n                assertThat(metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG), nullValue());\n                assertThat(metrics.get(MetricNames.WATERMARK_LAG), nullValue());\n            }\n\n            long pendingRecords = numTotalPerSubtask - processedRecordsPerSubtask;\n            assertThat(metrics.get(MetricNames.PENDING_RECORDS), isGauge(equalTo(pendingRecords)));\n            assertThat(\n                    metrics.get(MetricNames.PENDING_BYTES),\n                    isGauge(equalTo(pendingRecords * MockRecordEmitter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(metrics.get(MetricNames.SOURCE_IDLE_TIME), isGauge(equalTo(0L)));\n        }\n        assertThat(subtaskWithMetrics, equalTo(numSplits));\n    }\n","realPath":"flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/source/reader/SourceMetricsITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":171,"status":"B"},{"authorDate":"2021-08-25 03:58:09","commitOrder":1,"curCode":"    private void assertSinkMetrics(\n            long processedRecordsPerSubtask, int parallelism, int numSplits) {\n        List<OperatorMetricGroup> groups = reporter.findOperatorMetricGroups(\"MetricTestSink\");\n        assertThat(groups, hasSize(parallelism));\n\n        int subtaskWithMetrics = 0;\n        for (OperatorMetricGroup group : groups) {\n            Map<String, Metric> metrics = reporter.getMetricsByGroup(group);\n            \r\n            if (group.getIOMetricGroup().getNumRecordsOutCounter().getCount() == 0) {\n                continue;\n            }\n            subtaskWithMetrics++;\n            \r\n            assertThat(\n                    group.getIOMetricGroup().getNumRecordsOutCounter(),\n                    isCounter(equalTo(processedRecordsPerSubtask)));\n            assertThat(\n                    group.getIOMetricGroup().getNumBytesOutCounter(),\n                    isCounter(\n                            equalTo(\n                                    processedRecordsPerSubtask\n                                            * MetricWriter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.NUM_RECORDS_OUT_ERRORS),\n                    isCounter(equalTo((processedRecordsPerSubtask + 1) / 2)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.CURRENT_SEND_TIME),\n                    isGauge(\n                            equalTo(\n                                    (processedRecordsPerSubtask - 1)\n                                            * MetricWriter.BASE_SEND_TIME)));\n        }\n        assertThat(subtaskWithMetrics, equalTo(numSplits));\n    }\n","date":"2021-08-27 17:24:22","endLine":162,"groupId":"37683","id":2,"instanceNumber":2,"isCurCommit":1,"methodName":"assertSinkMetrics","params":"(longprocessedRecordsPerSubtask@intparallelism@intnumSplits)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/7a/d504f6518f2ea366fe95b6c30a9dfb0e05ab23.src","preCode":"    private void assertSinkMetrics(\n            long processedRecordsPerSubtask, int parallelism, int numSplits) {\n        List<OperatorMetricGroup> groups = reporter.findOperatorMetricGroups(\"MetricTestSink\");\n        assertThat(groups, hasSize(parallelism));\n\n        int subtaskWithMetrics = 0;\n        for (OperatorMetricGroup group : groups) {\n            Map<String, Metric> metrics = reporter.getMetricsByGroup(group);\n            \r\n            if (group.getIOMetricGroup().getNumRecordsOutCounter().getCount() == 0) {\n                continue;\n            }\n            subtaskWithMetrics++;\n            \r\n            assertThat(\n                    group.getIOMetricGroup().getNumRecordsOutCounter(),\n                    isCounter(equalTo(processedRecordsPerSubtask)));\n            assertThat(\n                    group.getIOMetricGroup().getNumBytesOutCounter(),\n                    isCounter(\n                            equalTo(\n                                    processedRecordsPerSubtask\n                                            * MetricWriter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.NUM_RECORDS_OUT_ERRORS),\n                    isCounter(equalTo((processedRecordsPerSubtask + 1) / 2)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.CURRENT_SEND_TIME),\n                    isGauge(\n                            equalTo(\n                                    (processedRecordsPerSubtask - 1)\n                                            * MetricWriter.BASE_SEND_TIME)));\n        }\n        assertThat(subtaskWithMetrics, equalTo(numSplits));\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/SinkMetricsITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":126,"status":"B"}],"commitId":"126fafc25d8769e1cdcd8d88e153bc33dbc95c61","commitMessage":"@@@[FLINK-23794][tests] Remove InMemoryReporter from MiniClusterResource.\n\nTests that need InMemoryReporter will register it themselves in the MiniClusterResource.\nThe life-cycle of the InMemoryReporter is now bound to the minicluster (as any other reporter). Thus.  if a tests need isolation.  a new minicluster should be spawned just for this case.\n","date":"2021-08-27 17:24:22","modifiedFileCount":"4","status":"B","submitter":"Arvid Heise"},{"authorTime":"2021-08-25 03:58:09","codes":[{"authorDate":"2021-08-26 03:11:50","commitOrder":2,"curCode":"    private void assertSourceMetrics(\n            InMemoryReporter reporter,\n            long processedRecordsPerSubtask,\n            long numTotalPerSubtask,\n            int parallelism,\n            int numSplits,\n            boolean hasTimestamps) {\n        List<OperatorMetricGroup> groups = reporter.findOperatorMetricGroups(\"MetricTestingSource\");\n        assertThat(groups, hasSize(parallelism));\n\n        int subtaskWithMetrics = 0;\n        for (OperatorMetricGroup group : groups) {\n            Map<String, Metric> metrics = reporter.getMetricsByGroup(group);\n            \r\n            if (group.getIOMetricGroup().getNumRecordsInCounter().getCount() == 0) {\n                \r\n                assertThat(\n                        metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG),\n                        isGauge(equalTo(InternalSourceReaderMetricGroup.UNDEFINED)));\n                assertThat(metrics.get(MetricNames.WATERMARK_LAG), nullValue());\n                continue;\n            }\n            subtaskWithMetrics++;\n            \r\n            assertThat(\n                    group.getIOMetricGroup().getNumRecordsInCounter(),\n                    isCounter(equalTo(processedRecordsPerSubtask)));\n            assertThat(\n                    group.getIOMetricGroup().getNumBytesInCounter(),\n                    isCounter(\n                            equalTo(\n                                    processedRecordsPerSubtask\n                                            * MockRecordEmitter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.NUM_RECORDS_IN_ERRORS),\n                    isCounter(equalTo(processedRecordsPerSubtask / 2)));\n            if (hasTimestamps) {\n                \r\n                assertThat(\n                        metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG),\n                        isGauge(isCloseTo(EVENTTIME_LAG, EVENTTIME_EPSILON)));\n                \r\n                \r\n                assertThat(\n                        metrics.get(MetricNames.WATERMARK_LAG),\n                        isGauge(isCloseTo(EVENTTIME_LAG, EVENTTIME_EPSILON)));\n                \r\n                Long watermarkLag =\n                        ((Gauge<Long>) metrics.get(MetricNames.WATERMARK_LAG)).getValue()\n                                - ((Gauge<Long>)\n                                                metrics.get(\n                                                        MetricNames.CURRENT_EMIT_EVENT_TIME_LAG))\n                                        .getValue();\n                \r\n                assertThat(watermarkLag, isCloseTo(WATERMARK_LAG, WATERMARK_EPSILON));\n            } else {\n                \r\n                assertThat(\n                        metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG),\n                        isGauge(equalTo(InternalSourceReaderMetricGroup.UNDEFINED)));\n                assertThat(metrics.get(MetricNames.WATERMARK_LAG), nullValue());\n            }\n\n            long pendingRecords = numTotalPerSubtask - processedRecordsPerSubtask;\n            assertThat(metrics.get(MetricNames.PENDING_RECORDS), isGauge(equalTo(pendingRecords)));\n            assertThat(\n                    metrics.get(MetricNames.PENDING_BYTES),\n                    isGauge(equalTo(pendingRecords * MockRecordEmitter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(metrics.get(MetricNames.SOURCE_IDLE_TIME), isGauge(equalTo(0L)));\n        }\n        assertThat(subtaskWithMetrics, equalTo(numSplits));\n    }\n","date":"2021-08-28 02:29:21","endLine":245,"groupId":"10748","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"assertSourceMetrics","params":"(InMemoryReporterreporter@longprocessedRecordsPerSubtask@longnumTotalPerSubtask@intparallelism@intnumSplits@booleanhasTimestamps)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/50/8e1efbd4c364f588b7bf45c99509eaf1003f72.src","preCode":"    private void assertSourceMetrics(\n            InMemoryReporter reporter,\n            long processedRecordsPerSubtask,\n            long numTotalPerSubtask,\n            int parallelism,\n            int numSplits,\n            boolean hasTimestamps) {\n        List<OperatorMetricGroup> groups = reporter.findOperatorMetricGroups(\"MetricTestingSource\");\n        assertThat(groups, hasSize(parallelism));\n\n        int subtaskWithMetrics = 0;\n        for (OperatorMetricGroup group : groups) {\n            Map<String, Metric> metrics = reporter.getMetricsByGroup(group);\n            \r\n            if (group.getIOMetricGroup().getNumRecordsInCounter().getCount() == 0) {\n                \r\n                assertThat(metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG), nullValue());\n                assertThat(metrics.get(MetricNames.WATERMARK_LAG), nullValue());\n                continue;\n            }\n            subtaskWithMetrics++;\n            \r\n            assertThat(\n                    group.getIOMetricGroup().getNumRecordsInCounter(),\n                    isCounter(equalTo(processedRecordsPerSubtask)));\n            assertThat(\n                    group.getIOMetricGroup().getNumBytesInCounter(),\n                    isCounter(\n                            equalTo(\n                                    processedRecordsPerSubtask\n                                            * MockRecordEmitter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.NUM_RECORDS_IN_ERRORS),\n                    isCounter(equalTo(processedRecordsPerSubtask / 2)));\n            if (hasTimestamps) {\n                \r\n                assertThat(\n                        metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG),\n                        isGauge(isCloseTo(EVENTTIME_LAG, EVENTTIME_EPSILON)));\n                \r\n                \r\n                assertThat(\n                        metrics.get(MetricNames.WATERMARK_LAG),\n                        isGauge(isCloseTo(EVENTTIME_LAG, EVENTTIME_EPSILON)));\n                \r\n                Long watermarkLag =\n                        ((Gauge<Long>) metrics.get(MetricNames.WATERMARK_LAG)).getValue()\n                                - ((Gauge<Long>)\n                                                metrics.get(\n                                                        MetricNames.CURRENT_EMIT_EVENT_TIME_LAG))\n                                        .getValue();\n                \r\n                assertThat(watermarkLag, isCloseTo(WATERMARK_LAG, WATERMARK_EPSILON));\n            } else {\n                \r\n                assertThat(metrics.get(MetricNames.CURRENT_EMIT_EVENT_TIME_LAG), nullValue());\n                assertThat(metrics.get(MetricNames.WATERMARK_LAG), nullValue());\n            }\n\n            long pendingRecords = numTotalPerSubtask - processedRecordsPerSubtask;\n            assertThat(metrics.get(MetricNames.PENDING_RECORDS), isGauge(equalTo(pendingRecords)));\n            assertThat(\n                    metrics.get(MetricNames.PENDING_BYTES),\n                    isGauge(equalTo(pendingRecords * MockRecordEmitter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(metrics.get(MetricNames.SOURCE_IDLE_TIME), isGauge(equalTo(0L)));\n        }\n        assertThat(subtaskWithMetrics, equalTo(numSplits));\n    }\n","realPath":"flink-connectors/flink-connector-base/src/test/java/org/apache/flink/connector/base/source/reader/SourceMetricsITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":172,"status":"M"},{"authorDate":"2021-08-25 03:58:09","commitOrder":2,"curCode":"    private void assertSinkMetrics(\n            long processedRecordsPerSubtask, int parallelism, int numSplits) {\n        List<OperatorMetricGroup> groups = reporter.findOperatorMetricGroups(\"MetricTestSink\");\n        assertThat(groups, hasSize(parallelism));\n\n        int subtaskWithMetrics = 0;\n        for (OperatorMetricGroup group : groups) {\n            Map<String, Metric> metrics = reporter.getMetricsByGroup(group);\n            \r\n            if (group.getIOMetricGroup().getNumRecordsOutCounter().getCount() == 0) {\n                continue;\n            }\n            subtaskWithMetrics++;\n            \r\n            assertThat(\n                    group.getIOMetricGroup().getNumRecordsOutCounter(),\n                    isCounter(equalTo(processedRecordsPerSubtask)));\n            assertThat(\n                    group.getIOMetricGroup().getNumBytesOutCounter(),\n                    isCounter(\n                            equalTo(\n                                    processedRecordsPerSubtask\n                                            * MetricWriter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.NUM_RECORDS_OUT_ERRORS),\n                    isCounter(equalTo((processedRecordsPerSubtask + 1) / 2)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.CURRENT_SEND_TIME),\n                    isGauge(\n                            equalTo(\n                                    (processedRecordsPerSubtask - 1)\n                                            * MetricWriter.BASE_SEND_TIME)));\n        }\n        assertThat(subtaskWithMetrics, equalTo(numSplits));\n    }\n","date":"2021-08-27 17:24:22","endLine":162,"groupId":"10748","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"assertSinkMetrics","params":"(longprocessedRecordsPerSubtask@intparallelism@intnumSplits)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/7a/d504f6518f2ea366fe95b6c30a9dfb0e05ab23.src","preCode":"    private void assertSinkMetrics(\n            long processedRecordsPerSubtask, int parallelism, int numSplits) {\n        List<OperatorMetricGroup> groups = reporter.findOperatorMetricGroups(\"MetricTestSink\");\n        assertThat(groups, hasSize(parallelism));\n\n        int subtaskWithMetrics = 0;\n        for (OperatorMetricGroup group : groups) {\n            Map<String, Metric> metrics = reporter.getMetricsByGroup(group);\n            \r\n            if (group.getIOMetricGroup().getNumRecordsOutCounter().getCount() == 0) {\n                continue;\n            }\n            subtaskWithMetrics++;\n            \r\n            assertThat(\n                    group.getIOMetricGroup().getNumRecordsOutCounter(),\n                    isCounter(equalTo(processedRecordsPerSubtask)));\n            assertThat(\n                    group.getIOMetricGroup().getNumBytesOutCounter(),\n                    isCounter(\n                            equalTo(\n                                    processedRecordsPerSubtask\n                                            * MetricWriter.RECORD_SIZE_IN_BYTES)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.NUM_RECORDS_OUT_ERRORS),\n                    isCounter(equalTo((processedRecordsPerSubtask + 1) / 2)));\n            \r\n            assertThat(\n                    metrics.get(MetricNames.CURRENT_SEND_TIME),\n                    isGauge(\n                            equalTo(\n                                    (processedRecordsPerSubtask - 1)\n                                            * MetricWriter.BASE_SEND_TIME)));\n        }\n        assertThat(subtaskWithMetrics, equalTo(numSplits));\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/streaming/runtime/SinkMetricsITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":126,"status":"N"}],"commitId":"fd429d084264357d3cfbfd8b2b62cf8327a8fd79","commitMessage":"@@@[FLINK-23776][datastream] Optimize source metric calculation\n\nThere is a performance regression of 15% on new sources in InputBenchmark. A couple of issues are fixed with this commit:\n- MetricTrackingOutput in SourceOperator adds 1 virtual calls per record. This accounts for ~5% of the regression. The solution is to move the functionality inside WatermarkToDataOutput.\n- Lazy registration of CURRENT_EMIT_EVENT_TIME_LAG gauge. This adds ~2% overhead as it checks for each record whether the metric has been registered already. The solution is to always add the metric and just return some UNDEFINED value when there is no record.\n- Check of NO_TIMESTAMP. This adds ~3% overhead as it's a long comparison for each record. The solution is to lazily check the timestamp in the gauge. This solution depends on the prior solution.\n- Fusion of recordEmitted() and eventTimeEmitted(). This removes 2% overhead and is possible after the previous optimizations.\n\nA bit of regression may remain after this commit. Future work may further improve the situation. However.  it may also be the price to be paid for the additional metrics. In real sources with I/O.  the remaining regression will not be as noticeable. For example.  the micro benchmarks imply that the new source is 2x faster than the old sources but we do not see any difference in actual sources.\n","date":"2021-08-28 02:29:21","modifiedFileCount":"7","status":"M","submitter":"Arvid Heise"}]
