[{"authorTime":"2020-05-16 02:06:46","codes":[{"authorDate":"2020-05-16 02:06:40","commitOrder":2,"curCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tElasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12Z\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12T12:12:12Z\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","date":"2020-05-17 22:34:39","endLine":115,"groupId":"1407","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/3b/667dc13aecb1359f5e3b0ba4dce8661006f50f.src","preCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tElasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12Z\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12T12:12:12Z\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"NB"},{"authorDate":"2020-05-16 02:06:46","commitOrder":2,"curCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tString myType = \"MyType\";\n\t\tElasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12Z\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12T12:12:12Z\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","date":"2020-05-17 22:34:47","endLine":117,"groupId":"15282","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/3c/096532abc3d3ae7afa0c3dccef7c98243eb5a4.src","preCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tString myType = \"MyType\";\n\t\tElasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12Z\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12T12:12:12Z\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"B"}],"commitId":"ccd2d531d1cb577113d5021efd6277031eeef9d1","commitMessage":"@@@[FLINK-17027] Introduce a new Elasticsearch 6 connector with new property keys\n\nThis closes #12184\n","date":"2020-05-17 22:34:47","modifiedFileCount":"0","status":"M","submitter":"Dawid Wysakowicz"},{"authorTime":"2020-06-17 21:32:10","codes":[{"authorDate":"2020-06-17 21:32:10","commitOrder":3,"curCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tElasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","date":"2020-06-17 21:47:28","endLine":115,"groupId":"1407","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/7f/41eb782af75794e178d884f075436ee5aadfb0.src","preCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tElasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12Z\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12T12:12:12Z\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"M"},{"authorDate":"2020-06-17 21:32:10","commitOrder":3,"curCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tString myType = \"MyType\";\n\t\tElasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","date":"2020-06-17 21:47:28","endLine":117,"groupId":"15282","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/26/cf90aa027b33cc7e59f9b2043c4a6c35243151.src","preCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tString myType = \"MyType\";\n\t\tElasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12Z\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12T12:12:12Z\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":66,"status":"M"}],"commitId":"c42a2f9cd6fcf50ff79f030f9b7c7bbe30d64a0f","commitMessage":"@@@[FLINK-18299][json] Fix the non SQL standard timestamp format in JSON format\n\n\nThe current timestamp format in JSON format is not SQL standard which uses RFC-3339. This commit changes the default behavior to parse/generate timestamp using SQL standard. Besides.  it introduces an option \"json.timestamp-format.standard\" to have the ability to fallback to ISO standard. \n\nThis closes #12661","date":"2020-06-17 21:47:28","modifiedFileCount":"19","status":"M","submitter":"Shengkai"},{"authorTime":"2020-11-17 18:05:20","codes":[{"authorDate":"2020-11-17 18:05:20","commitOrder":4,"curCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tElasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress())\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","date":"2020-11-18 20:28:55","endLine":133,"groupId":"7460","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c8/bb4e8ccdeace32ce68565ddf756754072af838.src","preCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tElasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"},{"authorDate":"2020-11-17 18:05:20","commitOrder":4,"curCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tString myType = \"MyType\";\n\t\tElasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), elasticsearchContainer.getHttpHostAddress())\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","date":"2020-11-18 20:28:55","endLine":135,"groupId":"6806","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f1/604d0d5017665f98279f3b422ddeaad471fcd1.src","preCode":"\tpublic void testWritingDocuments() throws Exception {\n\t\tTableSchema schema = TableSchema.builder()\n\t\t\t.field(\"a\", DataTypes.BIGINT().notNull())\n\t\t\t.field(\"b\", DataTypes.TIME())\n\t\t\t.field(\"c\", DataTypes.STRING().notNull())\n\t\t\t.field(\"d\", DataTypes.FLOAT())\n\t\t\t.field(\"e\", DataTypes.TINYINT().notNull())\n\t\t\t.field(\"f\", DataTypes.DATE())\n\t\t\t.field(\"g\", DataTypes.TIMESTAMP().notNull())\n\t\t\t.primaryKey(\"a\", \"g\")\n\t\t\t.build();\n\t\tGenericRowData rowData = GenericRowData.of(\n\t\t\t1L,\n\t\t\t12345,\n\t\t\tStringData.fromString(\"ABCDE\"),\n\t\t\t12.12f,\n\t\t\t(byte) 2,\n\t\t\t12345,\n\t\t\tTimestampData.fromLocalDateTime(LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n\t\tString index = \"writing-documents\";\n\t\tString myType = \"MyType\";\n\t\tElasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n\t\tSinkFunctionProvider sinkRuntimeProvider = (SinkFunctionProvider) sinkFactory.createDynamicTableSink(\n\t\t\tcontext()\n\t\t\t\t.withSchema(schema)\n\t\t\t\t.withOption(ElasticsearchOptions.INDEX_OPTION.key(), index)\n\t\t\t\t.withOption(ElasticsearchOptions.DOCUMENT_TYPE_OPTION.key(), myType)\n\t\t\t\t.withOption(ElasticsearchOptions.HOSTS_OPTION.key(), \"http://127.0.0.1:9200\")\n\t\t\t\t.withOption(ElasticsearchOptions.FLUSH_ON_CHECKPOINT_OPTION.key(), \"false\")\n\t\t\t\t.build()\n\t\t).getSinkRuntimeProvider(new MockContext());\n\n\t\tSinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n\t\tStreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\trowData.setRowKind(RowKind.UPDATE_AFTER);\n\t\tenvironment.<RowData>fromElements(rowData).addSink(sinkFunction);\n\t\tenvironment.execute();\n\n\t\tClient client = elasticsearchResource.getClient();\n\t\tMap<String, Object> response = client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n\t\tMap<Object, Object> expectedMap = new HashMap<>();\n\t\texpectedMap.put(\"a\", 1);\n\t\texpectedMap.put(\"b\", \"00:00:12\");\n\t\texpectedMap.put(\"c\", \"ABCDE\");\n\t\texpectedMap.put(\"d\", 12.12d);\n\t\texpectedMap.put(\"e\", 2);\n\t\texpectedMap.put(\"f\", \"2003-10-20\");\n\t\texpectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n\t\tassertThat(response, equalTo(expectedMap));\n\t}\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":84,"status":"M"}],"commitId":"a5a6ab4b61f69f4e40ee571c9f31812fe8013a67","commitMessage":"@@@[FLINK-17159] Use testcontainers for Elasticsearch ITCases\n\nThis should harden the tests because we now use random ports for the ES\nnodes. I have a suspicion that we had clashes before.  which were causing\ntest instability.\n\nAdditionally.  this allows us to get rid of quite some of our own code\nfor setting up an ES environment. Once we drop ES5 we can additionally\ndrop ElasticsearchResource and EmbeddedElasticsearchNodeEnvironment.\n","date":"2020-11-18 20:28:55","modifiedFileCount":"6","status":"M","submitter":"Aljoscha Krettek"},{"authorTime":"2021-03-18 19:13:17","codes":[{"authorDate":"2021-03-18 19:13:17","commitOrder":5,"curCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        Elasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchOptions.INDEX_OPTION.key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchOptions.HOSTS_OPTION.key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","date":"2021-03-24 04:35:35","endLine":152,"groupId":"7460","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e7/a9271c0e5a6ae8a28814cfd393b4b082995889.src","preCode":"    public void testWritingDocuments() throws Exception {\n        TableSchema schema =\n                TableSchema.builder()\n                        .field(\"a\", DataTypes.BIGINT().notNull())\n                        .field(\"b\", DataTypes.TIME())\n                        .field(\"c\", DataTypes.STRING().notNull())\n                        .field(\"d\", DataTypes.FLOAT())\n                        .field(\"e\", DataTypes.TINYINT().notNull())\n                        .field(\"f\", DataTypes.DATE())\n                        .field(\"g\", DataTypes.TIMESTAMP().notNull())\n                        .primaryKey(\"a\", \"g\")\n                        .build();\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        Elasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchOptions.INDEX_OPTION.key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchOptions.HOSTS_OPTION.key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"M"},{"authorDate":"2021-03-18 19:13:17","commitOrder":5,"curCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        String myType = \"MyType\";\n        Elasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchOptions.INDEX_OPTION.key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchOptions.DOCUMENT_TYPE_OPTION\n                                                                .key(),\n                                                        myType)\n                                                .withOption(\n                                                        ElasticsearchOptions.HOSTS_OPTION.key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\"))\n                        .actionGet()\n                        .getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","date":"2021-03-24 04:35:35","endLine":158,"groupId":"6806","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e4/3b0c53557a37aa34095737d1be1392c9d05af7.src","preCode":"    public void testWritingDocuments() throws Exception {\n        TableSchema schema =\n                TableSchema.builder()\n                        .field(\"a\", DataTypes.BIGINT().notNull())\n                        .field(\"b\", DataTypes.TIME())\n                        .field(\"c\", DataTypes.STRING().notNull())\n                        .field(\"d\", DataTypes.FLOAT())\n                        .field(\"e\", DataTypes.TINYINT().notNull())\n                        .field(\"f\", DataTypes.DATE())\n                        .field(\"g\", DataTypes.TIMESTAMP().notNull())\n                        .primaryKey(\"a\", \"g\")\n                        .build();\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        String myType = \"MyType\";\n        Elasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchOptions.INDEX_OPTION.key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchOptions.DOCUMENT_TYPE_OPTION\n                                                                .key(),\n                                                        myType)\n                                                .withOption(\n                                                        ElasticsearchOptions.HOSTS_OPTION.key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\"))\n                        .actionGet()\n                        .getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"M"}],"commitId":"73338e22bd0567169ce2636c8f9e3b87df783385","commitMessage":"@@@[FLINK-21913][table][connectors] Update DynamicTableFactory.Context to use ResolvedCatalogTable\n\nThis closes #15316.\n","date":"2021-03-24 04:35:35","modifiedFileCount":"45","status":"M","submitter":"Timo Walther"},{"authorTime":"2021-06-30 16:32:46","codes":[{"authorDate":"2021-06-30 16:32:46","commitOrder":6,"curCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        Elasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","date":"2021-07-12 18:56:17","endLine":154,"groupId":"7460","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/cb/025a602c4dd93484714c657f717cfda1d1c4d8.src","preCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        Elasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchOptions.INDEX_OPTION.key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchOptions.HOSTS_OPTION.key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"M"},{"authorDate":"2021-06-30 16:32:46","commitOrder":6,"curCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        String myType = \"MyType\";\n        Elasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .DOCUMENT_TYPE_OPTION\n                                                                .key(),\n                                                        myType)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\"))\n                        .actionGet()\n                        .getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","date":"2021-07-12 18:56:17","endLine":161,"groupId":"6806","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e9/7950159872dc72dcc8875849a65df88edbb4fd.src","preCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        String myType = \"MyType\";\n        Elasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchOptions.INDEX_OPTION.key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchOptions.DOCUMENT_TYPE_OPTION\n                                                                .key(),\n                                                        myType)\n                                                .withOption(\n                                                        ElasticsearchOptions.HOSTS_OPTION.key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\"))\n                        .actionGet()\n                        .getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"M"}],"commitId":"2dbb3de221339edf120dac3fbbd6e13c3e54af11","commitMessage":"@@@[FLINK-23064][connector-elasticsearch] Make connector options PublicEvolving\n","date":"2021-07-12 18:56:17","modifiedFileCount":"11","status":"M","submitter":"Ingo B?rk"},{"authorTime":"2021-08-21 19:53:33","codes":[{"authorDate":"2021-06-30 16:32:46","commitOrder":7,"curCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        Elasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","date":"2021-07-12 18:56:17","endLine":154,"groupId":"7460","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/cb/025a602c4dd93484714c657f717cfda1d1c4d8.src","preCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        Elasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"N"},{"authorDate":"2021-08-21 19:53:33","commitOrder":7,"curCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        String myType = \"MyType\";\n        Elasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .DOCUMENT_TYPE_OPTION\n                                                                .key(),\n                                                        myType)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        environment.setParallelism(4);\n\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\"))\n                        .actionGet()\n                        .getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","date":"2021-08-23 17:46:35","endLine":163,"groupId":"0","id":12,"instanceNumber":2,"isCurCommit":1,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/77/449d593e9c92a989a4edea459d83d1cb8ae23d.src","preCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        String myType = \"MyType\";\n        Elasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .DOCUMENT_TYPE_OPTION\n                                                                .key(),\n                                                        myType)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\"))\n                        .actionGet()\n                        .getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"M"}],"commitId":"0bf976eac26e80294a6ea28db6844e7311667b3f","commitMessage":"@@@[FLINK-21538][tests] Set default parallelism to 4 for Elasticsearch6DynamicSinkITCase.testWritingDocuments\n\nThis commit sets the default parallelism of Elasticsearch6DynamicSinkITCase.testWritingDocuments to 4 in order\nto reduce the load for our CI infrastructure.\n\nThis closes #16918.\n","date":"2021-08-23 17:46:35","modifiedFileCount":"1","status":"M","submitter":"Till Rohrmann"},{"authorTime":"2021-08-21 19:53:33","codes":[{"authorDate":"2021-08-21 20:21:33","commitOrder":8,"curCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        Elasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        environment.setParallelism(4);\n\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","date":"2021-08-23 17:59:47","endLine":156,"groupId":"10812","id":13,"instanceNumber":1,"isCurCommit":1,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/a7/4496ca2e4f6f55d1baf625c43d49e5604cf25d.src","preCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        Elasticsearch7DynamicSinkFactory sinkFactory = new Elasticsearch7DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, \"1_2012-12-12T12:12:12\")).actionGet().getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","realPath":"flink-connectors/flink-connector-elasticsearch7/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch7DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"M"},{"authorDate":"2021-08-21 19:53:33","commitOrder":8,"curCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        String myType = \"MyType\";\n        Elasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .DOCUMENT_TYPE_OPTION\n                                                                .key(),\n                                                        myType)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        environment.setParallelism(4);\n\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\"))\n                        .actionGet()\n                        .getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","date":"2021-08-23 17:46:35","endLine":163,"groupId":"10812","id":14,"instanceNumber":2,"isCurCommit":1,"methodName":"testWritingDocuments","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/77/449d593e9c92a989a4edea459d83d1cb8ae23d.src","preCode":"    public void testWritingDocuments() throws Exception {\n        ResolvedSchema schema =\n                new ResolvedSchema(\n                        Arrays.asList(\n                                Column.physical(\"a\", DataTypes.BIGINT().notNull()),\n                                Column.physical(\"b\", DataTypes.TIME()),\n                                Column.physical(\"c\", DataTypes.STRING().notNull()),\n                                Column.physical(\"d\", DataTypes.FLOAT()),\n                                Column.physical(\"e\", DataTypes.TINYINT().notNull()),\n                                Column.physical(\"f\", DataTypes.DATE()),\n                                Column.physical(\"g\", DataTypes.TIMESTAMP().notNull())),\n                        Collections.emptyList(),\n                        UniqueConstraint.primaryKey(\"name\", Arrays.asList(\"a\", \"g\")));\n        GenericRowData rowData =\n                GenericRowData.of(\n                        1L,\n                        12345,\n                        StringData.fromString(\"ABCDE\"),\n                        12.12f,\n                        (byte) 2,\n                        12345,\n                        TimestampData.fromLocalDateTime(\n                                LocalDateTime.parse(\"2012-12-12T12:12:12\")));\n\n        String index = \"writing-documents\";\n        String myType = \"MyType\";\n        Elasticsearch6DynamicSinkFactory sinkFactory = new Elasticsearch6DynamicSinkFactory();\n\n        SinkFunctionProvider sinkRuntimeProvider =\n                (SinkFunctionProvider)\n                        sinkFactory\n                                .createDynamicTableSink(\n                                        context()\n                                                .withSchema(schema)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.INDEX_OPTION\n                                                                .key(),\n                                                        index)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .DOCUMENT_TYPE_OPTION\n                                                                .key(),\n                                                        myType)\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions.HOSTS_OPTION\n                                                                .key(),\n                                                        elasticsearchContainer.getHttpHostAddress())\n                                                .withOption(\n                                                        ElasticsearchConnectorOptions\n                                                                .FLUSH_ON_CHECKPOINT_OPTION\n                                                                .key(),\n                                                        \"false\")\n                                                .build())\n                                .getSinkRuntimeProvider(new MockContext());\n\n        SinkFunction<RowData> sinkFunction = sinkRuntimeProvider.createSinkFunction();\n        StreamExecutionEnvironment environment =\n                StreamExecutionEnvironment.getExecutionEnvironment();\n        environment.setParallelism(4);\n\n        rowData.setRowKind(RowKind.UPDATE_AFTER);\n        environment.<RowData>fromElements(rowData).addSink(sinkFunction);\n        environment.execute();\n\n        Client client = getClient();\n        Map<String, Object> response =\n                client.get(new GetRequest(index, myType, \"1_2012-12-12T12:12:12\"))\n                        .actionGet()\n                        .getSource();\n        Map<Object, Object> expectedMap = new HashMap<>();\n        expectedMap.put(\"a\", 1);\n        expectedMap.put(\"b\", \"00:00:12\");\n        expectedMap.put(\"c\", \"ABCDE\");\n        expectedMap.put(\"d\", 12.12d);\n        expectedMap.put(\"e\", 2);\n        expectedMap.put(\"f\", \"2003-10-20\");\n        expectedMap.put(\"g\", \"2012-12-12 12:12:12\");\n        assertThat(response, equalTo(expectedMap));\n    }\n","realPath":"flink-connectors/flink-connector-elasticsearch6/src/test/java/org/apache/flink/streaming/connectors/elasticsearch/table/Elasticsearch6DynamicSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":85,"status":"N"}],"commitId":"2a4f15647e46b6deb9480a2d8b03cf754b276aa8","commitMessage":"@@@[FLINK-22333][tests] Harden Elasticsearch7DynamicSinkITCase.testWritingDocuments by setting parallelism to 4\n\nThis commit hardens the Elasticsearch7DynamicSinkITCase.testWritingDocuments tests by settings its parallelism\nto 4. Otherwise the test is run with as many CPUs are available on the machine. This can slow down the test\non our CI infrastructure.\n\nThis closes #16924.\n","date":"2021-08-23 17:59:47","modifiedFileCount":"1","status":"M","submitter":"Till Rohrmann"}]
