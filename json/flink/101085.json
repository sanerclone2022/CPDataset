[{"authorTime":"2020-11-07 14:23:56","codes":[{"authorDate":"2020-11-07 14:23:56","commitOrder":1,"curCode":"\tpublic void testLookupJoinPartitionedTable() throws Exception {\n\t\t\r\n\t\tTableEnvironment batchEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n\t\tbatchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n\t\tbatchEnv.useCatalog(hiveCatalog.getName());\n\t\tbatchEnv.executeSql(\"insert overwrite partition_table_1 values \" +\n\t\t\t\t\"(1,'a',08,2019,'09','01'),\" +\n\t\t\t\t\"(1,'a',10,2020,'09','31'),\" +\n\t\t\t\t\"(2,'a',21,2020,'09','31'),\" +\n\t\t\t\t\"(2,'b',22,2020,'09','31'),\" +\n\t\t\t\t\"(3,'c',33,2020,'09','31'),\" +\n\t\t\t\t\"(1,'a',101,2020,'08','01'),\" +\n\t\t\t\t\"(2,'a',121,2020,'08','01'),\" +\n\t\t\t\t\"(2,'b',122,2020,'08','01')\")\n\t\t\t\t.await();\n\n\t\tTableImpl flinkTable = (TableImpl) tableEnv.sqlQuery(\"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \" +\n\t\t\t\t\" default_catalog.default_database.probe as p\" +\n\t\t\t\t\" join partition_table_1 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n\t\tList<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n\t\tassertEquals(\"[1,a,10,2020,09,31, 2,b,22,2020,09,31, 3,c,33,2020,09,31]\", results.toString());\n\t}\n","date":"2020-11-07 14:23:56","endLine":255,"groupId":"30539","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testLookupJoinPartitionedTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/63/84134e0eeaede6d2fa8c8de449ec0a9810f56f.src","preCode":"\tpublic void testLookupJoinPartitionedTable() throws Exception {\n\t\t\r\n\t\tTableEnvironment batchEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n\t\tbatchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n\t\tbatchEnv.useCatalog(hiveCatalog.getName());\n\t\tbatchEnv.executeSql(\"insert overwrite partition_table_1 values \" +\n\t\t\t\t\"(1,'a',08,2019,'09','01'),\" +\n\t\t\t\t\"(1,'a',10,2020,'09','31'),\" +\n\t\t\t\t\"(2,'a',21,2020,'09','31'),\" +\n\t\t\t\t\"(2,'b',22,2020,'09','31'),\" +\n\t\t\t\t\"(3,'c',33,2020,'09','31'),\" +\n\t\t\t\t\"(1,'a',101,2020,'08','01'),\" +\n\t\t\t\t\"(2,'a',121,2020,'08','01'),\" +\n\t\t\t\t\"(2,'b',122,2020,'08','01')\")\n\t\t\t\t.await();\n\n\t\tTableImpl flinkTable = (TableImpl) tableEnv.sqlQuery(\"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \" +\n\t\t\t\t\" default_catalog.default_database.probe as p\" +\n\t\t\t\t\" join partition_table_1 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n\t\tList<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n\t\tassertEquals(\"[1,a,10,2020,09,31, 2,b,22,2020,09,31, 3,c,33,2020,09,31]\", results.toString());\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":234,"status":"B"},{"authorDate":"2020-11-07 14:23:56","commitOrder":1,"curCode":"\tpublic void testLookupJoinPartitionedTableWithPartitionTime() throws Exception {\n\t\t\r\n\t\tTableEnvironment batchEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n\t\tbatchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n\t\tbatchEnv.useCatalog(hiveCatalog.getName());\n\t\tbatchEnv.executeSql(\"insert overwrite partition_table_2 values \" +\n\t\t\t\t\"(1,'a',08,2020,'08','01'),\" +\n\t\t\t\t\"(1,'a',10,2020,'08','31'),\" +\n\t\t\t\t\"(2,'a',21,2019,'08','31'),\" +\n\t\t\t\t\"(2,'b',22,2020,'08','31'),\" +\n\t\t\t\t\"(3,'c',33,2017,'08','31'),\" +\n\t\t\t\t\"(1,'a',101,2017,'09','01'),\" +\n\t\t\t\t\"(2,'a',121,2019,'09','01'),\" +\n\t\t\t\t\"(2,'b',122,2019,'09','01')\")\n\t\t\t\t.await();\n\n\t\tTableImpl flinkTable = (TableImpl) tableEnv.sqlQuery(\"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \" +\n\t\t\t\t\" default_catalog.default_database.probe as p\" +\n\t\t\t\t\" join partition_table_2 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n\t\tList<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n\t\tassertEquals(\"[1,a,10,2020,08,31, 2,b,22,2020,08,31]\", results.toString());\n\t}\n","date":"2020-11-07 14:23:56","endLine":279,"groupId":"30539","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testLookupJoinPartitionedTableWithPartitionTime","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/63/84134e0eeaede6d2fa8c8de449ec0a9810f56f.src","preCode":"\tpublic void testLookupJoinPartitionedTableWithPartitionTime() throws Exception {\n\t\t\r\n\t\tTableEnvironment batchEnv = HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n\t\tbatchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n\t\tbatchEnv.useCatalog(hiveCatalog.getName());\n\t\tbatchEnv.executeSql(\"insert overwrite partition_table_2 values \" +\n\t\t\t\t\"(1,'a',08,2020,'08','01'),\" +\n\t\t\t\t\"(1,'a',10,2020,'08','31'),\" +\n\t\t\t\t\"(2,'a',21,2019,'08','31'),\" +\n\t\t\t\t\"(2,'b',22,2020,'08','31'),\" +\n\t\t\t\t\"(3,'c',33,2017,'08','31'),\" +\n\t\t\t\t\"(1,'a',101,2017,'09','01'),\" +\n\t\t\t\t\"(2,'a',121,2019,'09','01'),\" +\n\t\t\t\t\"(2,'b',122,2019,'09','01')\")\n\t\t\t\t.await();\n\n\t\tTableImpl flinkTable = (TableImpl) tableEnv.sqlQuery(\"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \" +\n\t\t\t\t\" default_catalog.default_database.probe as p\" +\n\t\t\t\t\" join partition_table_2 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n\t\tList<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n\t\tassertEquals(\"[1,a,10,2020,08,31, 2,b,22,2020,08,31]\", results.toString());\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"B"}],"commitId":"09386f27b66c86e8148ae8d25d72e3c2ac552362","commitMessage":"@@@[FLINK-19644][hive] Support read latest partition of Hive table in temporal join\n\nThis closes #13729","date":"2020-11-07 14:23:56","modifiedFileCount":"10","status":"B","submitter":"Leonard Xu"},{"authorTime":"2020-12-18 18:32:55","codes":[{"authorDate":"2020-12-18 18:32:55","commitOrder":2,"curCode":"    public void testLookupJoinPartitionedTable() throws Exception {\n        \r\n        TableEnvironment batchEnv =\n                HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n        batchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        batchEnv.useCatalog(hiveCatalog.getName());\n        batchEnv.executeSql(\n                        \"insert overwrite partition_table_1 values \"\n                                + \"(1,'a',08,2019,'09','01'),\"\n                                + \"(1,'a',10,2020,'09','31'),\"\n                                + \"(2,'a',21,2020,'09','31'),\"\n                                + \"(2,'b',22,2020,'09','31'),\"\n                                + \"(3,'c',33,2020,'09','31'),\"\n                                + \"(1,'a',101,2020,'08','01'),\"\n                                + \"(2,'a',121,2020,'08','01'),\"\n                                + \"(2,'b',122,2020,'08','01')\")\n                .await();\n\n        TableImpl flinkTable =\n                (TableImpl)\n                        tableEnv.sqlQuery(\n                                \"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \"\n                                        + \" default_catalog.default_database.probe as p\"\n                                        + \" join partition_table_1 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n        List<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n        assertEquals(\n                \"[+I[1, a, 10, 2020, 09, 31], +I[2, b, 22, 2020, 09, 31], +I[3, c, 33, 2020, 09, 31]]\",\n                results.toString());\n    }\n","date":"2021-01-08 00:17:30","endLine":289,"groupId":"30539","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testLookupJoinPartitionedTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f0/df0f6d186f9ae9dc1fc8e688352403f738950b.src","preCode":"    public void testLookupJoinPartitionedTable() throws Exception {\n        \r\n        TableEnvironment batchEnv =\n                HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n        batchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        batchEnv.useCatalog(hiveCatalog.getName());\n        batchEnv.executeSql(\n                        \"insert overwrite partition_table_1 values \"\n                                + \"(1,'a',08,2019,'09','01'),\"\n                                + \"(1,'a',10,2020,'09','31'),\"\n                                + \"(2,'a',21,2020,'09','31'),\"\n                                + \"(2,'b',22,2020,'09','31'),\"\n                                + \"(3,'c',33,2020,'09','31'),\"\n                                + \"(1,'a',101,2020,'08','01'),\"\n                                + \"(2,'a',121,2020,'08','01'),\"\n                                + \"(2,'b',122,2020,'08','01')\")\n                .await();\n\n        TableImpl flinkTable =\n                (TableImpl)\n                        tableEnv.sqlQuery(\n                                \"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \"\n                                        + \" default_catalog.default_database.probe as p\"\n                                        + \" join partition_table_1 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n        List<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n        assertEquals(\n                \"[1,a,10,2020,09,31, 2,b,22,2020,09,31, 3,c,33,2020,09,31]\", results.toString());\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":261,"status":"M"},{"authorDate":"2020-12-18 18:32:55","commitOrder":2,"curCode":"    public void testLookupJoinPartitionedTableWithPartitionTime() throws Exception {\n        \r\n        TableEnvironment batchEnv =\n                HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n        batchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        batchEnv.useCatalog(hiveCatalog.getName());\n        batchEnv.executeSql(\n                        \"insert overwrite partition_table_2 values \"\n                                + \"(1,'a',08,2020,'08','01'),\"\n                                + \"(1,'a',10,2020,'08','31'),\"\n                                + \"(2,'a',21,2019,'08','31'),\"\n                                + \"(2,'b',22,2020,'08','31'),\"\n                                + \"(3,'c',33,2017,'08','31'),\"\n                                + \"(1,'a',101,2017,'09','01'),\"\n                                + \"(2,'a',121,2019,'09','01'),\"\n                                + \"(2,'b',122,2019,'09','01')\")\n                .await();\n\n        TableImpl flinkTable =\n                (TableImpl)\n                        tableEnv.sqlQuery(\n                                \"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \"\n                                        + \" default_catalog.default_database.probe as p\"\n                                        + \" join partition_table_2 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n        List<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n        assertEquals(\n                \"[+I[1, a, 10, 2020, 08, 31], +I[2, b, 22, 2020, 08, 31]]\", results.toString());\n    }\n","date":"2021-01-08 00:17:30","endLine":319,"groupId":"30539","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testLookupJoinPartitionedTableWithPartitionTime","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f0/df0f6d186f9ae9dc1fc8e688352403f738950b.src","preCode":"    public void testLookupJoinPartitionedTableWithPartitionTime() throws Exception {\n        \r\n        TableEnvironment batchEnv =\n                HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n        batchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        batchEnv.useCatalog(hiveCatalog.getName());\n        batchEnv.executeSql(\n                        \"insert overwrite partition_table_2 values \"\n                                + \"(1,'a',08,2020,'08','01'),\"\n                                + \"(1,'a',10,2020,'08','31'),\"\n                                + \"(2,'a',21,2019,'08','31'),\"\n                                + \"(2,'b',22,2020,'08','31'),\"\n                                + \"(3,'c',33,2017,'08','31'),\"\n                                + \"(1,'a',101,2017,'09','01'),\"\n                                + \"(2,'a',121,2019,'09','01'),\"\n                                + \"(2,'b',122,2019,'09','01')\")\n                .await();\n\n        TableImpl flinkTable =\n                (TableImpl)\n                        tableEnv.sqlQuery(\n                                \"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \"\n                                        + \" default_catalog.default_database.probe as p\"\n                                        + \" join partition_table_2 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n        List<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n        assertEquals(\"[1,a,10,2020,08,31, 2,b,22,2020,08,31]\", results.toString());\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":292,"status":"M"}],"commitId":"73cdd3d0d9f6a807b3e47c09eef7983c9aa180c7","commitMessage":"@@@[FLINK-18090] Update tests for new Row.toString\n\nAll tests in modules apart from the Blink planner/runtime\nmodule have been updated.\n\nOtherwise we use a JUnit rule to make the migration of\nthe remaining tests incremental.\n\nThis closes #14568.\n","date":"2021-01-08 00:17:30","modifiedFileCount":"34","status":"M","submitter":"Timo Walther"},{"authorTime":"2021-06-24 15:56:28","codes":[{"authorDate":"2021-06-24 15:56:28","commitOrder":3,"curCode":"    public void testLookupJoinPartitionedTable() throws Exception {\n        \r\n        TableEnvironment batchEnv = HiveTestUtils.createTableEnvInBatchMode(SqlDialect.HIVE);\n        batchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        batchEnv.useCatalog(hiveCatalog.getName());\n        batchEnv.executeSql(\n                        \"insert overwrite partition_table_1 values \"\n                                + \"(1,'a',08,2019,'09','01'),\"\n                                + \"(1,'a',10,2020,'09','31'),\"\n                                + \"(2,'a',21,2020,'09','31'),\"\n                                + \"(2,'b',22,2020,'09','31'),\"\n                                + \"(3,'c',33,2020,'09','31'),\"\n                                + \"(1,'a',101,2020,'08','01'),\"\n                                + \"(2,'a',121,2020,'08','01'),\"\n                                + \"(2,'b',122,2020,'08','01')\")\n                .await();\n\n        TableImpl flinkTable =\n                (TableImpl)\n                        tableEnv.sqlQuery(\n                                \"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \"\n                                        + \" default_catalog.default_database.probe as p\"\n                                        + \" join partition_table_1 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n        List<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n        assertEquals(\n                \"[+I[1, a, 10, 2020, 09, 31], +I[2, b, 22, 2020, 09, 31], +I[3, c, 33, 2020, 09, 31]]\",\n                results.toString());\n    }\n","date":"2021-07-06 19:28:35","endLine":285,"groupId":"101085","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testLookupJoinPartitionedTable","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/d075c5169ae193d5bb4fde350e147955f219e7.src","preCode":"    public void testLookupJoinPartitionedTable() throws Exception {\n        \r\n        TableEnvironment batchEnv =\n                HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n        batchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        batchEnv.useCatalog(hiveCatalog.getName());\n        batchEnv.executeSql(\n                        \"insert overwrite partition_table_1 values \"\n                                + \"(1,'a',08,2019,'09','01'),\"\n                                + \"(1,'a',10,2020,'09','31'),\"\n                                + \"(2,'a',21,2020,'09','31'),\"\n                                + \"(2,'b',22,2020,'09','31'),\"\n                                + \"(3,'c',33,2020,'09','31'),\"\n                                + \"(1,'a',101,2020,'08','01'),\"\n                                + \"(2,'a',121,2020,'08','01'),\"\n                                + \"(2,'b',122,2020,'08','01')\")\n                .await();\n\n        TableImpl flinkTable =\n                (TableImpl)\n                        tableEnv.sqlQuery(\n                                \"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \"\n                                        + \" default_catalog.default_database.probe as p\"\n                                        + \" join partition_table_1 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n        List<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n        assertEquals(\n                \"[+I[1, a, 10, 2020, 09, 31], +I[2, b, 22, 2020, 09, 31], +I[3, c, 33, 2020, 09, 31]]\",\n                results.toString());\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2021-06-24 15:56:28","commitOrder":3,"curCode":"    public void testLookupJoinPartitionedTableWithPartitionTime() throws Exception {\n        \r\n        TableEnvironment batchEnv = HiveTestUtils.createTableEnvInBatchMode(SqlDialect.HIVE);\n        batchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        batchEnv.useCatalog(hiveCatalog.getName());\n        batchEnv.executeSql(\n                        \"insert overwrite partition_table_2 values \"\n                                + \"(1,'a',08,2020,'08','01'),\"\n                                + \"(1,'a',10,2020,'08','31'),\"\n                                + \"(2,'a',21,2019,'08','31'),\"\n                                + \"(2,'b',22,2020,'08','31'),\"\n                                + \"(3,'c',33,2017,'08','31'),\"\n                                + \"(1,'a',101,2017,'09','01'),\"\n                                + \"(2,'a',121,2019,'09','01'),\"\n                                + \"(2,'b',122,2019,'09','01')\")\n                .await();\n\n        TableImpl flinkTable =\n                (TableImpl)\n                        tableEnv.sqlQuery(\n                                \"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \"\n                                        + \" default_catalog.default_database.probe as p\"\n                                        + \" join partition_table_2 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n        List<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n        assertEquals(\n                \"[+I[1, a, 10, 2020, 08, 31], +I[2, b, 22, 2020, 08, 31]]\", results.toString());\n    }\n","date":"2021-07-06 19:28:35","endLine":314,"groupId":"101085","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testLookupJoinPartitionedTableWithPartitionTime","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2e/d075c5169ae193d5bb4fde350e147955f219e7.src","preCode":"    public void testLookupJoinPartitionedTableWithPartitionTime() throws Exception {\n        \r\n        TableEnvironment batchEnv =\n                HiveTestUtils.createTableEnvWithBlinkPlannerBatchMode(SqlDialect.HIVE);\n        batchEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        batchEnv.useCatalog(hiveCatalog.getName());\n        batchEnv.executeSql(\n                        \"insert overwrite partition_table_2 values \"\n                                + \"(1,'a',08,2020,'08','01'),\"\n                                + \"(1,'a',10,2020,'08','31'),\"\n                                + \"(2,'a',21,2019,'08','31'),\"\n                                + \"(2,'b',22,2020,'08','31'),\"\n                                + \"(3,'c',33,2017,'08','31'),\"\n                                + \"(1,'a',101,2017,'09','01'),\"\n                                + \"(2,'a',121,2019,'09','01'),\"\n                                + \"(2,'b',122,2019,'09','01')\")\n                .await();\n\n        TableImpl flinkTable =\n                (TableImpl)\n                        tableEnv.sqlQuery(\n                                \"select p.x, p.y, b.z, b.pt_year, b.pt_mon, b.pt_day from \"\n                                        + \" default_catalog.default_database.probe as p\"\n                                        + \" join partition_table_2 for system_time as of p.p as b on p.x=b.x and p.y=b.y\");\n        List<Row> results = CollectionUtil.iteratorToList(flinkTable.execute().collect());\n        assertEquals(\n                \"[+I[1, a, 10, 2020, 08, 31], +I[2, b, 22, 2020, 08, 31]]\", results.toString());\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":288,"status":"M"}],"commitId":"312fe4c1ce17ac6e5515bcab560b86456993daf5","commitMessage":"@@@[FLINK-22880][table] Remove 'blink' term from code base\n\nThis removes all mentionings of the term \"blink\" in the code\nbase. In order to reduce user confusion.  do not use this term\nanymore but refer to as \"Flink SQL\" or \"Flink Table API\".\n\nThis closes #16374.\n","date":"2021-07-06 19:28:35","modifiedFileCount":"73","status":"M","submitter":"Timo Walther"}]
