[{"authorTime":"2020-10-28 10:11:18","codes":[{"authorDate":"2020-10-28 10:11:18","commitOrder":2,"curCode":"\tpublic void testParallelismSetting() {\n\t\tfinal String dbName = \"source_db\";\n\t\tfinal String tblName = \"test_parallelism\";\n\t\tTableEnvironment tEnv = createTableEnv();\n\t\ttEnv.executeSql(\"CREATE TABLE source_db.test_parallelism \" +\n\t\t\t\t\"(`year` STRING, `value` INT) partitioned by (pt int)\");\n\n\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2014\", 3})\n\t\t\t\t.addRow(new Object[]{\"2014\", 4})\n\t\t\t\t.commit(\"pt=0\");\n\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2015\", 2})\n\t\t\t\t.addRow(new Object[]{\"2015\", 5})\n\t\t\t\t.commit(\"pt=1\");\n\n\t\tTable table = tEnv.sqlQuery(\"select * from hive.source_db.test_parallelism\");\n\t\ttestParallelismSettingTranslateAndAssert(2, table, tEnv);\n\t}\n","date":"2020-10-28 10:11:18","endLine":414,"groupId":"35396","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testParallelismSetting","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/a6/30f69c222c44c64a7d3da3f8e3392f4160c8d1.src","preCode":"\tpublic void testParallelismSetting() {\n\t\tfinal String dbName = \"source_db\";\n\t\tfinal String tblName = \"test_parallelism\";\n\t\tTableEnvironment tEnv = createTableEnv();\n\t\ttEnv.executeSql(\"CREATE TABLE source_db.test_parallelism \" +\n\t\t\t\t\"(`year` STRING, `value` INT) partitioned by (pt int)\");\n\n\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2014\", 3})\n\t\t\t\t.addRow(new Object[]{\"2014\", 4})\n\t\t\t\t.commit(\"pt=0\");\n\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2015\", 2})\n\t\t\t\t.addRow(new Object[]{\"2015\", 5})\n\t\t\t\t.commit(\"pt=1\");\n\n\t\tTable table = tEnv.sqlQuery(\"select * from hive.source_db.test_parallelism\");\n\t\ttestParallelismSettingTranslateAndAssert(2, table, tEnv);\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":396,"status":"MB"},{"authorDate":"2020-10-28 10:11:18","commitOrder":2,"curCode":"\tprivate void testParallelismSettingTranslateAndAssert(int expected, Table table, TableEnvironment tEnv) {\n\t\tPlannerBase planner = (PlannerBase) ((TableEnvironmentImpl) tEnv).getPlanner();\n\t\tRelNode relNode = planner.optimize(TableTestUtil.toRelNode(table));\n\t\tExecNode execNode = planner.translateToExecNodePlan(toScala(Collections.singletonList(relNode))).get(0);\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tTransformation transformation = execNode.translateToPlan(planner);\n\t\tAssert.assertEquals(expected, transformation.getParallelism());\n\t}\n","date":"2020-10-28 10:11:18","endLine":446,"groupId":"6867","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testParallelismSettingTranslateAndAssert","params":"(intexpected@Tabletable@TableEnvironmenttEnv)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/a6/30f69c222c44c64a7d3da3f8e3392f4160c8d1.src","preCode":"\tprivate void testParallelismSettingTranslateAndAssert(int expected, Table table, TableEnvironment tEnv) {\n\t\tPlannerBase planner = (PlannerBase) ((TableEnvironmentImpl) tEnv).getPlanner();\n\t\tRelNode relNode = planner.optimize(TableTestUtil.toRelNode(table));\n\t\tExecNode execNode = planner.translateToExecNodePlan(toScala(Collections.singletonList(relNode))).get(0);\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tTransformation transformation = execNode.translateToPlan(planner);\n\t\tAssert.assertEquals(expected, transformation.getParallelism());\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":439,"status":"B"}],"commitId":"09e0e655a7c7ada3313a1840364658f8111c0200","commitMessage":"@@@[FLINK-19641][hive] Optimize parallelism calculating of HiveTableSource by checking file number\n\nThis closes #13636","date":"2020-10-28 10:11:18","modifiedFileCount":"3","status":"M","submitter":"TsReaper"},{"authorTime":"2020-10-28 10:11:18","codes":[{"authorDate":"2020-11-24 10:53:43","commitOrder":3,"curCode":"\tpublic void testParallelismSetting() throws Exception {\n\t\tfinal String dbName = \"source_db\";\n\t\tfinal String tblName = \"test_parallelism\";\n\t\tbatchTableEnv.executeSql(\"CREATE TABLE source_db.test_parallelism \" +\n\t\t\t\t\"(`year` STRING, `value` INT) partitioned by (pt int)\");\n\n\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2014\", 3})\n\t\t\t\t.addRow(new Object[]{\"2014\", 4})\n\t\t\t\t.commit(\"pt=0\");\n\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2015\", 2})\n\t\t\t\t.addRow(new Object[]{\"2015\", 5})\n\t\t\t\t.commit(\"pt=1\");\n\n\t\tTable table = batchTableEnv.sqlQuery(\"select * from hive.source_db.test_parallelism\");\n\t\ttestParallelismSettingTranslateAndAssert(2, table, batchTableEnv);\n\t}\n","date":"2020-11-24 10:53:43","endLine":397,"groupId":"5793","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testParallelismSetting","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/9c/46eb973413634093e227110599b6dfeb859422.src","preCode":"\tpublic void testParallelismSetting() {\n\t\tfinal String dbName = \"source_db\";\n\t\tfinal String tblName = \"test_parallelism\";\n\t\tTableEnvironment tEnv = createTableEnv();\n\t\ttEnv.executeSql(\"CREATE TABLE source_db.test_parallelism \" +\n\t\t\t\t\"(`year` STRING, `value` INT) partitioned by (pt int)\");\n\n\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2014\", 3})\n\t\t\t\t.addRow(new Object[]{\"2014\", 4})\n\t\t\t\t.commit(\"pt=0\");\n\t\tHiveTestUtils.createTextTableInserter(hiveShell, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2015\", 2})\n\t\t\t\t.addRow(new Object[]{\"2015\", 5})\n\t\t\t\t.commit(\"pt=1\");\n\n\t\tTable table = tEnv.sqlQuery(\"select * from hive.source_db.test_parallelism\");\n\t\ttestParallelismSettingTranslateAndAssert(2, table, tEnv);\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":380,"status":"M"},{"authorDate":"2020-10-28 10:11:18","commitOrder":3,"curCode":"\tprivate void testParallelismSettingTranslateAndAssert(int expected, Table table, TableEnvironment tEnv) {\n\t\tPlannerBase planner = (PlannerBase) ((TableEnvironmentImpl) tEnv).getPlanner();\n\t\tRelNode relNode = planner.optimize(TableTestUtil.toRelNode(table));\n\t\tExecNode execNode = planner.translateToExecNodePlan(toScala(Collections.singletonList(relNode))).get(0);\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tTransformation transformation = execNode.translateToPlan(planner);\n\t\tAssert.assertEquals(expected, transformation.getParallelism());\n\t}\n","date":"2020-10-28 10:11:18","endLine":446,"groupId":"6867","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testParallelismSettingTranslateAndAssert","params":"(intexpected@Tabletable@TableEnvironmenttEnv)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/a6/30f69c222c44c64a7d3da3f8e3392f4160c8d1.src","preCode":"\tprivate void testParallelismSettingTranslateAndAssert(int expected, Table table, TableEnvironment tEnv) {\n\t\tPlannerBase planner = (PlannerBase) ((TableEnvironmentImpl) tEnv).getPlanner();\n\t\tRelNode relNode = planner.optimize(TableTestUtil.toRelNode(table));\n\t\tExecNode execNode = planner.translateToExecNodePlan(toScala(Collections.singletonList(relNode))).get(0);\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tTransformation transformation = execNode.translateToPlan(planner);\n\t\tAssert.assertEquals(expected, transformation.getParallelism());\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":439,"status":"N"}],"commitId":"e9b05e723fb02d9a6dae607ef28244eca6e9edc8","commitMessage":"@@@[FLINK-19653][hive] Reduce our dependency on hive runner for tests\n\nThis closes #14123","date":"2020-11-24 10:53:43","modifiedFileCount":"8","status":"M","submitter":"Rui Li"},{"authorTime":"2021-01-21 14:50:49","codes":[{"authorDate":"2020-11-24 10:53:43","commitOrder":4,"curCode":"\tpublic void testParallelismSetting() throws Exception {\n\t\tfinal String dbName = \"source_db\";\n\t\tfinal String tblName = \"test_parallelism\";\n\t\tbatchTableEnv.executeSql(\"CREATE TABLE source_db.test_parallelism \" +\n\t\t\t\t\"(`year` STRING, `value` INT) partitioned by (pt int)\");\n\n\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2014\", 3})\n\t\t\t\t.addRow(new Object[]{\"2014\", 4})\n\t\t\t\t.commit(\"pt=0\");\n\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2015\", 2})\n\t\t\t\t.addRow(new Object[]{\"2015\", 5})\n\t\t\t\t.commit(\"pt=1\");\n\n\t\tTable table = batchTableEnv.sqlQuery(\"select * from hive.source_db.test_parallelism\");\n\t\ttestParallelismSettingTranslateAndAssert(2, table, batchTableEnv);\n\t}\n","date":"2020-11-24 10:53:43","endLine":397,"groupId":"101064","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testParallelismSetting","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/9c/46eb973413634093e227110599b6dfeb859422.src","preCode":"\tpublic void testParallelismSetting() throws Exception {\n\t\tfinal String dbName = \"source_db\";\n\t\tfinal String tblName = \"test_parallelism\";\n\t\tbatchTableEnv.executeSql(\"CREATE TABLE source_db.test_parallelism \" +\n\t\t\t\t\"(`year` STRING, `value` INT) partitioned by (pt int)\");\n\n\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2014\", 3})\n\t\t\t\t.addRow(new Object[]{\"2014\", 4})\n\t\t\t\t.commit(\"pt=0\");\n\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, dbName, tblName)\n\t\t\t\t.addRow(new Object[]{\"2015\", 2})\n\t\t\t\t.addRow(new Object[]{\"2015\", 5})\n\t\t\t\t.commit(\"pt=1\");\n\n\t\tTable table = batchTableEnv.sqlQuery(\"select * from hive.source_db.test_parallelism\");\n\t\ttestParallelismSettingTranslateAndAssert(2, table, batchTableEnv);\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":380,"status":"N"},{"authorDate":"2021-01-21 14:50:49","commitOrder":4,"curCode":"    private void testParallelismSettingTranslateAndAssert(\n            int expected, Table table, TableEnvironment tEnv) {\n        PlannerBase planner = (PlannerBase) ((TableEnvironmentImpl) tEnv).getPlanner();\n        RelNode relNode = planner.optimize(TableTestUtil.toRelNode(table));\n        ExecNode<?> execNode =\n                planner.translateToExecNodeGraph(toScala(Collections.singletonList(relNode)))\n                        .getRootNodes()\n                        .get(0);\n        Transformation<?> transformation = execNode.translateToPlan(planner);\n        Assert.assertEquals(expected, transformation.getParallelism());\n    }\n","date":"2021-01-21 14:50:49","endLine":492,"groupId":"101064","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testParallelismSettingTranslateAndAssert","params":"(intexpected@Tabletable@TableEnvironmenttEnv)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/3b/bc2f9d665c6dfbfe3cfd939fc2039688ef4b71.src","preCode":"    private void testParallelismSettingTranslateAndAssert(\n            int expected, Table table, TableEnvironment tEnv) {\n        PlannerBase planner = (PlannerBase) ((TableEnvironmentImpl) tEnv).getPlanner();\n        RelNode relNode = planner.optimize(TableTestUtil.toRelNode(table));\n        ExecNode execNode =\n                planner.translateToExecNodePlan(toScala(Collections.singletonList(relNode))).get(0);\n        @SuppressWarnings(\"unchecked\")\n        Transformation transformation = execNode.translateToPlan(planner);\n        Assert.assertEquals(expected, transformation.getParallelism());\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":482,"status":"M"}],"commitId":"842f5cd703f1c31c85f6c4500ea54490924f7a92","commitMessage":"@@@[FLINK-21041][table-planner-blink] Introduce ExecNodeGraph to wrap the ExecNode topology\n\nThis closes #14700","date":"2021-01-21 14:50:49","modifiedFileCount":"6","status":"M","submitter":"godfrey he"}]
