[{"authorTime":"2018-11-02 18:48:46","codes":[{"authorDate":"2018-10-13 14:43:28","commitOrder":2,"curCode":"\tpublic void testFailAndRecoverSameCheckpointTwice() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-and-recover-same-checkpoint-twice\";\n\n\t\tOperatorSubtaskState snapshot1;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\tsnapshot1 = testHarness.snapshot(1, 3);\n\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(3, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43), 30_000L);\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2018-10-16 23:41:13","endLine":348,"groupId":"28571","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testFailAndRecoverSameCheckpointTwice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b1/4b3e2524bfc8f56945e33a3e93cf2402042eca.src","preCode":"\tpublic void testFailAndRecoverSameCheckpointTwice() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-and-recover-same-checkpoint-twice\";\n\n\t\tOperatorSubtaskState snapshot1;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\tsnapshot1 = testHarness.snapshot(1, 3);\n\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(3, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43), 30_000L);\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":304,"status":"NB"},{"authorDate":"2018-11-02 18:48:46","commitOrder":2,"curCode":"\tprivate void testRecoverWithChangeSemantics(\n\t\tString topic,\n\t\tFlinkKafkaProducer.Semantic fromSemantic,\n\t\tFlinkKafkaProducer.Semantic toSemantic) throws Exception {\n\t\tOperatorSubtaskState producerSnapshot;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, fromSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0);\n\t\t\tproducerSnapshot = testHarness.snapshot(1, 3);\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, toSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.initializeState(producerSnapshot);\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(45, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(46, 9);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(2);\n\t\t\ttestHarness.processElement(47, 9);\n\t\t}\n\t}\n","date":"2018-11-07 18:38:50","endLine":609,"groupId":"28571","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoverWithChangeSemantics","params":"(Stringtopic@FlinkKafkaProducer.SemanticfromSemantic@FlinkKafkaProducer.SemantictoSemantic)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/60/70930ae17d908bfaefe2212c8e410ae06fc9fc.src","preCode":"\tprivate void testRecoverWithChangeSemantics(\n\t\tString topic,\n\t\tFlinkKafkaProducer.Semantic fromSemantic,\n\t\tFlinkKafkaProducer.Semantic toSemantic) throws Exception {\n\t\tOperatorSubtaskState producerSnapshot;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, fromSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0);\n\t\t\tproducerSnapshot = testHarness.snapshot(1, 3);\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, toSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.initializeState(producerSnapshot);\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(45, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(46, 9);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(2);\n\t\t\ttestHarness.processElement(47, 9);\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":583,"status":"B"}],"commitId":"85f895b0836c19e4c0e56246aa9af10df8dee09b","commitMessage":"@@@[FLINK-10353][kafka] Support change of transactional semantics in Kafka Producer with existing state\n\nThis closes #7010.\n","date":"2018-11-07 18:38:50","modifiedFileCount":"7","status":"M","submitter":"Stefan Richter"},{"authorTime":"2018-11-02 18:48:46","codes":[{"authorDate":"2018-11-06 20:24:50","commitOrder":3,"curCode":"\tpublic void testFailAndRecoverSameCheckpointTwice() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-and-recover-same-checkpoint-twice\";\n\n\t\tOperatorSubtaskState snapshot1;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\tsnapshot1 = testHarness.snapshot(1, 3);\n\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(3, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43));\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2018-11-07 18:39:52","endLine":348,"groupId":"28571","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testFailAndRecoverSameCheckpointTwice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/29/f157ffb4fc3127da698be17217109b430f1e98.src","preCode":"\tpublic void testFailAndRecoverSameCheckpointTwice() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-and-recover-same-checkpoint-twice\";\n\n\t\tOperatorSubtaskState snapshot1;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\tsnapshot1 = testHarness.snapshot(1, 3);\n\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(3, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43), 30_000L);\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":304,"status":"M"},{"authorDate":"2018-11-02 18:48:46","commitOrder":3,"curCode":"\tprivate void testRecoverWithChangeSemantics(\n\t\tString topic,\n\t\tFlinkKafkaProducer.Semantic fromSemantic,\n\t\tFlinkKafkaProducer.Semantic toSemantic) throws Exception {\n\t\tOperatorSubtaskState producerSnapshot;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, fromSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0);\n\t\t\tproducerSnapshot = testHarness.snapshot(1, 3);\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, toSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.initializeState(producerSnapshot);\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(45, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(46, 9);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(2);\n\t\t\ttestHarness.processElement(47, 9);\n\t\t}\n\t}\n","date":"2018-11-07 18:38:50","endLine":609,"groupId":"28571","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoverWithChangeSemantics","params":"(Stringtopic@FlinkKafkaProducer.SemanticfromSemantic@FlinkKafkaProducer.SemantictoSemantic)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/60/70930ae17d908bfaefe2212c8e410ae06fc9fc.src","preCode":"\tprivate void testRecoverWithChangeSemantics(\n\t\tString topic,\n\t\tFlinkKafkaProducer.Semantic fromSemantic,\n\t\tFlinkKafkaProducer.Semantic toSemantic) throws Exception {\n\t\tOperatorSubtaskState producerSnapshot;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, fromSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0);\n\t\t\tproducerSnapshot = testHarness.snapshot(1, 3);\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, toSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.initializeState(producerSnapshot);\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(45, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(46, 9);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(2);\n\t\t\ttestHarness.processElement(47, 9);\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":583,"status":"N"}],"commitId":"bf0454b1262d8ef51aa945d8b4cb1015f8429ed1","commitMessage":"@@@[hotfix][tests] Deduplicate the default timeout constants in FlinkKafkaProducerITCase\n","date":"2018-11-07 18:39:52","modifiedFileCount":"3","status":"M","submitter":"Stefan Richter"},{"authorTime":"2019-06-11 16:47:37","codes":[{"authorDate":"2019-06-11 16:47:37","commitOrder":4,"curCode":"\tpublic void testFailAndRecoverSameCheckpointTwice() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-and-recover-same-checkpoint-twice\";\n\n\t\tOperatorSubtaskState snapshot1;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\tsnapshot1 = testHarness.snapshot(1, 3);\n\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(3, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43));\n\t\tdeleteTestTopic(topic);\n\t\tcheckProducerLeak();\n\t}\n","date":"2019-06-11 16:47:37","endLine":312,"groupId":"10277","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testFailAndRecoverSameCheckpointTwice","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/10/97fd60255eb66dd8d9351762940b79401ba3a8.src","preCode":"\tpublic void testFailAndRecoverSameCheckpointTwice() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-and-recover-same-checkpoint-twice\";\n\n\t\tOperatorSubtaskState snapshot1;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\tsnapshot1 = testHarness.snapshot(1, 3);\n\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic)) {\n\t\t\ttestHarness.setup();\n\t\t\t\r\n\t\t\ttestHarness.initializeState(snapshot1);\n\t\t\ttestHarness.open();\n\n\t\t\t\r\n\t\t\ttestHarness.processElement(44, 7);\n\t\t\ttestHarness.snapshot(3, 8);\n\t\t\ttestHarness.processElement(45, 9);\n\t\t}\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43));\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":267,"status":"M"},{"authorDate":"2019-06-11 16:47:37","commitOrder":4,"curCode":"\tprivate void testRecoverWithChangeSemantics(\n\t\tString topic,\n\t\tFlinkKafkaProducer.Semantic fromSemantic,\n\t\tFlinkKafkaProducer.Semantic toSemantic) throws Exception {\n\t\tOperatorSubtaskState producerSnapshot;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, fromSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0);\n\t\t\tproducerSnapshot = testHarness.snapshot(1, 3);\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, toSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.initializeState(producerSnapshot);\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(45, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(46, 9);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(2);\n\t\t\ttestHarness.processElement(47, 9);\n\t\t}\n\t\tcheckProducerLeak();\n\t}\n","date":"2019-06-11 16:47:37","endLine":582,"groupId":"10277","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoverWithChangeSemantics","params":"(Stringtopic@FlinkKafkaProducer.SemanticfromSemantic@FlinkKafkaProducer.SemantictoSemantic)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/10/97fd60255eb66dd8d9351762940b79401ba3a8.src","preCode":"\tprivate void testRecoverWithChangeSemantics(\n\t\tString topic,\n\t\tFlinkKafkaProducer.Semantic fromSemantic,\n\t\tFlinkKafkaProducer.Semantic toSemantic) throws Exception {\n\t\tOperatorSubtaskState producerSnapshot;\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, fromSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(42, 0);\n\t\t\ttestHarness.snapshot(0, 1);\n\t\t\ttestHarness.processElement(43, 2);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(0);\n\t\t\tproducerSnapshot = testHarness.snapshot(1, 3);\n\t\t\ttestHarness.processElement(44, 4);\n\t\t}\n\n\t\ttry (OneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic, toSemantic)) {\n\t\t\ttestHarness.setup();\n\t\t\ttestHarness.initializeState(producerSnapshot);\n\t\t\ttestHarness.open();\n\t\t\ttestHarness.processElement(45, 7);\n\t\t\ttestHarness.snapshot(2, 8);\n\t\t\ttestHarness.processElement(46, 9);\n\t\t\ttestHarness.notifyOfCompletedCheckpoint(2);\n\t\t\ttestHarness.processElement(47, 9);\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":555,"status":"M"}],"commitId":"8364849c46db89a15be7793dd421a19713d93b97","commitMessage":"@@@[FLINK-10455][Connectors/Kafka] Ensure all the KafkaProducers closed on an exception\n\nThe patch fixes the bugs reported in FLINK-10445 by making sure all the KafkaProducers are closed when FlinkKafkaProducer is closed. The same fix was applied to universal FlinkKafkaProducer and FlinkKafkaProducer011.\n","date":"2019-06-11 16:47:37","modifiedFileCount":"4","status":"M","submitter":"Jiangjie (Becket) Qin"}]
