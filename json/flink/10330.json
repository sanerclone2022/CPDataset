[{"authorTime":"2020-10-16 20:19:57","codes":[{"authorDate":"2019-02-22 22:57:07","commitOrder":4,"curCode":"\tprivate FlinkKafkaProducer(\n\t\t\tString defaultTopic,\n\t\t\tKeyedSerializationSchema<IN> keyedSchema,\n\t\t\tFlinkKafkaPartitioner<IN> customPartitioner,\n\t\t\tKafkaSerializationSchema<IN> kafkaSchema,\n\t\t\tProperties producerConfig,\n\t\t\tFlinkKafkaProducer.Semantic semantic,\n\t\t\tint kafkaProducersPoolSize) {\n\t\tsuper(new FlinkKafkaProducer.TransactionStateSerializer(), new FlinkKafkaProducer.ContextStateSerializer());\n\n\t\tthis.defaultTopicId = checkNotNull(defaultTopic, \"defaultTopic is null\");\n\n\t\tif (kafkaSchema != null) {\n\t\t\tthis.keyedSchema = null;\n\t\t\tthis.kafkaSchema = kafkaSchema;\n\t\t\tthis.flinkKafkaPartitioner = null;\n\t\t\tClosureCleaner.clean(\n\t\t\t\t\tthis.kafkaSchema, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\n\t\t\tif (customPartitioner != null) {\n\t\t\t\tthrow new IllegalArgumentException(\"Customer partitioner can only be used when\" +\n\t\t\t\t\t\t\"using a KeyedSerializationSchema or SerializationSchema.\");\n\t\t\t}\n\t\t} else if (keyedSchema != null) {\n\t\t\tthis.kafkaSchema = null;\n\t\t\tthis.keyedSchema = keyedSchema;\n\t\t\tthis.flinkKafkaPartitioner = customPartitioner;\n\t\t\tClosureCleaner.clean(\n\t\t\t\t\tthis.flinkKafkaPartitioner,\n\t\t\t\t\tExecutionConfig.ClosureCleanerLevel.RECURSIVE,\n\t\t\t\t\ttrue);\n\t\t\tClosureCleaner.clean(\n\t\t\t\t\tthis.keyedSchema, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\t\t} else {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"You must provide either a KafkaSerializationSchema or a\" +\n\t\t\t\t\t\t\t\"KeyedSerializationSchema.\");\n\t\t}\n\n\t\tthis.producerConfig = checkNotNull(producerConfig, \"producerConfig is null\");\n\t\tthis.semantic = checkNotNull(semantic, \"semantic is null\");\n\t\tthis.kafkaProducersPoolSize = kafkaProducersPoolSize;\n\t\tcheckState(kafkaProducersPoolSize > 0, \"kafkaProducersPoolSize must be non empty\");\n\n\t\t\r\n\t\tif (!producerConfig.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\tif (!producerConfig.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\t\r\n\t\tif (!this.producerConfig.containsKey(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n\t\t\tthrow new IllegalArgumentException(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + \" must be supplied in the producer config properties.\");\n\t\t}\n\n\t\tif (!producerConfig.containsKey(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG)) {\n\t\t\tlong timeout = DEFAULT_KAFKA_TRANSACTION_TIMEOUT.toMilliseconds();\n\t\t\tcheckState(timeout < Integer.MAX_VALUE && timeout > 0, \"timeout does not fit into 32 bit integer\");\n\t\t\tthis.producerConfig.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, (int) timeout);\n\t\t\tLOG.warn(\"Property [{}] not specified. Setting it to {}\", ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, DEFAULT_KAFKA_TRANSACTION_TIMEOUT);\n\t\t}\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif (semantic == FlinkKafkaProducer.Semantic.EXACTLY_ONCE) {\n\t\t\tfinal Object object = this.producerConfig.get(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG);\n\t\t\tfinal long transactionTimeout;\n\t\t\tif (object instanceof String && StringUtils.isNumeric((String) object)) {\n\t\t\t\ttransactionTimeout = Long.parseLong((String) object);\n\t\t\t} else if (object instanceof Number) {\n\t\t\t\ttransactionTimeout = ((Number) object).longValue();\n\t\t\t} else {\n\t\t\t\tthrow new IllegalArgumentException(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG\n\t\t\t\t\t\t+ \" must be numeric, was \" + object);\n\t\t\t}\n\t\t\tsuper.setTransactionTimeout(transactionTimeout);\n\t\t\tsuper.enableTransactionTimeoutWarnings(0.8);\n\t\t}\n\n\t\tthis.topicPartitionsMap = new HashMap<>();\n\t}\n","date":"2019-06-28 15:27:00","endLine":665,"groupId":"9842","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"FlinkKafkaProducer","params":"(StringdefaultTopic@KeyedSerializationSchema<IN>keyedSchema@FlinkKafkaPartitioner<IN>customPartitioner@KafkaSerializationSchema<IN>kafkaSchema@PropertiesproducerConfig@FlinkKafkaProducer.Semanticsemantic@intkafkaProducersPoolSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/a8/bff7c6c3cbe4a0b291a98fa6e0f96881b9906b.src","preCode":"\tprivate FlinkKafkaProducer(\n\t\t\tString defaultTopic,\n\t\t\tKeyedSerializationSchema<IN> keyedSchema,\n\t\t\tFlinkKafkaPartitioner<IN> customPartitioner,\n\t\t\tKafkaSerializationSchema<IN> kafkaSchema,\n\t\t\tProperties producerConfig,\n\t\t\tFlinkKafkaProducer.Semantic semantic,\n\t\t\tint kafkaProducersPoolSize) {\n\t\tsuper(new FlinkKafkaProducer.TransactionStateSerializer(), new FlinkKafkaProducer.ContextStateSerializer());\n\n\t\tthis.defaultTopicId = checkNotNull(defaultTopic, \"defaultTopic is null\");\n\n\t\tif (kafkaSchema != null) {\n\t\t\tthis.keyedSchema = null;\n\t\t\tthis.kafkaSchema = kafkaSchema;\n\t\t\tthis.flinkKafkaPartitioner = null;\n\t\t\tClosureCleaner.clean(\n\t\t\t\t\tthis.kafkaSchema, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\n\t\t\tif (customPartitioner != null) {\n\t\t\t\tthrow new IllegalArgumentException(\"Customer partitioner can only be used when\" +\n\t\t\t\t\t\t\"using a KeyedSerializationSchema or SerializationSchema.\");\n\t\t\t}\n\t\t} else if (keyedSchema != null) {\n\t\t\tthis.kafkaSchema = null;\n\t\t\tthis.keyedSchema = keyedSchema;\n\t\t\tthis.flinkKafkaPartitioner = customPartitioner;\n\t\t\tClosureCleaner.clean(\n\t\t\t\t\tthis.flinkKafkaPartitioner,\n\t\t\t\t\tExecutionConfig.ClosureCleanerLevel.RECURSIVE,\n\t\t\t\t\ttrue);\n\t\t\tClosureCleaner.clean(\n\t\t\t\t\tthis.keyedSchema, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\t\t} else {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"You must provide either a KafkaSerializationSchema or a\" +\n\t\t\t\t\t\t\t\"KeyedSerializationSchema.\");\n\t\t}\n\n\t\tthis.producerConfig = checkNotNull(producerConfig, \"producerConfig is null\");\n\t\tthis.semantic = checkNotNull(semantic, \"semantic is null\");\n\t\tthis.kafkaProducersPoolSize = kafkaProducersPoolSize;\n\t\tcheckState(kafkaProducersPoolSize > 0, \"kafkaProducersPoolSize must be non empty\");\n\n\t\t\r\n\t\tif (!producerConfig.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\tif (!producerConfig.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\t\r\n\t\tif (!this.producerConfig.containsKey(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n\t\t\tthrow new IllegalArgumentException(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + \" must be supplied in the producer config properties.\");\n\t\t}\n\n\t\tif (!producerConfig.containsKey(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG)) {\n\t\t\tlong timeout = DEFAULT_KAFKA_TRANSACTION_TIMEOUT.toMilliseconds();\n\t\t\tcheckState(timeout < Integer.MAX_VALUE && timeout > 0, \"timeout does not fit into 32 bit integer\");\n\t\t\tthis.producerConfig.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, (int) timeout);\n\t\t\tLOG.warn(\"Property [{}] not specified. Setting it to {}\", ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, DEFAULT_KAFKA_TRANSACTION_TIMEOUT);\n\t\t}\n\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif (semantic == FlinkKafkaProducer.Semantic.EXACTLY_ONCE) {\n\t\t\tfinal Object object = this.producerConfig.get(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG);\n\t\t\tfinal long transactionTimeout;\n\t\t\tif (object instanceof String && StringUtils.isNumeric((String) object)) {\n\t\t\t\ttransactionTimeout = Long.parseLong((String) object);\n\t\t\t} else if (object instanceof Number) {\n\t\t\t\ttransactionTimeout = ((Number) object).longValue();\n\t\t\t} else {\n\t\t\t\tthrow new IllegalArgumentException(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG\n\t\t\t\t\t\t+ \" must be numeric, was \" + object);\n\t\t\t}\n\t\t\tsuper.setTransactionTimeout(transactionTimeout);\n\t\t\tsuper.enableTransactionTimeoutWarnings(0.8);\n\t\t}\n\n\t\tthis.topicPartitionsMap = new HashMap<>();\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducer.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":577,"status":"NB"},{"authorDate":"2020-10-16 20:19:57","commitOrder":4,"curCode":"\tpublic FlinkKafkaProducerBase(String defaultTopicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {\n\t\trequireNonNull(defaultTopicId, \"TopicID not set\");\n\t\trequireNonNull(serializationSchema, \"serializationSchema not set\");\n\t\trequireNonNull(producerConfig, \"producerConfig not set\");\n\t\tClosureCleaner.clean(customPartitioner, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\t\tClosureCleaner.ensureSerializable(serializationSchema);\n\n\t\tthis.defaultTopicId = defaultTopicId;\n\t\tthis.schema = serializationSchema;\n\t\tthis.producerConfig = producerConfig;\n\t\tthis.flinkKafkaPartitioner = customPartitioner;\n\n\t\t\r\n\t\tif (!producerConfig.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\tif (!producerConfig.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\t\r\n\t\tif (!this.producerConfig.containsKey(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n\t\t\tthrow new IllegalArgumentException(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + \" must be supplied in the producer config properties.\");\n\t\t}\n\n\t\tthis.topicPartitionsMap = new HashMap<>();\n\t}\n","date":"2020-10-20 05:13:30","endLine":174,"groupId":"32467","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"FlinkKafkaProducerBase","params":"(StringdefaultTopicId@KeyedSerializationSchema<IN>serializationSchema@PropertiesproducerConfig@FlinkKafkaPartitioner<IN>customPartitioner)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/38/8a0653982ae606a858a764cb969f42e7fcfac7.src","preCode":"\tpublic FlinkKafkaProducerBase(String defaultTopicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {\n\t\trequireNonNull(defaultTopicId, \"TopicID not set\");\n\t\trequireNonNull(serializationSchema, \"serializationSchema not set\");\n\t\trequireNonNull(producerConfig, \"producerConfig not set\");\n\t\tClosureCleaner.clean(customPartitioner, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\t\tClosureCleaner.ensureSerializable(serializationSchema);\n\n\t\tthis.defaultTopicId = defaultTopicId;\n\t\tthis.schema = serializationSchema;\n\t\tthis.producerConfig = producerConfig;\n\t\tthis.flinkKafkaPartitioner = customPartitioner;\n\n\t\t\r\n\t\tif (!producerConfig.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\tif (!producerConfig.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\t\r\n\t\tif (!this.producerConfig.containsKey(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n\t\t\tthrow new IllegalArgumentException(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + \" must be supplied in the producer config properties.\");\n\t\t}\n\n\t\tthis.topicPartitionsMap = new HashMap<>();\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":143,"status":"B"}],"commitId":"a87407e60be4e69cb18b6d29b9754d740b8243f0","commitMessage":"@@@[FLINK-19672][connector-kafka] Merge connector-kafka-base and connector-kafka\n","date":"2020-10-20 05:13:30","modifiedFileCount":"0","status":"M","submitter":"Timo Walther"},{"authorTime":"2020-10-16 20:19:57","codes":[{"authorDate":"2021-09-06 18:45:35","commitOrder":5,"curCode":"    private FlinkKafkaProducer(\n            String defaultTopic,\n            KeyedSerializationSchema<IN> keyedSchema,\n            FlinkKafkaPartitioner<IN> customPartitioner,\n            KafkaSerializationSchema<IN> kafkaSchema,\n            Properties producerConfig,\n            FlinkKafkaProducer.Semantic semantic,\n            int kafkaProducersPoolSize) {\n        super(\n                new FlinkKafkaProducer.TransactionStateSerializer(),\n                new FlinkKafkaProducer.ContextStateSerializer());\n\n        this.defaultTopicId = checkNotNull(defaultTopic, \"defaultTopic is null\");\n\n        if (kafkaSchema != null) {\n            this.keyedSchema = null;\n            this.kafkaSchema = kafkaSchema;\n            this.flinkKafkaPartitioner = null;\n            ClosureCleaner.clean(\n                    this.kafkaSchema, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\n            if (customPartitioner != null) {\n                throw new IllegalArgumentException(\n                        \"Customer partitioner can only be used when\"\n                                + \"using a KeyedSerializationSchema or SerializationSchema.\");\n            }\n        } else if (keyedSchema != null) {\n            this.kafkaSchema = null;\n            this.keyedSchema = keyedSchema;\n            this.flinkKafkaPartitioner = customPartitioner;\n            ClosureCleaner.clean(\n                    this.flinkKafkaPartitioner,\n                    ExecutionConfig.ClosureCleanerLevel.RECURSIVE,\n                    true);\n            ClosureCleaner.clean(\n                    this.keyedSchema, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n        } else {\n            throw new IllegalArgumentException(\n                    \"You must provide either a KafkaSerializationSchema or a\"\n                            + \"KeyedSerializationSchema.\");\n        }\n\n        this.producerConfig = checkNotNull(producerConfig, \"producerConfig is null\");\n        this.semantic = checkNotNull(semantic, \"semantic is null\");\n        this.kafkaProducersPoolSize = kafkaProducersPoolSize;\n        checkState(kafkaProducersPoolSize > 0, \"kafkaProducersPoolSize must be non empty\");\n\n        \r\n        if (!producerConfig.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n            this.producerConfig.put(\n                    ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n                    ByteArraySerializer.class.getName());\n        } else {\n            LOG.warn(\n                    \"Overwriting the '{}' is not recommended\",\n                    ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n        }\n\n        if (!producerConfig.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n            this.producerConfig.put(\n                    ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n                    ByteArraySerializer.class.getName());\n        } else {\n            LOG.warn(\n                    \"Overwriting the '{}' is not recommended\",\n                    ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n        }\n\n        \r\n        if (!this.producerConfig.containsKey(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n            throw new IllegalArgumentException(\n                    ProducerConfig.BOOTSTRAP_SERVERS_CONFIG\n                            + \" must be supplied in the producer config properties.\");\n        }\n\n        if (!producerConfig.containsKey(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG)) {\n            long timeout = DEFAULT_KAFKA_TRANSACTION_TIMEOUT.toMilliseconds();\n            checkState(\n                    timeout < Integer.MAX_VALUE && timeout > 0,\n                    \"timeout does not fit into 32 bit integer\");\n            this.producerConfig.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, (int) timeout);\n            LOG.warn(\n                    \"Property [{}] not specified. Setting it to {}\",\n                    ProducerConfig.TRANSACTION_TIMEOUT_CONFIG,\n                    DEFAULT_KAFKA_TRANSACTION_TIMEOUT);\n        }\n\n        \r\n        \r\n        \r\n        if (semantic == FlinkKafkaProducer.Semantic.EXACTLY_ONCE) {\n            final long transactionTimeout = getTransactionTimeout(producerConfig);\n            super.setTransactionTimeout(transactionTimeout);\n            super.enableTransactionTimeoutWarnings(0.8);\n        }\n\n        this.topicPartitionsMap = new HashMap<>();\n    }\n","date":"2021-09-06 18:45:35","endLine":742,"groupId":"10330","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"FlinkKafkaProducer","params":"(StringdefaultTopic@KeyedSerializationSchema<IN>keyedSchema@FlinkKafkaPartitioner<IN>customPartitioner@KafkaSerializationSchema<IN>kafkaSchema@PropertiesproducerConfig@FlinkKafkaProducer.Semanticsemantic@intkafkaProducersPoolSize)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/59/70158b0fc34241cbf9477f3c7c8e1fac9617bb.src","preCode":"    private FlinkKafkaProducer(\n            String defaultTopic,\n            KeyedSerializationSchema<IN> keyedSchema,\n            FlinkKafkaPartitioner<IN> customPartitioner,\n            KafkaSerializationSchema<IN> kafkaSchema,\n            Properties producerConfig,\n            FlinkKafkaProducer.Semantic semantic,\n            int kafkaProducersPoolSize) {\n        super(\n                new FlinkKafkaProducer.TransactionStateSerializer(),\n                new FlinkKafkaProducer.ContextStateSerializer());\n\n        this.defaultTopicId = checkNotNull(defaultTopic, \"defaultTopic is null\");\n\n        if (kafkaSchema != null) {\n            this.keyedSchema = null;\n            this.kafkaSchema = kafkaSchema;\n            this.flinkKafkaPartitioner = null;\n            ClosureCleaner.clean(\n                    this.kafkaSchema, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\n            if (customPartitioner != null) {\n                throw new IllegalArgumentException(\n                        \"Customer partitioner can only be used when\"\n                                + \"using a KeyedSerializationSchema or SerializationSchema.\");\n            }\n        } else if (keyedSchema != null) {\n            this.kafkaSchema = null;\n            this.keyedSchema = keyedSchema;\n            this.flinkKafkaPartitioner = customPartitioner;\n            ClosureCleaner.clean(\n                    this.flinkKafkaPartitioner,\n                    ExecutionConfig.ClosureCleanerLevel.RECURSIVE,\n                    true);\n            ClosureCleaner.clean(\n                    this.keyedSchema, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n        } else {\n            throw new IllegalArgumentException(\n                    \"You must provide either a KafkaSerializationSchema or a\"\n                            + \"KeyedSerializationSchema.\");\n        }\n\n        this.producerConfig = checkNotNull(producerConfig, \"producerConfig is null\");\n        this.semantic = checkNotNull(semantic, \"semantic is null\");\n        this.kafkaProducersPoolSize = kafkaProducersPoolSize;\n        checkState(kafkaProducersPoolSize > 0, \"kafkaProducersPoolSize must be non empty\");\n\n        \r\n        if (!producerConfig.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n            this.producerConfig.put(\n                    ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n                    ByteArraySerializer.class.getName());\n        } else {\n            LOG.warn(\n                    \"Overwriting the '{}' is not recommended\",\n                    ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n        }\n\n        if (!producerConfig.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n            this.producerConfig.put(\n                    ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n                    ByteArraySerializer.class.getName());\n        } else {\n            LOG.warn(\n                    \"Overwriting the '{}' is not recommended\",\n                    ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n        }\n\n        \r\n        if (!this.producerConfig.containsKey(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n            throw new IllegalArgumentException(\n                    ProducerConfig.BOOTSTRAP_SERVERS_CONFIG\n                            + \" must be supplied in the producer config properties.\");\n        }\n\n        if (!producerConfig.containsKey(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG)) {\n            long timeout = DEFAULT_KAFKA_TRANSACTION_TIMEOUT.toMilliseconds();\n            checkState(\n                    timeout < Integer.MAX_VALUE && timeout > 0,\n                    \"timeout does not fit into 32 bit integer\");\n            this.producerConfig.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, (int) timeout);\n            LOG.warn(\n                    \"Property [{}] not specified. Setting it to {}\",\n                    ProducerConfig.TRANSACTION_TIMEOUT_CONFIG,\n                    DEFAULT_KAFKA_TRANSACTION_TIMEOUT);\n        }\n\n        \r\n        \r\n        \r\n        if (semantic == FlinkKafkaProducer.Semantic.EXACTLY_ONCE) {\n            final Object object =\n                    this.producerConfig.get(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG);\n            final long transactionTimeout;\n            if (object instanceof String && StringUtils.isNumeric((String) object)) {\n                transactionTimeout = Long.parseLong((String) object);\n            } else if (object instanceof Number) {\n                transactionTimeout = ((Number) object).longValue();\n            } else {\n                throw new IllegalArgumentException(\n                        ProducerConfig.TRANSACTION_TIMEOUT_CONFIG\n                                + \" must be numeric, was \"\n                                + object);\n            }\n            super.setTransactionTimeout(transactionTimeout);\n            super.enableTransactionTimeoutWarnings(0.8);\n        }\n\n        this.topicPartitionsMap = new HashMap<>();\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducer.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":645,"status":"M"},{"authorDate":"2020-10-16 20:19:57","commitOrder":5,"curCode":"\tpublic FlinkKafkaProducerBase(String defaultTopicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {\n\t\trequireNonNull(defaultTopicId, \"TopicID not set\");\n\t\trequireNonNull(serializationSchema, \"serializationSchema not set\");\n\t\trequireNonNull(producerConfig, \"producerConfig not set\");\n\t\tClosureCleaner.clean(customPartitioner, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\t\tClosureCleaner.ensureSerializable(serializationSchema);\n\n\t\tthis.defaultTopicId = defaultTopicId;\n\t\tthis.schema = serializationSchema;\n\t\tthis.producerConfig = producerConfig;\n\t\tthis.flinkKafkaPartitioner = customPartitioner;\n\n\t\t\r\n\t\tif (!producerConfig.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\tif (!producerConfig.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\t\r\n\t\tif (!this.producerConfig.containsKey(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n\t\t\tthrow new IllegalArgumentException(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + \" must be supplied in the producer config properties.\");\n\t\t}\n\n\t\tthis.topicPartitionsMap = new HashMap<>();\n\t}\n","date":"2020-10-20 05:13:30","endLine":174,"groupId":"10330","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"FlinkKafkaProducerBase","params":"(StringdefaultTopicId@KeyedSerializationSchema<IN>serializationSchema@PropertiesproducerConfig@FlinkKafkaPartitioner<IN>customPartitioner)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/38/8a0653982ae606a858a764cb969f42e7fcfac7.src","preCode":"\tpublic FlinkKafkaProducerBase(String defaultTopicId, KeyedSerializationSchema<IN> serializationSchema, Properties producerConfig, FlinkKafkaPartitioner<IN> customPartitioner) {\n\t\trequireNonNull(defaultTopicId, \"TopicID not set\");\n\t\trequireNonNull(serializationSchema, \"serializationSchema not set\");\n\t\trequireNonNull(producerConfig, \"producerConfig not set\");\n\t\tClosureCleaner.clean(customPartitioner, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\t\tClosureCleaner.ensureSerializable(serializationSchema);\n\n\t\tthis.defaultTopicId = defaultTopicId;\n\t\tthis.schema = serializationSchema;\n\t\tthis.producerConfig = producerConfig;\n\t\tthis.flinkKafkaPartitioner = customPartitioner;\n\n\t\t\r\n\t\tif (!producerConfig.containsKey(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\tif (!producerConfig.containsKey(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n\t\t\tthis.producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, ByteArraySerializer.class.getName());\n\t\t} else {\n\t\t\tLOG.warn(\"Overwriting the '{}' is not recommended\", ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n\t\t}\n\n\t\t\r\n\t\tif (!this.producerConfig.containsKey(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n\t\t\tthrow new IllegalArgumentException(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG + \" must be supplied in the producer config properties.\");\n\t\t}\n\n\t\tthis.topicPartitionsMap = new HashMap<>();\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/main/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":143,"status":"N"}],"commitId":"73bb9d3b40178b001f1b9920b52a0db0b459af70","commitMessage":"@@@[FLINK-23839][kafka] Improve warnings on InvalidTxnState-/ProducerFencedException\n\n","date":"2021-09-06 18:45:35","modifiedFileCount":"2","status":"M","submitter":"David Moravek"}]
