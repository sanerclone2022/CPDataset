[{"authorTime":"2020-10-16 20:19:57","codes":[{"authorDate":"2020-10-16 20:19:57","commitOrder":1,"curCode":"\tpublic void runCancelingOnFullInputTest() throws Exception {\n\t\tfinal String topic = \"cancelingOnFullTopic\";\n\n\t\tfinal int parallelism = 3;\n\t\tcreateTestTopic(topic, parallelism, 1);\n\n\t\t\r\n\t\tDataGenerators.InfiniteStringsGenerator generator =\n\t\t\t\tnew DataGenerators.InfiniteStringsGenerator(kafkaServer, topic);\n\t\tgenerator.start();\n\n\t\t\r\n\n\t\tfinal AtomicReference<Throwable> jobError = new AtomicReference<>();\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setParallelism(parallelism);\n\t\tenv.enableCheckpointing(100);\n\n\t\tProperties props = new Properties();\n\t\tprops.putAll(standardProps);\n\t\tprops.putAll(secureProps);\n\t\tFlinkKafkaConsumerBase<String> source = kafkaServer.getConsumer(topic, new SimpleStringSchema(), props);\n\n\t\tenv.addSource(source).addSink(new DiscardingSink<String>());\n\n\t\tJobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\n\t\tfinal Runnable jobRunner = () -> {\n\t\t\ttry {\n\t\t\t\tsubmitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n\t\t\t} catch (Throwable t) {\n\t\t\t\tjobError.set(t);\n\t\t\t}\n\t\t};\n\n\t\tThread runnerThread = new Thread(jobRunner, \"program runner thread\");\n\t\trunnerThread.start();\n\n\t\t\r\n\t\tThread.sleep(2000);\n\n\t\tThrowable failueCause = jobError.get();\n\t\tif (failueCause != null) {\n\t\t\tfailueCause.printStackTrace();\n\t\t\tAssert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n\t\t}\n\n\t\t\r\n\t\tclient.cancel(jobId).get();\n\n\t\t\r\n\t\trunnerThread.join();\n\n\t\tassertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n\t\tif (generator.isAlive()) {\n\t\t\tgenerator.shutdown();\n\t\t\tgenerator.join();\n\t\t}\n\t\telse {\n\t\t\tThrowable t = generator.getError();\n\t\t\tif (t != null) {\n\t\t\t\tt.printStackTrace();\n\t\t\t\tfail(\"Generator failed: \" + t.getMessage());\n\t\t\t} else {\n\t\t\t\tfail(\"Generator failed with no exception\");\n\t\t\t}\n\t\t}\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2020-10-20 05:13:30","endLine":1044,"groupId":"8244","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"runCancelingOnFullInputTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/45/cb862f300a7c0e0f8a396a92a1bfcae40d57c2.src","preCode":"\tpublic void runCancelingOnFullInputTest() throws Exception {\n\t\tfinal String topic = \"cancelingOnFullTopic\";\n\n\t\tfinal int parallelism = 3;\n\t\tcreateTestTopic(topic, parallelism, 1);\n\n\t\t\r\n\t\tDataGenerators.InfiniteStringsGenerator generator =\n\t\t\t\tnew DataGenerators.InfiniteStringsGenerator(kafkaServer, topic);\n\t\tgenerator.start();\n\n\t\t\r\n\n\t\tfinal AtomicReference<Throwable> jobError = new AtomicReference<>();\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setParallelism(parallelism);\n\t\tenv.enableCheckpointing(100);\n\n\t\tProperties props = new Properties();\n\t\tprops.putAll(standardProps);\n\t\tprops.putAll(secureProps);\n\t\tFlinkKafkaConsumerBase<String> source = kafkaServer.getConsumer(topic, new SimpleStringSchema(), props);\n\n\t\tenv.addSource(source).addSink(new DiscardingSink<String>());\n\n\t\tJobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\n\t\tfinal Runnable jobRunner = () -> {\n\t\t\ttry {\n\t\t\t\tsubmitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n\t\t\t} catch (Throwable t) {\n\t\t\t\tjobError.set(t);\n\t\t\t}\n\t\t};\n\n\t\tThread runnerThread = new Thread(jobRunner, \"program runner thread\");\n\t\trunnerThread.start();\n\n\t\t\r\n\t\tThread.sleep(2000);\n\n\t\tThrowable failueCause = jobError.get();\n\t\tif (failueCause != null) {\n\t\t\tfailueCause.printStackTrace();\n\t\t\tAssert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n\t\t}\n\n\t\t\r\n\t\tclient.cancel(jobId).get();\n\n\t\t\r\n\t\trunnerThread.join();\n\n\t\tassertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n\t\tif (generator.isAlive()) {\n\t\t\tgenerator.shutdown();\n\t\t\tgenerator.join();\n\t\t}\n\t\telse {\n\t\t\tThrowable t = generator.getError();\n\t\t\tif (t != null) {\n\t\t\t\tt.printStackTrace();\n\t\t\t\tfail(\"Generator failed: \" + t.getMessage());\n\t\t\t} else {\n\t\t\t\tfail(\"Generator failed with no exception\");\n\t\t\t}\n\t\t}\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":972,"status":"B"},{"authorDate":"2020-10-16 20:19:57","commitOrder":1,"curCode":"\tpublic void runCancelingOnEmptyInputTest() throws Exception {\n\t\tfinal String topic = \"cancelingOnEmptyInputTopic\";\n\n\t\tfinal int parallelism = 3;\n\t\tcreateTestTopic(topic, parallelism, 1);\n\n\t\tfinal AtomicReference<Throwable> error = new AtomicReference<>();\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setParallelism(parallelism);\n\t\tenv.enableCheckpointing(100);\n\n\t\tProperties props = new Properties();\n\t\tprops.putAll(standardProps);\n\t\tprops.putAll(secureProps);\n\t\tFlinkKafkaConsumerBase<String> source = kafkaServer.getConsumer(topic, new SimpleStringSchema(), props);\n\n\t\tenv.addSource(source).addSink(new DiscardingSink<String>());\n\n\t\tJobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\n\t\tfinal Runnable jobRunner = () -> {\n\t\t\ttry {\n\t\t\t\tsubmitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n\t\t\t} catch (Throwable t) {\n\t\t\t\tLOG.error(\"Job Runner failed with exception\", t);\n\t\t\t\terror.set(t);\n\t\t\t}\n\t\t};\n\n\t\tThread runnerThread = new Thread(jobRunner, \"program runner thread\");\n\t\trunnerThread.start();\n\n\t\t\r\n\t\tThread.sleep(2000);\n\n\t\tThrowable failueCause = error.get();\n\t\tif (failueCause != null) {\n\t\t\tfailueCause.printStackTrace();\n\t\t\tAssert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n\t\t}\n\t\t\r\n\t\tclient.cancel(jobId).get();\n\n\t\t\r\n\t\trunnerThread.join();\n\n\t\tassertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2020-10-20 05:13:30","endLine":1100,"groupId":"8246","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"runCancelingOnEmptyInputTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/45/cb862f300a7c0e0f8a396a92a1bfcae40d57c2.src","preCode":"\tpublic void runCancelingOnEmptyInputTest() throws Exception {\n\t\tfinal String topic = \"cancelingOnEmptyInputTopic\";\n\n\t\tfinal int parallelism = 3;\n\t\tcreateTestTopic(topic, parallelism, 1);\n\n\t\tfinal AtomicReference<Throwable> error = new AtomicReference<>();\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setParallelism(parallelism);\n\t\tenv.enableCheckpointing(100);\n\n\t\tProperties props = new Properties();\n\t\tprops.putAll(standardProps);\n\t\tprops.putAll(secureProps);\n\t\tFlinkKafkaConsumerBase<String> source = kafkaServer.getConsumer(topic, new SimpleStringSchema(), props);\n\n\t\tenv.addSource(source).addSink(new DiscardingSink<String>());\n\n\t\tJobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\t\tfinal JobID jobId = jobGraph.getJobID();\n\n\t\tfinal Runnable jobRunner = () -> {\n\t\t\ttry {\n\t\t\t\tsubmitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n\t\t\t} catch (Throwable t) {\n\t\t\t\tLOG.error(\"Job Runner failed with exception\", t);\n\t\t\t\terror.set(t);\n\t\t\t}\n\t\t};\n\n\t\tThread runnerThread = new Thread(jobRunner, \"program runner thread\");\n\t\trunnerThread.start();\n\n\t\t\r\n\t\tThread.sleep(2000);\n\n\t\tThrowable failueCause = error.get();\n\t\tif (failueCause != null) {\n\t\t\tfailueCause.printStackTrace();\n\t\t\tAssert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n\t\t}\n\t\t\r\n\t\tclient.cancel(jobId).get();\n\n\t\t\r\n\t\trunnerThread.join();\n\n\t\tassertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":1049,"status":"B"}],"commitId":"a87407e60be4e69cb18b6d29b9754d740b8243f0","commitMessage":"@@@[FLINK-19672][connector-kafka] Merge connector-kafka-base and connector-kafka\n","date":"2020-10-20 05:13:30","modifiedFileCount":"0","status":"B","submitter":"Timo Walther"},{"authorTime":"2021-03-08 09:35:30","codes":[{"authorDate":"2021-03-08 09:35:30","commitOrder":2,"curCode":"    public void runCancelingOnFullInputTest() throws Exception {\n        final String topic = \"cancelingOnFullTopic\";\n\n        final int parallelism = 3;\n        createTestTopic(topic, parallelism, 1);\n\n        \r\n        DataGenerators.InfiniteStringsGenerator generator =\n                new DataGenerators.InfiniteStringsGenerator(kafkaServer, topic);\n        generator.start();\n\n        \r\n\n        final AtomicReference<Throwable> jobError = new AtomicReference<>();\n\n        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(parallelism);\n        env.enableCheckpointing(100);\n\n        Properties props = new Properties();\n        props.putAll(standardProps);\n        props.putAll(secureProps);\n        getStream(env, topic, new SimpleStringSchema(), props)\n                .addSink(new DiscardingSink<String>());\n\n        JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n        final JobID jobId = jobGraph.getJobID();\n\n        final Runnable jobRunner =\n                () -> {\n                    try {\n                        submitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n                    } catch (Throwable t) {\n                        jobError.set(t);\n                    }\n                };\n\n        Thread runnerThread = new Thread(jobRunner, \"program runner thread\");\n        runnerThread.start();\n\n        \r\n        Thread.sleep(2000);\n\n        Throwable failueCause = jobError.get();\n        if (failueCause != null) {\n            failueCause.printStackTrace();\n            Assert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n        }\n\n        \r\n        client.cancel(jobId).get();\n\n        \r\n        runnerThread.join();\n\n        assertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n        if (generator.isAlive()) {\n            generator.shutdown();\n            generator.join();\n        } else {\n            Throwable t = generator.getError();\n            if (t != null) {\n                t.printStackTrace();\n                fail(\"Generator failed: \" + t.getMessage());\n            } else {\n                fail(\"Generator failed with no exception\");\n            }\n        }\n\n        deleteTestTopic(topic);\n    }\n","date":"2021-03-30 07:53:01","endLine":1189,"groupId":"10270","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"runCancelingOnFullInputTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/93/e0cfef96b5b0f0e877c88de0373924f5a0b515.src","preCode":"    public void runCancelingOnFullInputTest() throws Exception {\n        final String topic = \"cancelingOnFullTopic\";\n\n        final int parallelism = 3;\n        createTestTopic(topic, parallelism, 1);\n\n        \r\n        DataGenerators.InfiniteStringsGenerator generator =\n                new DataGenerators.InfiniteStringsGenerator(kafkaServer, topic);\n        generator.start();\n\n        \r\n\n        final AtomicReference<Throwable> jobError = new AtomicReference<>();\n\n        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(parallelism);\n        env.enableCheckpointing(100);\n\n        Properties props = new Properties();\n        props.putAll(standardProps);\n        props.putAll(secureProps);\n        FlinkKafkaConsumerBase<String> source =\n                kafkaServer.getConsumer(topic, new SimpleStringSchema(), props);\n\n        env.addSource(source).addSink(new DiscardingSink<String>());\n\n        JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n        final JobID jobId = jobGraph.getJobID();\n\n        final Runnable jobRunner =\n                () -> {\n                    try {\n                        submitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n                    } catch (Throwable t) {\n                        jobError.set(t);\n                    }\n                };\n\n        Thread runnerThread = new Thread(jobRunner, \"program runner thread\");\n        runnerThread.start();\n\n        \r\n        Thread.sleep(2000);\n\n        Throwable failueCause = jobError.get();\n        if (failueCause != null) {\n            failueCause.printStackTrace();\n            Assert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n        }\n\n        \r\n        client.cancel(jobId).get();\n\n        \r\n        runnerThread.join();\n\n        assertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n        if (generator.isAlive()) {\n            generator.shutdown();\n            generator.join();\n        } else {\n            Throwable t = generator.getError();\n            if (t != null) {\n                t.printStackTrace();\n                fail(\"Generator failed: \" + t.getMessage());\n            } else {\n                fail(\"Generator failed with no exception\");\n            }\n        }\n\n        deleteTestTopic(topic);\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":1118,"status":"M"},{"authorDate":"2021-03-08 09:35:30","commitOrder":2,"curCode":"    public void runCancelingOnEmptyInputTest() throws Exception {\n        final String topic = \"cancelingOnEmptyInputTopic\";\n\n        final int parallelism = 3;\n        createTestTopic(topic, parallelism, 1);\n\n        final AtomicReference<Throwable> error = new AtomicReference<>();\n\n        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(parallelism);\n        env.enableCheckpointing(100);\n\n        Properties props = new Properties();\n        props.putAll(standardProps);\n        props.putAll(secureProps);\n\n        getStream(env, topic, new SimpleStringSchema(), props)\n                .addSink(new DiscardingSink<String>());\n\n        JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n        final JobID jobId = jobGraph.getJobID();\n\n        final Runnable jobRunner =\n                () -> {\n                    try {\n                        submitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n                    } catch (Throwable t) {\n                        LOG.error(\"Job Runner failed with exception\", t);\n                        error.set(t);\n                    }\n                };\n\n        Thread runnerThread = new Thread(jobRunner, \"program runner thread\");\n        runnerThread.start();\n\n        \r\n        Thread.sleep(2000);\n\n        Throwable failueCause = error.get();\n        if (failueCause != null) {\n            failueCause.printStackTrace();\n            Assert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n        }\n        \r\n        client.cancel(jobId).get();\n\n        \r\n        runnerThread.join();\n\n        assertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n        deleteTestTopic(topic);\n    }\n","date":"2021-03-30 07:53:01","endLine":1244,"groupId":"10270","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"runCancelingOnEmptyInputTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/93/e0cfef96b5b0f0e877c88de0373924f5a0b515.src","preCode":"    public void runCancelingOnEmptyInputTest() throws Exception {\n        final String topic = \"cancelingOnEmptyInputTopic\";\n\n        final int parallelism = 3;\n        createTestTopic(topic, parallelism, 1);\n\n        final AtomicReference<Throwable> error = new AtomicReference<>();\n\n        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(parallelism);\n        env.enableCheckpointing(100);\n\n        Properties props = new Properties();\n        props.putAll(standardProps);\n        props.putAll(secureProps);\n        FlinkKafkaConsumerBase<String> source =\n                kafkaServer.getConsumer(topic, new SimpleStringSchema(), props);\n\n        env.addSource(source).addSink(new DiscardingSink<String>());\n\n        JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n        final JobID jobId = jobGraph.getJobID();\n\n        final Runnable jobRunner =\n                () -> {\n                    try {\n                        submitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n                    } catch (Throwable t) {\n                        LOG.error(\"Job Runner failed with exception\", t);\n                        error.set(t);\n                    }\n                };\n\n        Thread runnerThread = new Thread(jobRunner, \"program runner thread\");\n        runnerThread.start();\n\n        \r\n        Thread.sleep(2000);\n\n        Throwable failueCause = error.get();\n        if (failueCause != null) {\n            failueCause.printStackTrace();\n            Assert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n        }\n        \r\n        client.cancel(jobId).get();\n\n        \r\n        runnerThread.join();\n\n        assertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n        deleteTestTopic(topic);\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":1192,"status":"M"}],"commitId":"3abf5550a11ac4733799187bf49122417a177b6a","commitMessage":"@@@[FLINK-20114][connector/kafka] Add IT cases for KafkaSource by migrating IT cases from FlinkKafkaConsumer.\n","date":"2021-03-30 07:53:01","modifiedFileCount":"4","status":"M","submitter":"Dong Lin"}]
