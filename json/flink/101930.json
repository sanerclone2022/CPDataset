[{"authorTime":"2020-03-06 08:04:08","codes":[{"authorDate":"2020-05-15 20:39:37","commitOrder":2,"curCode":"\tpublic void testWriteAvroReflect() throws Exception {\n\t\tFile folder = TEMPORARY_FOLDER.newFolder();\n\n\t\tList<Datum> data = Arrays.asList(\n\t\t\tnew Datum(\"a\", 1),\n\t\t\tnew Datum(\"b\", 2),\n\t\t\tnew Datum(\"c\", 3));\n\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setParallelism(1);\n\t\tenv.enableCheckpointing(100);\n\n\t\tAvroWriterFactory<Datum> avroWriterFactory = AvroWriters.forReflectRecord(Datum.class);\n\t\tDataStream<Datum> stream = env.addSource(\n\t\t\tnew FiniteTestSource<>(data),\n\t\t\tTypeInformation.of(Datum.class));\n\t\tstream.addSink(StreamingFileSink.forBulkFormat(\n\t\t\tPath.fromLocalFile(folder),\n\t\t\tavroWriterFactory).build());\n\t\tenv.execute();\n\n\t\tvalidateResults(folder, new ReflectDatumReader<>(Datum.class), data);\n\t}\n","date":"2020-05-15 20:39:37","endLine":137,"groupId":"17373","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testWriteAvroReflect","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/a6/efaaea1c4df12a65ac123c3ab371edb832c154.src","preCode":"\tpublic void testWriteAvroReflect() throws Exception {\n\t\tFile folder = TEMPORARY_FOLDER.newFolder();\n\n\t\tList<Datum> data = Arrays.asList(\n\t\t\tnew Datum(\"a\", 1),\n\t\t\tnew Datum(\"b\", 2),\n\t\t\tnew Datum(\"c\", 3));\n\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setParallelism(1);\n\t\tenv.enableCheckpointing(100);\n\n\t\tAvroWriterFactory<Datum> avroWriterFactory = AvroWriters.forReflectRecord(Datum.class);\n\t\tDataStream<Datum> stream = env.addSource(\n\t\t\tnew FiniteTestSource<>(data),\n\t\t\tTypeInformation.of(Datum.class));\n\t\tstream.addSink(StreamingFileSink.forBulkFormat(\n\t\t\tPath.fromLocalFile(folder),\n\t\t\tavroWriterFactory).build());\n\t\tenv.execute();\n\n\t\tvalidateResults(folder, new ReflectDatumReader<>(Datum.class), data);\n\t}\n","realPath":"flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroStreamingFileSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":115,"status":"NB"},{"authorDate":"2020-03-06 08:04:08","commitOrder":2,"curCode":"\tpublic void testWriteParquetAvroReflect() throws Exception {\n\n\t\tfinal File folder = TEMPORARY_FOLDER.newFolder();\n\n\t\tfinal List<Datum> data = Arrays.asList(\n\t\t\t\tnew Datum(\"a\", 1), new Datum(\"b\", 2), new Datum(\"c\", 3));\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setParallelism(1);\n\t\tenv.enableCheckpointing(100);\n\n\t\tDataStream<Datum> stream = env.addSource(\n\t\t\t\tnew FiniteTestSource<>(data), TypeInformation.of(Datum.class));\n\n\t\tstream.addSink(\n\t\t\t\tStreamingFileSink.forBulkFormat(\n\t\t\t\t\t\tPath.fromLocalFile(folder),\n\t\t\t\t\t\tParquetAvroWriters.forReflectRecord(Datum.class))\n\t\t\t\t\t\t.build());\n\n\t\tenv.execute();\n\n\t\tvalidateResults(folder, ReflectData.get(), data);\n\t}\n","date":"2020-10-12 18:46:58","endLine":154,"groupId":"17373","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testWriteParquetAvroReflect","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/4e/c747e4db5acfba81ec7cab3b83310bcc96d6fc.src","preCode":"\tpublic void testWriteParquetAvroReflect() throws Exception {\n\n\t\tfinal File folder = TEMPORARY_FOLDER.newFolder();\n\n\t\tfinal List<Datum> data = Arrays.asList(\n\t\t\t\tnew Datum(\"a\", 1), new Datum(\"b\", 2), new Datum(\"c\", 3));\n\n\t\tfinal StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.setParallelism(1);\n\t\tenv.enableCheckpointing(100);\n\n\t\tDataStream<Datum> stream = env.addSource(\n\t\t\t\tnew FiniteTestSource<>(data), TypeInformation.of(Datum.class));\n\n\t\tstream.addSink(\n\t\t\t\tStreamingFileSink.forBulkFormat(\n\t\t\t\t\t\tPath.fromLocalFile(folder),\n\t\t\t\t\t\tParquetAvroWriters.forReflectRecord(Datum.class))\n\t\t\t\t\t\t.build());\n\n\t\tenv.execute();\n\n\t\tvalidateResults(folder, ReflectData.get(), data);\n\t}\n","realPath":"flink-formats/flink-parquet/src/test/java/org/apache/flink/formats/parquet/avro/ParquetAvroStreamingFileSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":131,"status":"B"}],"commitId":"e0565444a08b1d176fcb3133b8f70c3629072370","commitMessage":"@@@[hotfix] Rename ParquetStreamingFileSinkITCase\n","date":"2020-10-12 18:46:58","modifiedFileCount":"0","status":"M","submitter":"Gao Yun"},{"authorTime":"2021-08-25 10:43:17","codes":[{"authorDate":"2021-08-25 10:43:17","commitOrder":3,"curCode":"    public void testWriteAvroReflect() throws Exception {\n        File folder = TEMPORARY_FOLDER.newFolder();\n\n        List<Datum> data = Arrays.asList(new Datum(\"a\", 1), new Datum(\"b\", 2), new Datum(\"c\", 3));\n\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(1);\n        env.enableCheckpointing(100);\n\n        AvroWriterFactory<Datum> avroWriterFactory = AvroWriters.forReflectRecord(Datum.class);\n        DataStream<Datum> stream =\n                env.addSource(new FiniteTestSource<>(data), TypeInformation.of(Datum.class));\n        stream.addSink(\n                StreamingFileSink.forBulkFormat(Path.fromLocalFile(folder), avroWriterFactory)\n                        .withBucketAssigner(new UniqueBucketAssigner<>(\"test\"))\n                        .build());\n        env.execute();\n\n        validateResults(folder, new ReflectDatumReader<>(Datum.class), data);\n    }\n","date":"2021-08-25 19:29:37","endLine":135,"groupId":"101930","id":3,"instanceNumber":1,"isCurCommit":1,"methodName":"testWriteAvroReflect","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/c0/5e381c816cb4d3104223c88551a09d420452ce.src","preCode":"    public void testWriteAvroReflect() throws Exception {\n        File folder = TEMPORARY_FOLDER.newFolder();\n\n        List<Datum> data = Arrays.asList(new Datum(\"a\", 1), new Datum(\"b\", 2), new Datum(\"c\", 3));\n\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(1);\n        env.enableCheckpointing(100);\n\n        AvroWriterFactory<Datum> avroWriterFactory = AvroWriters.forReflectRecord(Datum.class);\n        DataStream<Datum> stream =\n                env.addSource(new FiniteTestSource<>(data), TypeInformation.of(Datum.class));\n        stream.addSink(\n                StreamingFileSink.forBulkFormat(Path.fromLocalFile(folder), avroWriterFactory)\n                        .build());\n        env.execute();\n\n        validateResults(folder, new ReflectDatumReader<>(Datum.class), data);\n    }\n","realPath":"flink-formats/flink-avro/src/test/java/org/apache/flink/formats/avro/AvroStreamingFileSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":116,"status":"M"},{"authorDate":"2021-08-25 10:43:17","commitOrder":3,"curCode":"    public void testWriteParquetAvroReflect() throws Exception {\n\n        final File folder = TEMPORARY_FOLDER.newFolder();\n\n        final List<Datum> data =\n                Arrays.asList(new Datum(\"a\", 1), new Datum(\"b\", 2), new Datum(\"c\", 3));\n\n        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(1);\n        env.enableCheckpointing(100);\n\n        DataStream<Datum> stream =\n                env.addSource(new FiniteTestSource<>(data), TypeInformation.of(Datum.class));\n\n        stream.addSink(\n                StreamingFileSink.forBulkFormat(\n                                Path.fromLocalFile(folder),\n                                ParquetAvroWriters.forReflectRecord(Datum.class))\n                        .withBucketAssigner(new UniqueBucketAssigner<>(\"test\"))\n                        .build());\n\n        env.execute();\n\n        validateResults(folder, ReflectData.get(), data);\n    }\n","date":"2021-08-25 19:29:37","endLine":157,"groupId":"101930","id":4,"instanceNumber":2,"isCurCommit":1,"methodName":"testWriteParquetAvroReflect","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/bf/a10f12d929991b909ef74132460e56d7a0d86e.src","preCode":"    public void testWriteParquetAvroReflect() throws Exception {\n\n        final File folder = TEMPORARY_FOLDER.newFolder();\n\n        final List<Datum> data =\n                Arrays.asList(new Datum(\"a\", 1), new Datum(\"b\", 2), new Datum(\"c\", 3));\n\n        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(1);\n        env.enableCheckpointing(100);\n\n        DataStream<Datum> stream =\n                env.addSource(new FiniteTestSource<>(data), TypeInformation.of(Datum.class));\n\n        stream.addSink(\n                StreamingFileSink.forBulkFormat(\n                                Path.fromLocalFile(folder),\n                                ParquetAvroWriters.forReflectRecord(Datum.class))\n                        .build());\n\n        env.execute();\n\n        validateResults(folder, ReflectData.get(), data);\n    }\n","realPath":"flink-formats/flink-parquet/src/test/java/org/apache/flink/formats/parquet/avro/ParquetAvroStreamingFileSinkITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":133,"status":"M"}],"commitId":"5390e91bd47219adde15d5d515a4f5baf4231fc2","commitMessage":"@@@[FLINK-22710][formats] Explicitly set the bucket assigner to avoid writing into two buckets in the tests\n\nThis closes #16950.\n","date":"2021-08-25 19:29:37","modifiedFileCount":"9","status":"M","submitter":"Yun Gao"}]
