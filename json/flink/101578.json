[{"authorTime":"2016-10-06 22:43:42","codes":[{"authorDate":"2016-10-06 22:43:42","commitOrder":2,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, false);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, false);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof SuppressRestartsException) {\n\t\t\t\tSuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause();\n\n\t\t\t\tif (suppressRestartsException.getCause() instanceof IllegalStateException) {\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t} else {\n\t\t\t\t\tthrow exception;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-10-14 16:05:06","endLine":320,"groupId":"45928","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/48/d720a0e0c0c46bf1b54d675144ceb5beceddea.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, false);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, false);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof SuppressRestartsException) {\n\t\t\t\tSuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause();\n\n\t\t\t\tif (suppressRestartsException.getCause() instanceof IllegalStateException) {\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t} else {\n\t\t\t\t\tthrow exception;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":232,"status":"MB"},{"authorDate":"2016-10-06 22:43:42","commitOrder":2,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, true);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, true);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\tsumExp += c;\n\t\t\t}\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\tsumAct += c;\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-10-14 16:05:06","endLine":548,"groupId":"46801","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/48/d720a0e0c0c46bf1b54d675144ceb5beceddea.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, true);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, true);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\tsumExp += c;\n\t\t\t}\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\tsumAct += c;\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":456,"status":"MB"}],"commitId":"fd410d9f6d1c8d53fb721752528ebd77fd78db57","commitMessage":"@@@[FLINK-4512] [FLIP-10] Add option to persist periodic checkpoints\n\n[FLINK-4509] [FLIP-10] Specify savepoint directory per savepoint\n[FLINK-4507] [FLIP-10] Deprecate savepoint backend config\n\nThis closes #2608.\n","date":"2016-10-14 16:05:06","modifiedFileCount":"50","status":"M","submitter":"Ufuk Celebi"},{"authorTime":"2016-10-06 22:43:42","codes":[{"authorDate":"2016-09-14 20:27:27","commitOrder":3,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, false);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, false);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-10-19 17:41:26","endLine":313,"groupId":"45928","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/0e/513fa00c662aa51a430f164dba25d9ebc332d3.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, false);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, false);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof SuppressRestartsException) {\n\t\t\t\tSuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause();\n\n\t\t\t\tif (suppressRestartsException.getCause() instanceof IllegalStateException) {\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t} else {\n\t\t\t\t\tthrow exception;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":231,"status":"M"},{"authorDate":"2016-10-06 22:43:42","commitOrder":3,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, true);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, true);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\tsumExp += c;\n\t\t\t}\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\tsumAct += c;\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-10-14 16:05:06","endLine":548,"groupId":"46801","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/48/d720a0e0c0c46bf1b54d675144ceb5beceddea.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, true);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, true);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\tsumExp += c;\n\t\t\t}\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\tsumAct += c;\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":456,"status":"N"}],"commitId":"b05c3c1b01fc48674d01e138e5e3e628c823974f","commitMessage":"@@@[FLINK-4619] Answer with JobResultFailure if savepoint restore fails during submission\n\nThis closes #2498.\n","date":"2016-10-19 17:41:26","modifiedFileCount":"3","status":"M","submitter":"Maciek Pr?chniak"},{"authorTime":"2016-10-04 16:59:38","codes":[{"authorDate":"2016-10-04 16:59:38","commitOrder":4,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-10-20 22:14:21","endLine":321,"groupId":"45928","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/95/115d65b56d0638f1dd1ef61cf5c1082fdde3c1.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, false);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, false);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":239,"status":"M"},{"authorDate":"2016-10-04 16:59:38","commitOrder":4,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-10-20 22:14:21","endLine":574,"groupId":"21856","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/95/115d65b56d0638f1dd1ef61cf5c1082fdde3c1.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, true);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, true);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\tsumExp += c;\n\t\t\t}\n\n\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\tsumAct += c;\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":467,"status":"M"}],"commitId":"cab9cd44eca83ef8cbcd2a2d070d8c79cb037977","commitMessage":"@@@[FLINK-4844] Partitionable Raw Keyed/Operator State\n","date":"2016-10-20 22:14:21","modifiedFileCount":"87","status":"M","submitter":"Stefan Richter"},{"authorTime":"2016-10-04 16:59:38","codes":[{"authorDate":"2016-10-31 07:36:58","commitOrder":5,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-10-31 21:02:59","endLine":315,"groupId":"45928","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/da/25ae641618d675da72dd285da22db63b2603b5.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":239,"status":"M"},{"authorDate":"2016-10-04 16:59:38","commitOrder":5,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-10-20 22:14:21","endLine":574,"groupId":"21856","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/95/115d65b56d0638f1dd1ef61cf5c1082fdde3c1.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":467,"status":"N"}],"commitId":"094b747a39906f01f6a8b92233a5a8011618e641","commitMessage":"@@@[hotfix] Improved test stability of RescalingITCase\n\nThis closes #2728.\n","date":"2016-10-31 21:02:59","modifiedFileCount":"1","status":"M","submitter":"Stefan Richter"},{"authorTime":"2016-10-27 00:05:26","codes":[{"authorDate":"2016-10-27 00:05:26","commitOrder":6,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-11-02 14:34:21","endLine":316,"groupId":"45928","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/5a/6417329010ded63de2a627feec65dd6d6eb3d8.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"M"},{"authorDate":"2016-10-27 00:05:26","commitOrder":6,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-11-02 14:34:21","endLine":569,"groupId":"21856","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/5a/6417329010ded63de2a627feec65dd6d6eb3d8.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointPath(savepointPath);\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":462,"status":"M"}],"commitId":"c0e620f0ace0aa3500a5642e7165cf9f05e81f6a","commitMessage":"@@@[FLINK-4445] [checkpointing] Add option to allow non restored checkpoint state\n\nAllows to skip checkpoint state that cannot be mapped to a job vertex when\nrestoring.\n\nThis closes #2712.\n","date":"2016-11-02 14:34:21","modifiedFileCount":"12","status":"M","submitter":"Ufuk Celebi"},{"authorTime":"2016-12-03 09:42:25","codes":[{"authorDate":"2016-10-27 00:05:26","commitOrder":7,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-11-02 14:34:21","endLine":316,"groupId":"45928","id":11,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/5a/6417329010ded63de2a627feec65dd6d6eb3d8.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"N"},{"authorDate":"2016-12-03 09:42:25","commitOrder":7,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tSystem.out.println(savepointResponse);\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2017-01-14 04:29:19","endLine":593,"groupId":"52863","id":12,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/45/fcc2533f942890da33322c9c2bb6c52870d632.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":474,"status":"M"}],"commitId":"1020ba2c9cfc1d01703e97c72e20a922bae0732d","commitMessage":"@@@[FLINK-5265] Introduce state handle replication mode for CheckpointCoordinator\n","date":"2017-01-14 04:29:19","modifiedFileCount":"17","status":"M","submitter":"Stefan Richter"},{"authorTime":"2017-05-31 03:40:47","codes":[{"authorDate":"2016-10-27 00:05:26","commitOrder":8,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-11-02 14:34:21","endLine":316,"groupId":"45928","id":13,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/5a/6417329010ded63de2a627feec65dd6d6eb3d8.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"N"},{"authorDate":"2017-05-31 03:40:47","commitOrder":8,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tSystem.out.println(savepointResponse);\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2017-07-13 06:37:47","endLine":629,"groupId":"52863","id":14,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ca/d669364fdbe99dd80339cdbc2656123c7c7c9b.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tSystem.out.println(savepointResponse);\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":510,"status":"M"}],"commitId":"9bd491e05120915cbde36d4452e3982fe5d0975f","commitMessage":"@@@[FLINK-6731] [tests] Activate strict checkstyle for flink-tests\n\nThis closes #4295\n","date":"2017-07-13 06:37:47","modifiedFileCount":"185","status":"M","submitter":"Greg Hogan"},{"authorTime":"2018-02-06 21:44:01","codes":[{"authorDate":"2016-10-27 00:05:26","commitOrder":9,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2016-11-02 14:34:21","endLine":316,"groupId":"45928","id":15,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/5a/6417329010ded63de2a627feec65dd6d6eb3d8.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":240,"status":"N"},{"authorDate":"2018-02-06 21:44:01","commitOrder":9,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","date":"2018-02-25 22:14:21","endLine":626,"groupId":"0","id":16,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/a2/3c679e65f2b37331aa2c6dde179ea2dbc73d46.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tSystem.out.println(savepointResponse);\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":508,"status":"M"}],"commitId":"df3e6bb7627db03635febd48eff4c10032b668ef","commitMessage":"@@@[FLINK-8360][checkpointing] Implement state storage for local recovery and integrate with task lifecycle\n","date":"2018-02-25 22:14:21","modifiedFileCount":"107","status":"M","submitter":"Stefan Richter"},{"authorTime":"2018-03-19 18:36:39","codes":[{"authorDate":"2018-03-19 18:36:39","commitOrder":10,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID);\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tclient.setDetached(false);\n\t\t\tclient.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","date":"2018-03-24 02:11:49","endLine":302,"groupId":"32274","id":17,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e4/f4389bb6abc56bd4f91e9dc2cce1e0784167b8.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\tassertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tjobID = null;\n\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":255,"status":"M"},{"authorDate":"2018-03-19 18:36:39","commitOrder":10,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn client.triggerSavepoint(jobID, null);\n\t\t\t\t\t} catch (FlinkException e) {\n\t\t\t\t\t\treturn FutureUtils.completedExceptionally(e);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID);\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tclient.setDetached(false);\n\t\t\tclient.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","date":"2018-03-24 02:11:49","endLine":530,"groupId":"32275","id":18,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/e4/f4389bb6abc56bd4f91e9dc2cce1e0784167b8.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tFiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES);\n\t\tDeadline deadline = timeout.fromNow();\n\n\t\tJobID jobID = null;\n\t\tActorGateway jobManager = null;\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tjobManager = cluster.getLeaderGateway(deadline.timeLeft());\n\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tjobID = jobGraph.getJobID();\n\n\t\t\tcluster.submitJobDetached(jobGraph);\n\n\t\t\tObject savepointResponse = null;\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\twhile (deadline.hasTimeLeft()) {\n\n\t\t\t\tFuture<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft());\n\t\t\t\tFiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS);\n\t\t\t\tsavepointResponse = Await.result(savepointPathFuture, waitingTime);\n\n\t\t\t\tif (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess);\n\n\t\t\tfinal String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath();\n\n\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft());\n\n\t\t\tFuture<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft());\n\n\t\t\tObject cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft());\n\n\t\t\tassertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess);\n\n\t\t\tAwait.ready(jobRemovedFuture, deadline.timeLeft());\n\n\t\t\t\r\n\t\t\tjobID = null;\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tjobID = scaledJobGraph.getJobID();\n\n\t\t\tcluster.submitJobAndWait(scaledJobGraph, false);\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t\tjobID = null;\n\n\t\t} finally {\n\t\t\t\r\n\t\t\tif (jobID != null && jobManager != null) {\n\t\t\t\tFuture<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout);\n\n\t\t\t\ttry {\n\t\t\t\t\tAwait.ready(jobRemovedFuture, timeout);\n\t\t\t\t} catch (TimeoutException | InterruptedException ie) {\n\t\t\t\t\tfail(\"Failed while cleaning up the cluster.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":435,"status":"M"}],"commitId":"edb6f7fef8c5df6af43bbe28f96d8c6bb3332d00","commitMessage":"@@@[FLINK-8956][tests] Port RescalingITCase to flip6\n\nThis closes #5715.\n","date":"2018-03-24 02:11:49","modifiedFileCount":"1","status":"M","submitter":"zentol"},{"authorTime":"2019-11-01 14:51:28","codes":[{"authorDate":"2019-11-01 14:51:28","commitOrder":11,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID);\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","date":"2019-11-01 14:51:28","endLine":303,"groupId":"32274","id":19,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/cf/1b00a5d2fefb67d804f6f6c5eefe557d94c8d3.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID);\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tclient.setDetached(false);\n\t\t\tclient.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2019-11-01 14:51:28","commitOrder":11,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn client.triggerSavepoint(jobID, null);\n\t\t\t\t\t} catch (FlinkException e) {\n\t\t\t\t\t\treturn FutureUtils.completedExceptionally(e);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID);\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","date":"2019-11-01 14:51:28","endLine":527,"groupId":"2022","id":20,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/cf/1b00a5d2fefb67d804f6f6c5eefe557d94c8d3.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tclient.setDetached(true);\n\t\t\tclient.submitJob(jobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn client.triggerSavepoint(jobID, null);\n\t\t\t\t\t} catch (FlinkException e) {\n\t\t\t\t\t\treturn FutureUtils.completedExceptionally(e);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID);\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tclient.setDetached(false);\n\t\t\tclient.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":434,"status":"M"}],"commitId":"bf5235e340543b9c4551d2131e8a405bd1e9e0c0","commitMessage":"@@@[FLINK-14496][client] Exclude detach flag from ClusterClient\n\nThis closes #9972 .","date":"2019-11-01 14:51:28","modifiedFileCount":"37","status":"M","submitter":"tison"},{"authorTime":"2019-11-08 10:23:59","codes":[{"authorDate":"2019-11-08 10:23:59","commitOrder":12,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","date":"2019-11-08 10:23:59","endLine":303,"groupId":"32274","id":21,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/92/3933fbfc07fbdb138584bed9c14182277a926d.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID);\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"M"},{"authorDate":"2019-11-08 10:23:59","commitOrder":12,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn client.triggerSavepoint(jobID, null);\n\t\t\t\t\t} catch (FlinkException e) {\n\t\t\t\t\t\treturn FutureUtils.completedExceptionally(e);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","date":"2019-11-08 10:23:59","endLine":527,"groupId":"0","id":22,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/92/3933fbfc07fbdb138584bed9c14182277a926d.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn client.triggerSavepoint(jobID, null);\n\t\t\t\t\t} catch (FlinkException e) {\n\t\t\t\t\t\treturn FutureUtils.completedExceptionally(e);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID);\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":434,"status":"M"}],"commitId":"d938c19480c220344827271ff8da729cd91735b3","commitMessage":"@@@[FLINK-14593][client] Port ClusterClient to asynchronous interface version\n\nThis closes #10069 .\n","date":"2019-11-08 10:23:59","modifiedFileCount":"27","status":"M","submitter":"tison"},{"authorTime":"2019-11-29 09:55:23","codes":[{"authorDate":"2019-11-08 10:23:59","commitOrder":13,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","date":"2019-11-08 10:23:59","endLine":303,"groupId":"32274","id":23,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/92/3933fbfc07fbdb138584bed9c14182277a926d.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":258,"status":"N"},{"authorDate":"2019-11-29 09:55:23","commitOrder":13,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> client.triggerSavepoint(jobID, null),\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","date":"2019-11-29 21:51:53","endLine":520,"groupId":"2022","id":24,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f0/f0507374a86fb5d1b00c549d9a0b2740ab6132.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn client.triggerSavepoint(jobID, null);\n\t\t\t\t\t} catch (FlinkException e) {\n\t\t\t\t\t\treturn FutureUtils.completedExceptionally(e);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":433,"status":"M"}],"commitId":"cf4de13474804e84535cba2dd93b1fa980d71652","commitMessage":"@@@[FLINK-14762][client] Implement JobClient#triggerSavepoint\n","date":"2019-11-29 21:51:53","modifiedFileCount":"6","status":"M","submitter":"tison"},{"authorTime":"2020-08-15 08:29:49","codes":[{"authorDate":"2020-08-15 08:29:49","commitOrder":14,"curCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tclient.submitJob(jobGraph).get();\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tsubmitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","date":"2020-08-20 07:30:49","endLine":300,"groupId":"32723","id":25,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/be/58fd7331dde7f5275411e70b2fe077b385f6e9.src","preCode":"\tpublic void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n\t\tfinal int parallelism = numSlots / 2;\n\t\tfinal int parallelism2 = numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\t\r\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\t\t} catch (JobExecutionException exception) {\n\t\t\tif (exception.getCause() instanceof IllegalStateException) {\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t} else {\n\t\t\t\tthrow exception;\n\t\t\t}\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":255,"status":"M"},{"authorDate":"2020-08-15 08:29:49","commitOrder":14,"curCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tclient.submitJob(jobGraph).get();\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> client.triggerSavepoint(jobID, null),\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tsubmitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","date":"2020-08-20 07:30:49","endLine":518,"groupId":"32721","id":26,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/be/58fd7331dde7f5275411e70b2fe077b385f6e9.src","preCode":"\tpublic void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n\t\tfinal int parallelism = scaleOut ? numSlots : numSlots / 2;\n\t\tfinal int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n\t\tfinal int maxParallelism = 13;\n\n\t\tDuration timeout = Duration.ofMinutes(3);\n\t\tDeadline deadline = Deadline.now().plus(timeout);\n\n\t\tClusterClient<?> client = cluster.getClusterClient();\n\n\t\tint counterSize = Math.max(parallelism, parallelism2);\n\n\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||\n\t\t\t\tcheckpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\tPartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSource.checkCorrectRestore = new int[counterSize];\n\t\t} else {\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n\t\t\tPartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n\t\t}\n\n\t\ttry {\n\t\t\tJobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n\t\t\tfinal JobID jobID = jobGraph.getJobID();\n\n\t\t\tClientUtils.submitJob(client, jobGraph);\n\n\t\t\t\r\n\t\t\tStateSourceBase.workStartedLatch.await();\n\n\t\t\tCompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(\n\t\t\t\t() -> client.triggerSavepoint(jobID, null),\n\t\t\t\t(int) deadline.timeLeft().getSeconds() / 10,\n\t\t\t\tTime.seconds(10),\n\t\t\t\t(throwable) -> true,\n\t\t\t\tTestingUtils.defaultScheduledExecutor()\n\t\t\t);\n\n\t\t\tfinal String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n\t\t\tclient.cancel(jobID).get();\n\n\t\t\twhile (!getRunningJobs(client).isEmpty()) {\n\t\t\t\tThread.sleep(50);\n\t\t\t}\n\n\t\t\tJobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n\t\t\tscaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath));\n\n\t\t\tClientUtils.submitJobAndWaitForResult(client, scaledJobGraph, RescalingITCase.class.getClassLoader());\n\n\t\t\tint sumExp = 0;\n\t\t\tint sumAct = 0;\n\n\t\t\tif (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSource.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\n\t\t\t\tsumExp *= parallelism2;\n\t\t\t} else {\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n\t\t\t\t\tsumExp += c;\n\t\t\t\t}\n\n\t\t\t\tfor (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n\t\t\t\t\tsumAct += c;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tassertEquals(sumExp, sumAct);\n\t\t} finally {\n\t\t}\n\t}\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":431,"status":"M"}],"commitId":"dfb8a3be7f0d113032a28cf6a1b296725e5562f5","commitMessage":"@@@[FLINK-15299][test] Move ClientUtils#submitJob & ClientUtils#submitJobAndWaitForResult to test scope\n\nThis closes #11469 .\n","date":"2020-08-20 07:30:49","modifiedFileCount":"28","status":"M","submitter":"tison"},{"authorTime":"2021-04-14 19:54:22","codes":[{"authorDate":"2021-04-14 19:54:22","commitOrder":15,"curCode":"    public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n        final int parallelism = numSlots / 2;\n        final int parallelism2 = numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            \r\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n        } catch (JobExecutionException exception) {\n            if (exception.getCause() instanceof IllegalStateException) {\n                \r\n                \r\n                \r\n            } else {\n                throw exception;\n            }\n        }\n    }\n","date":"2021-04-15 21:01:09","endLine":336,"groupId":"33740","id":27,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ae/da6994fe5fca74412c9d3d8d94c1a655244179.src","preCode":"    public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n        final int parallelism = numSlots / 2;\n        final int parallelism2 = numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            client.cancel(jobID).get();\n\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            \r\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n        } catch (JobExecutionException exception) {\n            if (exception.getCause() instanceof IllegalStateException) {\n                \r\n                \r\n                \r\n            } else {\n                throw exception;\n            }\n        }\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":282,"status":"M"},{"authorDate":"2021-04-14 19:54:22","commitOrder":15,"curCode":"    public void testSavepointRescalingPartitionedOperatorState(\n            boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n        final int parallelism = scaleOut ? numSlots : numSlots / 2;\n        final int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        int counterSize = Math.max(parallelism, parallelism2);\n\n        if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION\n                || checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n            PartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSource.checkCorrectRestore = new int[counterSize];\n        } else {\n            PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n        }\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture =\n                    FutureUtils.retryWithDelay(\n                            () -> client.triggerSavepoint(jobID, null),\n                            (int) deadline.timeLeft().getSeconds() / 10,\n                            Time.seconds(10),\n                            (throwable) -> true,\n                            TestingUtils.defaultScheduledExecutor());\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n            int sumExp = 0;\n            int sumAct = 0;\n\n            if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            } else if (checkpointMethod\n                    == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n\n                sumExp *= parallelism2;\n            } else {\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            }\n\n            assertEquals(sumExp, sumAct);\n        } finally {\n        }\n    }\n","date":"2021-04-15 21:01:09","endLine":589,"groupId":"31404","id":28,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ae/da6994fe5fca74412c9d3d8d94c1a655244179.src","preCode":"    public void testSavepointRescalingPartitionedOperatorState(\n            boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n        final int parallelism = scaleOut ? numSlots : numSlots / 2;\n        final int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        int counterSize = Math.max(parallelism, parallelism2);\n\n        if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION\n                || checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n            PartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSource.checkCorrectRestore = new int[counterSize];\n        } else {\n            PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n        }\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture =\n                    FutureUtils.retryWithDelay(\n                            () -> client.triggerSavepoint(jobID, null),\n                            (int) deadline.timeLeft().getSeconds() / 10,\n                            Time.seconds(10),\n                            (throwable) -> true,\n                            TestingUtils.defaultScheduledExecutor());\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            client.cancel(jobID).get();\n\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n            int sumExp = 0;\n            int sumAct = 0;\n\n            if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            } else if (checkpointMethod\n                    == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n\n                sumExp *= parallelism2;\n            } else {\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            }\n\n            assertEquals(sumExp, sumAct);\n        } finally {\n        }\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":493,"status":"M"}],"commitId":"87efae4d3180a52e16240a0b4bbb197f85acd22c","commitMessage":"@@@[FLINK-21941] Make sure jobs do not finish before taking savepoint in RescalingITCase\n","date":"2021-04-15 21:01:09","modifiedFileCount":"1","status":"M","submitter":"Dawid Wysakowicz"},{"authorTime":"2021-06-25 23:31:35","codes":[{"authorDate":"2021-06-25 23:31:35","commitOrder":16,"curCode":"    public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n        final int parallelism = numSlots / 2;\n        final int parallelism2 = numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID());\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            \r\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n        } catch (JobExecutionException exception) {\n            if (exception.getCause() instanceof IllegalStateException) {\n                \r\n                \r\n                \r\n            } else {\n                throw exception;\n            }\n        }\n    }\n","date":"2021-06-30 17:43:35","endLine":340,"groupId":"33740","id":29,"instanceNumber":1,"isCurCommit":0,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/5e/444689b56eae3385aa4f32f714fd391ef86d25.src","preCode":"    public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n        final int parallelism = numSlots / 2;\n        final int parallelism2 = numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            \r\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n        } catch (JobExecutionException exception) {\n            if (exception.getCause() instanceof IllegalStateException) {\n                \r\n                \r\n                \r\n            } else {\n                throw exception;\n            }\n        }\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":284,"status":"M"},{"authorDate":"2021-06-25 23:31:35","commitOrder":16,"curCode":"    public void testSavepointRescalingPartitionedOperatorState(\n            boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n        final int parallelism = scaleOut ? numSlots : numSlots / 2;\n        final int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        int counterSize = Math.max(parallelism, parallelism2);\n\n        if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION\n                || checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n            PartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSource.checkCorrectRestore = new int[counterSize];\n        } else {\n            PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n        }\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID());\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture =\n                    FutureUtils.retryWithDelay(\n                            () -> client.triggerSavepoint(jobID, null),\n                            (int) deadline.timeLeft().getSeconds() / 10,\n                            Time.seconds(10),\n                            (throwable) -> true,\n                            TestingUtils.defaultScheduledExecutor());\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n            int sumExp = 0;\n            int sumAct = 0;\n\n            if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            } else if (checkpointMethod\n                    == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n\n                sumExp *= parallelism2;\n            } else {\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            }\n\n            assertEquals(sumExp, sumAct);\n        } finally {\n        }\n    }\n","date":"2021-06-30 17:43:35","endLine":596,"groupId":"23512","id":30,"instanceNumber":2,"isCurCommit":0,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/5e/444689b56eae3385aa4f32f714fd391ef86d25.src","preCode":"    public void testSavepointRescalingPartitionedOperatorState(\n            boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n        final int parallelism = scaleOut ? numSlots : numSlots / 2;\n        final int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        int counterSize = Math.max(parallelism, parallelism2);\n\n        if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION\n                || checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n            PartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSource.checkCorrectRestore = new int[counterSize];\n        } else {\n            PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n        }\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture =\n                    FutureUtils.retryWithDelay(\n                            () -> client.triggerSavepoint(jobID, null),\n                            (int) deadline.timeLeft().getSeconds() / 10,\n                            Time.seconds(10),\n                            (throwable) -> true,\n                            TestingUtils.defaultScheduledExecutor());\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n            int sumExp = 0;\n            int sumAct = 0;\n\n            if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            } else if (checkpointMethod\n                    == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n\n                sumExp *= parallelism2;\n            } else {\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            }\n\n            assertEquals(sumExp, sumAct);\n        } finally {\n        }\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":498,"status":"M"}],"commitId":"3b92d67017173547268673d71652a6bc98167abb","commitMessage":"@@@[FLINK-22593][tests] Waiting all tasks running before triggerSavepoint\n","date":"2021-06-30 17:43:35","modifiedFileCount":"3","status":"M","submitter":"Anton Kalashnikov"},{"authorTime":"2021-08-13 08:54:07","codes":[{"authorDate":"2021-08-13 08:54:07","commitOrder":17,"curCode":"    public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n        final int parallelism = numSlots / 2;\n        final int parallelism2 = numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID(), false);\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            \r\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n        } catch (JobExecutionException exception) {\n            if (exception.getCause() instanceof IllegalStateException) {\n                \r\n                \r\n                \r\n            } else {\n                throw exception;\n            }\n        }\n    }\n","date":"2021-08-23 20:24:35","endLine":354,"groupId":"101578","id":31,"instanceNumber":1,"isCurCommit":1,"methodName":"testSavepointRescalingNonPartitionedStateCausesException","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/55/114557496406880db793aaf65bda729c91c226.src","preCode":"    public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n        final int parallelism = numSlots / 2;\n        final int parallelism2 = numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID());\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            \r\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(\n                            parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n        } catch (JobExecutionException exception) {\n            if (exception.getCause() instanceof IllegalStateException) {\n                \r\n                \r\n                \r\n            } else {\n                throw exception;\n            }\n        }\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":298,"status":"M"},{"authorDate":"2021-08-13 08:54:07","commitOrder":17,"curCode":"    public void testSavepointRescalingPartitionedOperatorState(\n            boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n        final int parallelism = scaleOut ? numSlots : numSlots / 2;\n        final int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        int counterSize = Math.max(parallelism, parallelism2);\n\n        if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION\n                || checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n            PartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSource.checkCorrectRestore = new int[counterSize];\n        } else {\n            PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n        }\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID(), false);\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture =\n                    FutureUtils.retryWithDelay(\n                            () -> client.triggerSavepoint(jobID, null),\n                            (int) deadline.timeLeft().getSeconds() / 10,\n                            Time.seconds(10),\n                            (throwable) -> true,\n                            TestingUtils.defaultScheduledExecutor());\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n            int sumExp = 0;\n            int sumAct = 0;\n\n            if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            } else if (checkpointMethod\n                    == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n\n                sumExp *= parallelism2;\n            } else {\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            }\n\n            assertEquals(sumExp, sumAct);\n        } finally {\n        }\n    }\n","date":"2021-08-23 20:24:35","endLine":610,"groupId":"101578","id":32,"instanceNumber":2,"isCurCommit":1,"methodName":"testSavepointRescalingPartitionedOperatorState","params":"(booleanscaleOut@OperatorCheckpointMethodcheckpointMethod)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/55/114557496406880db793aaf65bda729c91c226.src","preCode":"    public void testSavepointRescalingPartitionedOperatorState(\n            boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n        final int parallelism = scaleOut ? numSlots : numSlots / 2;\n        final int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n        final int maxParallelism = 13;\n\n        Duration timeout = Duration.ofMinutes(3);\n        Deadline deadline = Deadline.now().plus(timeout);\n\n        ClusterClient<?> client = cluster.getClusterClient();\n\n        int counterSize = Math.max(parallelism, parallelism2);\n\n        if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION\n                || checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n            PartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSource.checkCorrectRestore = new int[counterSize];\n        } else {\n            PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n            PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n        }\n\n        try {\n            JobGraph jobGraph =\n                    createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n            \r\n            StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n            final JobID jobID = jobGraph.getJobID();\n\n            client.submitJob(jobGraph).get();\n\n            \r\n            waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID());\n            \r\n            StateSourceBase.workStartedLatch.await();\n\n            CompletableFuture<String> savepointPathFuture =\n                    FutureUtils.retryWithDelay(\n                            () -> client.triggerSavepoint(jobID, null),\n                            (int) deadline.timeLeft().getSeconds() / 10,\n                            Time.seconds(10),\n                            (throwable) -> true,\n                            TestingUtils.defaultScheduledExecutor());\n\n            final String savepointPath =\n                    savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \r\n            StateSourceBase.canFinishLatch.countDown();\n            client.cancel(jobID).get();\n            while (!getRunningJobs(client).isEmpty()) {\n                Thread.sleep(50);\n            }\n\n            JobGraph scaledJobGraph =\n                    createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n            scaledJobGraph.setSavepointRestoreSettings(\n                    SavepointRestoreSettings.forPath(savepointPath));\n\n            submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n            int sumExp = 0;\n            int sumAct = 0;\n\n            if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            } else if (checkpointMethod\n                    == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n                for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSource.checkCorrectRestore) {\n                    sumAct += c;\n                }\n\n                sumExp *= parallelism2;\n            } else {\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n                    sumExp += c;\n                }\n\n                for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n                    sumAct += c;\n                }\n            }\n\n            assertEquals(sumExp, sumAct);\n        } finally {\n        }\n    }\n","realPath":"flink-tests/src/test/java/org/apache/flink/test/checkpointing/RescalingITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":512,"status":"M"}],"commitId":"136bb52326922dfe70b3cc79fd463f9d6cfecc32","commitMessage":"@@@[FLINK-23811][tests] Handle finished subtasks in CommonTestUtils.waitForAllTaskRunning\n\nCommonTestUtils.waitForAllTaskRunning returns when all the subtasks are running AND\nthe job is running and not finished. However.  with FLIP-147.  subtasks may finish and\nthe job will still be running. So the method won't return and instead timeout.\n\nThis commit adds a flag to indicate whether to fail or proceed\nwhen a finished sub-task is encountered.\n","date":"2021-08-23 20:24:35","modifiedFileCount":"7","status":"M","submitter":"Roman Khachatryan"}]
