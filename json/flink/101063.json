[{"authorTime":"2020-06-03 10:38:29","codes":[{"authorDate":"2020-06-03 10:38:29","commitOrder":1,"curCode":"\tpublic void testProjectionPushDown() throws Exception {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{1, \"a\"})\n\t\t\t\t\t.addRow(new Object[]{2, \"b\"})\n\t\t\t\t\t.commit(\"p1=2013, p2='2013'\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{3, \"c\"})\n\t\t\t\t\t.commit(\"p1=2014, p2='2014'\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select p1, count(y) from hive.`default`.src group by p1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain =\n\t\t\t\t\t\"HiveTableSource(x, y, p1, p2) TablePath: default.src, PartitionPruned: false, PartitionNums: null, ProjectedFields: [2, 1]\";\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan, physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = Lists.newArrayList(table.execute().collect());\n\t\t\tassertEquals(2, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"2013,2\", \"2014,1\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","date":"2020-06-03 10:38:29","endLine":357,"groupId":"26231","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testProjectionPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/31/7943ad498b940b0c5e615cca86688171e06bb1.src","preCode":"\tpublic void testProjectionPushDown() throws Exception {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{1, \"a\"})\n\t\t\t\t\t.addRow(new Object[]{2, \"b\"})\n\t\t\t\t\t.commit(\"p1=2013, p2='2013'\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{3, \"c\"})\n\t\t\t\t\t.commit(\"p1=2014, p2='2014'\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select p1, count(y) from hive.`default`.src group by p1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain =\n\t\t\t\t\t\"HiveTableSource(x, y, p1, p2) TablePath: default.src, PartitionPruned: false, PartitionNums: null, ProjectedFields: [2, 1]\";\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan, physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = Lists.newArrayList(table.execute().collect());\n\t\t\tassertEquals(2, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"2013,2\", \"2014,1\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":329,"status":"B"},{"authorDate":"2020-06-03 10:38:29","commitOrder":1,"curCode":"\tpublic void testLimitPushDown() throws Exception {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src (a string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t\t.addRow(new Object[]{\"a\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"b\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"c\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"d\"})\n\t\t\t\t\t\t.commit();\n\t\t\t\r\n\t\t\thiveShell.execute(\"analyze table src COMPUTE STATISTICS\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain = \"HiveTableSource(a) TablePath: default.src, PartitionPruned: false, \" +\n\t\t\t\t\t\t\t\t\t\"PartitionNums: null, LimitPushDown true, Limit 1\";\n\t\t\tassertTrue(logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = Lists.newArrayList(table.execute().collect());\n\t\t\tassertEquals(1, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"a\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","date":"2020-06-03 10:38:29","endLine":389,"groupId":"45972","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testLimitPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/31/7943ad498b940b0c5e615cca86688171e06bb1.src","preCode":"\tpublic void testLimitPushDown() throws Exception {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src (a string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t\t.addRow(new Object[]{\"a\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"b\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"c\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"d\"})\n\t\t\t\t\t\t.commit();\n\t\t\t\r\n\t\t\thiveShell.execute(\"analyze table src COMPUTE STATISTICS\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain = \"HiveTableSource(a) TablePath: default.src, PartitionPruned: false, \" +\n\t\t\t\t\t\t\t\t\t\"PartitionNums: null, LimitPushDown true, Limit 1\";\n\t\t\tassertTrue(logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = Lists.newArrayList(table.execute().collect());\n\t\t\tassertEquals(1, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"a\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":360,"status":"B"}],"commitId":"21cb58625b607cf227cfd298595fdda3ed7c579a","commitMessage":"@@@[FLINK-17937][hive] Change some hive connector tests to IT cases\n\n\nThis closes #12333","date":"2020-06-03 10:38:29","modifiedFileCount":"0","status":"B","submitter":"Rui Li"},{"authorTime":"2020-06-18 11:52:35","codes":[{"authorDate":"2020-06-18 11:52:35","commitOrder":2,"curCode":"\tpublic void testProjectionPushDown() {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{1, \"a\"})\n\t\t\t\t\t.addRow(new Object[]{2, \"b\"})\n\t\t\t\t\t.commit(\"p1=2013, p2='2013'\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{3, \"c\"})\n\t\t\t\t\t.commit(\"p1=2014, p2='2014'\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select p1, count(y) from hive.`default`.src group by p1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain =\n\t\t\t\t\t\"HiveTableSource(x, y, p1, p2) TablePath: default.src, PartitionPruned: false, PartitionNums: null, ProjectedFields: [2, 1]\";\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan, physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(2, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"2013,2\", \"2014,1\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","date":"2020-09-07 17:37:11","endLine":366,"groupId":"26231","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testProjectionPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/52/6a45498a992d05b79faa9039e1e7c21234f28c.src","preCode":"\tpublic void testProjectionPushDown() throws Exception {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{1, \"a\"})\n\t\t\t\t\t.addRow(new Object[]{2, \"b\"})\n\t\t\t\t\t.commit(\"p1=2013, p2='2013'\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{3, \"c\"})\n\t\t\t\t\t.commit(\"p1=2014, p2='2014'\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select p1, count(y) from hive.`default`.src group by p1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain =\n\t\t\t\t\t\"HiveTableSource(x, y, p1, p2) TablePath: default.src, PartitionPruned: false, PartitionNums: null, ProjectedFields: [2, 1]\";\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan, physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = Lists.newArrayList(table.execute().collect());\n\t\t\tassertEquals(2, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"2013,2\", \"2014,1\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":338,"status":"M"},{"authorDate":"2020-06-18 11:52:35","commitOrder":2,"curCode":"\tpublic void testLimitPushDown() {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src (a string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t\t.addRow(new Object[]{\"a\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"b\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"c\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"d\"})\n\t\t\t\t\t\t.commit();\n\t\t\t\r\n\t\t\thiveShell.execute(\"analyze table src COMPUTE STATISTICS\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain = \"HiveTableSource(a) TablePath: default.src, PartitionPruned: false, \" +\n\t\t\t\t\t\t\t\t\t\"PartitionNums: null, LimitPushDown true, Limit 1\";\n\t\t\tassertTrue(logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(1, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"a\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","date":"2020-09-07 17:37:11","endLine":398,"groupId":"20316","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testLimitPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/52/6a45498a992d05b79faa9039e1e7c21234f28c.src","preCode":"\tpublic void testLimitPushDown() throws Exception {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src (a string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t\t.addRow(new Object[]{\"a\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"b\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"c\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"d\"})\n\t\t\t\t\t\t.commit();\n\t\t\t\r\n\t\t\thiveShell.execute(\"analyze table src COMPUTE STATISTICS\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain = \"HiveTableSource(a) TablePath: default.src, PartitionPruned: false, \" +\n\t\t\t\t\t\t\t\t\t\"PartitionNums: null, LimitPushDown true, Limit 1\";\n\t\t\tassertTrue(logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = Lists.newArrayList(table.execute().collect());\n\t\t\tassertEquals(1, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"a\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":369,"status":"M"}],"commitId":"91d2b628bfe1a2e7beed5111a6d9a572cc6bc310","commitMessage":"@@@[hotfix][table][connector] Use CollectionUtil#iteratorToList instead of Guava Lists\n","date":"2020-09-07 17:37:11","modifiedFileCount":"18","status":"M","submitter":"godfreyhe"},{"authorTime":"2020-10-28 09:54:12","codes":[{"authorDate":"2020-10-28 09:54:12","commitOrder":3,"curCode":"\tpublic void testProjectionPushDown() {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{1, \"a\"})\n\t\t\t\t\t.addRow(new Object[]{2, \"b\"})\n\t\t\t\t\t.commit(\"p1=2013, p2='2013'\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{3, \"c\"})\n\t\t\t\t\t.commit(\"p1=2014, p2='2014'\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select p1, count(y) from hive.`default`.src group by p1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString expectedExplain =\n\t\t\t\t\t\"table=[[hive, default, src, project=[p1, y]]]\";\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(2, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"2013,2\", \"2014,1\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","date":"2020-10-28 09:54:12","endLine":361,"groupId":"26231","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testProjectionPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/64/14bbb01610a799b5cb10b4f7e69b1843a70dcf.src","preCode":"\tpublic void testProjectionPushDown() {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{1, \"a\"})\n\t\t\t\t\t.addRow(new Object[]{2, \"b\"})\n\t\t\t\t\t.commit(\"p1=2013, p2='2013'\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{3, \"c\"})\n\t\t\t\t\t.commit(\"p1=2014, p2='2014'\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select p1, count(y) from hive.`default`.src group by p1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain =\n\t\t\t\t\t\"HiveTableSource(x, y, p1, p2) TablePath: default.src, PartitionPruned: false, PartitionNums: null, ProjectedFields: [2, 1]\";\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan, physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(2, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"2013,2\", \"2014,1\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":335,"status":"M"},{"authorDate":"2020-10-28 09:54:12","commitOrder":3,"curCode":"\tpublic void testLimitPushDown() {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src (a string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t\t.addRow(new Object[]{\"a\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"b\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"c\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"d\"})\n\t\t\t\t\t\t.commit();\n\t\t\t\r\n\t\t\thiveShell.execute(\"analyze table src COMPUTE STATISTICS\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(\"table=[[hive, default, src, limit=[1]]]\"));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(1, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"a\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","date":"2020-10-28 09:54:12","endLine":389,"groupId":"33238","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testLimitPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/64/14bbb01610a799b5cb10b4f7e69b1843a70dcf.src","preCode":"\tpublic void testLimitPushDown() {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src (a string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t\t.addRow(new Object[]{\"a\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"b\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"c\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"d\"})\n\t\t\t\t\t\t.commit();\n\t\t\t\r\n\t\t\thiveShell.execute(\"analyze table src COMPUTE STATISTICS\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString physicalPlan = explain[3];\n\t\t\tString expectedExplain = \"HiveTableSource(a) TablePath: default.src, PartitionPruned: false, \" +\n\t\t\t\t\t\t\t\t\t\"PartitionNums: null, LimitPushDown true, Limit 1\";\n\t\t\tassertTrue(logicalPlan.contains(expectedExplain));\n\t\t\tassertTrue(physicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(1, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"a\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":364,"status":"M"}],"commitId":"0a14ad1cc47c4c6d4de0d5c90d3cd9578ca2536c","commitMessage":"@@@[FLINK-19789][hive] Migrate Hive connector to new table source sink interface\n\nThis closes #13771","date":"2020-10-28 09:54:12","modifiedFileCount":"10","status":"M","submitter":"Jingsong Lee"},{"authorTime":"2020-11-24 10:53:43","codes":[{"authorDate":"2020-11-24 10:53:43","commitOrder":4,"curCode":"\tpublic void testProjectionPushDown() throws Exception {\n\t\tbatchTableEnv.executeSql(\"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{1, \"a\"})\n\t\t\t\t\t.addRow(new Object[]{2, \"b\"})\n\t\t\t\t\t.commit(\"p1=2013, p2='2013'\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{3, \"c\"})\n\t\t\t\t\t.commit(\"p1=2014, p2='2014'\");\n\t\t\tTable table = batchTableEnv.sqlQuery(\"select p1, count(y) from hive.`default`.src group by p1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString expectedExplain =\n\t\t\t\t\t\"table=[[hive, default, src, project=[p1, y]]]\";\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(2, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"2013,2\", \"2014,1\"}, rowStrings);\n\t\t} finally {\n\t\t\tbatchTableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","date":"2020-11-24 10:53:43","endLine":352,"groupId":"26231","id":7,"instanceNumber":1,"isCurCommit":0,"methodName":"testProjectionPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/9c/46eb973413634093e227110599b6dfeb859422.src","preCode":"\tpublic void testProjectionPushDown() {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{1, \"a\"})\n\t\t\t\t\t.addRow(new Object[]{2, \"b\"})\n\t\t\t\t\t.commit(\"p1=2013, p2='2013'\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t.addRow(new Object[]{3, \"c\"})\n\t\t\t\t\t.commit(\"p1=2014, p2='2014'\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select p1, count(y) from hive.`default`.src group by p1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tString expectedExplain =\n\t\t\t\t\t\"table=[[hive, default, src, project=[p1, y]]]\";\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(2, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"2013,2\", \"2014,1\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":327,"status":"M"},{"authorDate":"2020-11-24 10:53:43","commitOrder":4,"curCode":"\tpublic void testLimitPushDown() throws Exception {\n\t\tbatchTableEnv.executeSql(\"create table src (a string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n\t\t\t\t\t\t.addRow(new Object[]{\"a\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"b\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"c\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"d\"})\n\t\t\t\t\t\t.commit();\n\t\t\tTable table = batchTableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(\"table=[[hive, default, src, limit=[1]]]\"));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(1, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"a\"}, rowStrings);\n\t\t} finally {\n\t\t\tbatchTableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","date":"2020-11-24 10:53:43","endLine":377,"groupId":"26232","id":8,"instanceNumber":2,"isCurCommit":0,"methodName":"testLimitPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/9c/46eb973413634093e227110599b6dfeb859422.src","preCode":"\tpublic void testLimitPushDown() {\n\t\tTableEnvironment tableEnv = createTableEnv();\n\t\ttableEnv.executeSql(\"create table src (a string)\");\n\t\ttry {\n\t\t\tHiveTestUtils.createTextTableInserter(hiveShell, \"default\", \"src\")\n\t\t\t\t\t\t.addRow(new Object[]{\"a\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"b\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"c\"})\n\t\t\t\t\t\t.addRow(new Object[]{\"d\"})\n\t\t\t\t\t\t.commit();\n\t\t\t\r\n\t\t\thiveShell.execute(\"analyze table src COMPUTE STATISTICS\");\n\t\t\tTable table = tableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n\t\t\tString[] explain = table.explain().split(\"==.*==\\n\");\n\t\t\tassertEquals(4, explain.length);\n\t\t\tString logicalPlan = explain[2];\n\t\t\tassertTrue(logicalPlan, logicalPlan.contains(\"table=[[hive, default, src, limit=[1]]]\"));\n\n\t\t\tList<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n\t\t\tassertEquals(1, rows.size());\n\t\t\tObject[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n\t\t\tassertArrayEquals(new String[]{\"a\"}, rowStrings);\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop table src\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":355,"status":"M"}],"commitId":"e9b05e723fb02d9a6dae607ef28244eca6e9edc8","commitMessage":"@@@[FLINK-19653][hive] Reduce our dependency on hive runner for tests\n\nThis closes #14123","date":"2020-11-24 10:53:43","modifiedFileCount":"8","status":"M","submitter":"Rui Li"},{"authorTime":"2020-12-18 18:32:55","codes":[{"authorDate":"2020-12-18 18:32:55","commitOrder":5,"curCode":"    public void testProjectionPushDown() throws Exception {\n        batchTableEnv.executeSql(\n                \"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n        try {\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n                    .addRow(new Object[] {1, \"a\"})\n                    .addRow(new Object[] {2, \"b\"})\n                    .commit(\"p1=2013, p2='2013'\");\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n                    .addRow(new Object[] {3, \"c\"})\n                    .commit(\"p1=2014, p2='2014'\");\n            Table table =\n                    batchTableEnv.sqlQuery(\n                            \"select p1, count(y) from hive.`default`.src group by p1\");\n            String[] explain = table.explain().split(\"==.*==\\n\");\n            assertEquals(4, explain.length);\n            String logicalPlan = explain[2];\n            String expectedExplain = \"table=[[hive, default, src, project=[p1, y]]]\";\n            assertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\n            List<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n            assertEquals(2, rows.size());\n            Object[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n            assertArrayEquals(new String[] {\"+I[2013, 2]\", \"+I[2014, 1]\"}, rowStrings);\n        } finally {\n            batchTableEnv.executeSql(\"drop table src\");\n        }\n    }\n","date":"2021-01-08 00:17:30","endLine":404,"groupId":"101063","id":9,"instanceNumber":1,"isCurCommit":0,"methodName":"testProjectionPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/dd/1bb79a9390eaafc5cd08289e675b44b548395e.src","preCode":"    public void testProjectionPushDown() throws Exception {\n        batchTableEnv.executeSql(\n                \"create table src(x int,y string) partitioned by (p1 bigint, p2 string)\");\n        try {\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n                    .addRow(new Object[] {1, \"a\"})\n                    .addRow(new Object[] {2, \"b\"})\n                    .commit(\"p1=2013, p2='2013'\");\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n                    .addRow(new Object[] {3, \"c\"})\n                    .commit(\"p1=2014, p2='2014'\");\n            Table table =\n                    batchTableEnv.sqlQuery(\n                            \"select p1, count(y) from hive.`default`.src group by p1\");\n            String[] explain = table.explain().split(\"==.*==\\n\");\n            assertEquals(4, explain.length);\n            String logicalPlan = explain[2];\n            String expectedExplain = \"table=[[hive, default, src, project=[p1, y]]]\";\n            assertTrue(logicalPlan, logicalPlan.contains(expectedExplain));\n\n            List<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n            assertEquals(2, rows.size());\n            Object[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n            assertArrayEquals(new String[] {\"2013,2\", \"2014,1\"}, rowStrings);\n        } finally {\n            batchTableEnv.executeSql(\"drop table src\");\n        }\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":377,"status":"M"},{"authorDate":"2020-12-18 18:32:55","commitOrder":5,"curCode":"    public void testLimitPushDown() throws Exception {\n        batchTableEnv.executeSql(\"create table src (a string)\");\n        try {\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n                    .addRow(new Object[] {\"a\"})\n                    .addRow(new Object[] {\"b\"})\n                    .addRow(new Object[] {\"c\"})\n                    .addRow(new Object[] {\"d\"})\n                    .commit();\n            Table table = batchTableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n            String[] explain = table.explain().split(\"==.*==\\n\");\n            assertEquals(4, explain.length);\n            String logicalPlan = explain[2];\n            assertTrue(\n                    logicalPlan, logicalPlan.contains(\"table=[[hive, default, src, limit=[1]]]\"));\n\n            List<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n            assertEquals(1, rows.size());\n            Object[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n            assertArrayEquals(new String[] {\"+I[a]\"}, rowStrings);\n        } finally {\n            batchTableEnv.executeSql(\"drop table src\");\n        }\n    }\n","date":"2021-01-08 00:17:30","endLine":430,"groupId":"101063","id":10,"instanceNumber":2,"isCurCommit":0,"methodName":"testLimitPushDown","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/dd/1bb79a9390eaafc5cd08289e675b44b548395e.src","preCode":"    public void testLimitPushDown() throws Exception {\n        batchTableEnv.executeSql(\"create table src (a string)\");\n        try {\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"default\", \"src\")\n                    .addRow(new Object[] {\"a\"})\n                    .addRow(new Object[] {\"b\"})\n                    .addRow(new Object[] {\"c\"})\n                    .addRow(new Object[] {\"d\"})\n                    .commit();\n            Table table = batchTableEnv.sqlQuery(\"select * from hive.`default`.src limit 1\");\n            String[] explain = table.explain().split(\"==.*==\\n\");\n            assertEquals(4, explain.length);\n            String logicalPlan = explain[2];\n            assertTrue(\n                    logicalPlan, logicalPlan.contains(\"table=[[hive, default, src, limit=[1]]]\"));\n\n            List<Row> rows = CollectionUtil.iteratorToList(table.execute().collect());\n            assertEquals(1, rows.size());\n            Object[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n            assertArrayEquals(new String[] {\"a\"}, rowStrings);\n        } finally {\n            batchTableEnv.executeSql(\"drop table src\");\n        }\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveTableSourceITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":407,"status":"M"}],"commitId":"73cdd3d0d9f6a807b3e47c09eef7983c9aa180c7","commitMessage":"@@@[FLINK-18090] Update tests for new Row.toString\n\nAll tests in modules apart from the Blink planner/runtime\nmodule have been updated.\n\nOtherwise we use a JUnit rule to make the migration of\nthe remaining tests incremental.\n\nThis closes #14568.\n","date":"2021-01-08 00:17:30","modifiedFileCount":"34","status":"M","submitter":"Timo Walther"}]
