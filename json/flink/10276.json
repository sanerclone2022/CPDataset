[{"authorTime":"2018-10-13 14:43:28","codes":[{"authorDate":"2018-11-02 18:48:46","commitOrder":2,"curCode":"\tpublic void testFlinkKafkaProducerFailBeforeNotify() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-before-notify\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open();\n\t\ttestHarness.processElement(42, 0);\n\t\ttestHarness.snapshot(0, 1);\n\t\ttestHarness.processElement(43, 2);\n\t\tOperatorSubtaskState snapshot = testHarness.snapshot(1, 3);\n\n\t\tint leaderId = kafkaServer.getLeaderToShutDown(topic);\n\t\tfailBroker(leaderId);\n\n\t\ttry {\n\t\t\ttestHarness.processElement(44, 4);\n\t\t\ttestHarness.snapshot(2, 5);\n\t\t\tfail();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\r\n\t\t}\n\t\ttry {\n\t\t\ttestHarness.close();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t}\n\n\t\tkafkaServer.restartBroker(leaderId);\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.setup();\n\t\ttestHarness.initializeState(snapshot);\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43), 30_000L);\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2018-11-07 18:38:50","endLine":205,"groupId":"33669","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testFlinkKafkaProducerFailBeforeNotify","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/60/70930ae17d908bfaefe2212c8e410ae06fc9fc.src","preCode":"\tpublic void testFlinkKafkaProducerFailBeforeNotify() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-before-notify\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open();\n\t\ttestHarness.processElement(42, 0);\n\t\ttestHarness.snapshot(0, 1);\n\t\ttestHarness.processElement(43, 2);\n\t\tOperatorSubtaskState snapshot = testHarness.snapshot(1, 3);\n\n\t\tint leaderId = kafkaServer.getLeaderToShutDown(topic);\n\t\tfailBroker(leaderId);\n\n\t\ttry {\n\t\t\ttestHarness.processElement(44, 4);\n\t\t\ttestHarness.snapshot(2, 5);\n\t\t\tfail();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\r\n\t\t}\n\t\ttry {\n\t\t\ttestHarness.close();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t}\n\n\t\tkafkaServer.restartBroker(leaderId);\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.setup();\n\t\ttestHarness.initializeState(snapshot);\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43), 30_000L);\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":166,"status":"B"},{"authorDate":"2018-10-13 14:43:28","commitOrder":2,"curCode":"\tpublic void testRecoverCommittedTransaction() throws Exception {\n\t\tString topic = \"flink-kafka-producer-recover-committed-transaction\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open(); \r\n\t\ttestHarness.processElement(42, 0); \r\n\t\tOperatorSubtaskState checkpoint0 = testHarness.snapshot(0, 1); \r\n\t\ttestHarness.processElement(43, 2); \r\n\t\ttestHarness.notifyOfCompletedCheckpoint(0); \r\n\t\ttestHarness.snapshot(1, 3); \r\n\t\ttestHarness.processElement(44, 4); \r\n\t\ttestHarness.close(); \r\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.initializeState(checkpoint0); \r\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42), 30_000L);\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2018-10-16 23:41:13","endLine":543,"groupId":"28580","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoverCommittedTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b1/4b3e2524bfc8f56945e33a3e93cf2402042eca.src","preCode":"\tpublic void testRecoverCommittedTransaction() throws Exception {\n\t\tString topic = \"flink-kafka-producer-recover-committed-transaction\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open(); \r\n\t\ttestHarness.processElement(42, 0); \r\n\t\tOperatorSubtaskState checkpoint0 = testHarness.snapshot(0, 1); \r\n\t\ttestHarness.processElement(43, 2); \r\n\t\ttestHarness.notifyOfCompletedCheckpoint(0); \r\n\t\ttestHarness.snapshot(1, 3); \r\n\t\ttestHarness.processElement(44, 4); \r\n\t\ttestHarness.close(); \r\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.initializeState(checkpoint0); \r\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42), 30_000L);\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":521,"status":"NB"}],"commitId":"85f895b0836c19e4c0e56246aa9af10df8dee09b","commitMessage":"@@@[FLINK-10353][kafka] Support change of transactional semantics in Kafka Producer with existing state\n\nThis closes #7010.\n","date":"2018-11-07 18:38:50","modifiedFileCount":"7","status":"M","submitter":"Stefan Richter"},{"authorTime":"2018-11-06 20:24:50","codes":[{"authorDate":"2018-11-06 20:24:50","commitOrder":3,"curCode":"\tpublic void testFlinkKafkaProducerFailBeforeNotify() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-before-notify\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open();\n\t\ttestHarness.processElement(42, 0);\n\t\ttestHarness.snapshot(0, 1);\n\t\ttestHarness.processElement(43, 2);\n\t\tOperatorSubtaskState snapshot = testHarness.snapshot(1, 3);\n\n\t\tint leaderId = kafkaServer.getLeaderToShutDown(topic);\n\t\tfailBroker(leaderId);\n\n\t\ttry {\n\t\t\ttestHarness.processElement(44, 4);\n\t\t\ttestHarness.snapshot(2, 5);\n\t\t\tfail();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\r\n\t\t}\n\t\ttry {\n\t\t\ttestHarness.close();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t}\n\n\t\tkafkaServer.restartBroker(leaderId);\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.setup();\n\t\ttestHarness.initializeState(snapshot);\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43));\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2018-11-07 18:39:52","endLine":205,"groupId":"33669","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testFlinkKafkaProducerFailBeforeNotify","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/29/f157ffb4fc3127da698be17217109b430f1e98.src","preCode":"\tpublic void testFlinkKafkaProducerFailBeforeNotify() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-before-notify\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open();\n\t\ttestHarness.processElement(42, 0);\n\t\ttestHarness.snapshot(0, 1);\n\t\ttestHarness.processElement(43, 2);\n\t\tOperatorSubtaskState snapshot = testHarness.snapshot(1, 3);\n\n\t\tint leaderId = kafkaServer.getLeaderToShutDown(topic);\n\t\tfailBroker(leaderId);\n\n\t\ttry {\n\t\t\ttestHarness.processElement(44, 4);\n\t\t\ttestHarness.snapshot(2, 5);\n\t\t\tfail();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\r\n\t\t}\n\t\ttry {\n\t\t\ttestHarness.close();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t}\n\n\t\tkafkaServer.restartBroker(leaderId);\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.setup();\n\t\ttestHarness.initializeState(snapshot);\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43), 30_000L);\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":166,"status":"M"},{"authorDate":"2018-11-06 20:24:50","commitOrder":3,"curCode":"\tpublic void testRecoverCommittedTransaction() throws Exception {\n\t\tString topic = \"flink-kafka-producer-recover-committed-transaction\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open(); \r\n\t\ttestHarness.processElement(42, 0); \r\n\t\tOperatorSubtaskState checkpoint0 = testHarness.snapshot(0, 1); \r\n\t\ttestHarness.processElement(43, 2); \r\n\t\ttestHarness.notifyOfCompletedCheckpoint(0); \r\n\t\ttestHarness.snapshot(1, 3); \r\n\t\ttestHarness.processElement(44, 4); \r\n\t\ttestHarness.close(); \r\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.initializeState(checkpoint0); \r\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42));\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2018-11-07 18:39:52","endLine":542,"groupId":"28580","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoverCommittedTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/29/f157ffb4fc3127da698be17217109b430f1e98.src","preCode":"\tpublic void testRecoverCommittedTransaction() throws Exception {\n\t\tString topic = \"flink-kafka-producer-recover-committed-transaction\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open(); \r\n\t\ttestHarness.processElement(42, 0); \r\n\t\tOperatorSubtaskState checkpoint0 = testHarness.snapshot(0, 1); \r\n\t\ttestHarness.processElement(43, 2); \r\n\t\ttestHarness.notifyOfCompletedCheckpoint(0); \r\n\t\ttestHarness.snapshot(1, 3); \r\n\t\ttestHarness.processElement(44, 4); \r\n\t\ttestHarness.close(); \r\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.initializeState(checkpoint0); \r\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42), 30_000L);\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":520,"status":"M"}],"commitId":"bf0454b1262d8ef51aa945d8b4cb1015f8429ed1","commitMessage":"@@@[hotfix][tests] Deduplicate the default timeout constants in FlinkKafkaProducerITCase\n","date":"2018-11-07 18:39:52","modifiedFileCount":"3","status":"M","submitter":"Stefan Richter"},{"authorTime":"2019-06-11 16:47:37","codes":[{"authorDate":"2019-06-11 16:47:37","commitOrder":4,"curCode":"\tpublic void testFlinkKafkaProducerFailBeforeNotify() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-before-notify\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open();\n\t\ttestHarness.processElement(42, 0);\n\t\ttestHarness.snapshot(0, 1);\n\t\ttestHarness.processElement(43, 2);\n\t\tOperatorSubtaskState snapshot = testHarness.snapshot(1, 3);\n\n\t\tint leaderId = kafkaServer.getLeaderToShutDown(topic);\n\t\tfailBroker(leaderId);\n\n\t\ttry {\n\t\t\ttestHarness.processElement(44, 4);\n\t\t\ttestHarness.snapshot(2, 5);\n\t\t\tfail();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\r\n\t\t}\n\t\ttry {\n\t\t\ttestHarness.close();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t}\n\n\t\tkafkaServer.restartBroker(leaderId);\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.setup();\n\t\ttestHarness.initializeState(snapshot);\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43));\n\n\t\tdeleteTestTopic(topic);\n\t\tcheckProducerLeak();\n\t}\n","date":"2019-06-11 16:47:37","endLine":207,"groupId":"10276","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testFlinkKafkaProducerFailBeforeNotify","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/10/97fd60255eb66dd8d9351762940b79401ba3a8.src","preCode":"\tpublic void testFlinkKafkaProducerFailBeforeNotify() throws Exception {\n\t\tString topic = \"flink-kafka-producer-fail-before-notify\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open();\n\t\ttestHarness.processElement(42, 0);\n\t\ttestHarness.snapshot(0, 1);\n\t\ttestHarness.processElement(43, 2);\n\t\tOperatorSubtaskState snapshot = testHarness.snapshot(1, 3);\n\n\t\tint leaderId = kafkaServer.getLeaderToShutDown(topic);\n\t\tfailBroker(leaderId);\n\n\t\ttry {\n\t\t\ttestHarness.processElement(44, 4);\n\t\t\ttestHarness.snapshot(2, 5);\n\t\t\tfail();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\r\n\t\t}\n\t\ttry {\n\t\t\ttestHarness.close();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t}\n\n\t\tkafkaServer.restartBroker(leaderId);\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.setup();\n\t\ttestHarness.initializeState(snapshot);\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42, 43));\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":167,"status":"M"},{"authorDate":"2019-06-11 16:47:37","commitOrder":4,"curCode":"\tpublic void testRecoverCommittedTransaction() throws Exception {\n\t\tString topic = \"flink-kafka-producer-recover-committed-transaction\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open(); \r\n\t\ttestHarness.processElement(42, 0); \r\n\t\tOperatorSubtaskState checkpoint0 = testHarness.snapshot(0, 1); \r\n\t\ttestHarness.processElement(43, 2); \r\n\t\ttestHarness.notifyOfCompletedCheckpoint(0); \r\n\t\ttestHarness.snapshot(1, 3); \r\n\t\ttestHarness.processElement(44, 4); \r\n\t\ttestHarness.close(); \r\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.initializeState(checkpoint0); \r\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42));\n\n\t\tdeleteTestTopic(topic);\n\t\tcheckProducerLeak();\n\t}\n","date":"2019-06-11 16:47:37","endLine":514,"groupId":"10276","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testRecoverCommittedTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/10/97fd60255eb66dd8d9351762940b79401ba3a8.src","preCode":"\tpublic void testRecoverCommittedTransaction() throws Exception {\n\t\tString topic = \"flink-kafka-producer-recover-committed-transaction\";\n\n\t\tOneInputStreamOperatorTestHarness<Integer, Object> testHarness = createTestHarness(topic);\n\n\t\ttestHarness.setup();\n\t\ttestHarness.open(); \r\n\t\ttestHarness.processElement(42, 0); \r\n\t\tOperatorSubtaskState checkpoint0 = testHarness.snapshot(0, 1); \r\n\t\ttestHarness.processElement(43, 2); \r\n\t\ttestHarness.notifyOfCompletedCheckpoint(0); \r\n\t\ttestHarness.snapshot(1, 3); \r\n\t\ttestHarness.processElement(44, 4); \r\n\t\ttestHarness.close(); \r\n\n\t\ttestHarness = createTestHarness(topic);\n\t\ttestHarness.initializeState(checkpoint0); \r\n\t\ttestHarness.close();\n\n\t\tassertExactlyOnceForTopic(createProperties(), topic, 0, Arrays.asList(42));\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":491,"status":"M"}],"commitId":"8364849c46db89a15be7793dd421a19713d93b97","commitMessage":"@@@[FLINK-10455][Connectors/Kafka] Ensure all the KafkaProducers closed on an exception\n\nThe patch fixes the bugs reported in FLINK-10445 by making sure all the KafkaProducers are closed when FlinkKafkaProducer is closed. The same fix was applied to universal FlinkKafkaProducer and FlinkKafkaProducer011.\n","date":"2019-06-11 16:47:37","modifiedFileCount":"4","status":"M","submitter":"Jiangjie (Becket) Qin"}]
