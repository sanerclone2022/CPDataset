[{"authorTime":"2020-11-04 10:54:31","codes":[{"authorDate":"2020-11-04 10:54:31","commitOrder":1,"curCode":"\tpublic void testCreateSourceTableWithoutPK() {\n\t\tthrown.expect(ValidationException.class);\n\t\tthrown.expect(containsCause(new ValidationException(\"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \" +\n\t\t\t\t\"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \" +\n\t\t\t\t\"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n\t\tTableSchema illegalSchema = TableSchema.builder()\n\t\t\t\t.field(\"window_start\", DataTypes.STRING())\n\t\t\t\t.field(\"region\", DataTypes.STRING())\n\t\t\t\t.field(\"view_count\", DataTypes.BIGINT())\n\t\t\t\t.build();\n\t\tcreateActualSource(illegalSchema, getFullSinkOptions());\n\t}\n","date":"2020-11-05 21:08:26","endLine":197,"groupId":"44345","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testCreateSourceTableWithoutPK","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ed/f697ba642c4739d1fce777c5d3456fd5600ad1.src","preCode":"\tpublic void testCreateSourceTableWithoutPK() {\n\t\tthrown.expect(ValidationException.class);\n\t\tthrown.expect(containsCause(new ValidationException(\"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \" +\n\t\t\t\t\"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \" +\n\t\t\t\t\"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n\t\tTableSchema illegalSchema = TableSchema.builder()\n\t\t\t\t.field(\"window_start\", DataTypes.STRING())\n\t\t\t\t.field(\"region\", DataTypes.STRING())\n\t\t\t\t.field(\"view_count\", DataTypes.BIGINT())\n\t\t\t\t.build();\n\t\tcreateActualSource(illegalSchema, getFullSinkOptions());\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":185,"status":"B"},{"authorDate":"2020-11-04 10:54:31","commitOrder":1,"curCode":"\tpublic void testCreateSinkTableWithoutPK() {\n\t\tthrown.expect(ValidationException.class);\n\t\tthrown.expect(containsCause(new ValidationException(\"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \" +\n\t\t\t\t\"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \" +\n\t\t\t\t\"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n\t\tTableSchema illegalSchema = TableSchema.builder()\n\t\t\t\t.field(\"region\", DataTypes.STRING())\n\t\t\t\t.field(\"view_count\", DataTypes.BIGINT())\n\t\t\t\t.build();\n\t\tcreateActualSink(illegalSchema, getFullSinkOptions());\n\t}\n","date":"2020-11-05 21:08:26","endLine":211,"groupId":"44344","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testCreateSinkTableWithoutPK","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ed/f697ba642c4739d1fce777c5d3456fd5600ad1.src","preCode":"\tpublic void testCreateSinkTableWithoutPK() {\n\t\tthrown.expect(ValidationException.class);\n\t\tthrown.expect(containsCause(new ValidationException(\"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \" +\n\t\t\t\t\"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \" +\n\t\t\t\t\"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n\t\tTableSchema illegalSchema = TableSchema.builder()\n\t\t\t\t.field(\"region\", DataTypes.STRING())\n\t\t\t\t.field(\"view_count\", DataTypes.BIGINT())\n\t\t\t\t.build();\n\t\tcreateActualSink(illegalSchema, getFullSinkOptions());\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":200,"status":"B"}],"commitId":"9cc5e07c43fdae37c5f2afd617091931c92626d6","commitMessage":"@@@[FLINK-19858][upsert-kafka] Introduce the upsert-kafka table factory\n\nThis closes #13850\n","date":"2020-11-05 21:08:26","modifiedFileCount":"10","status":"B","submitter":"Shengkai"},{"authorTime":"2020-11-04 10:54:31","codes":[{"authorDate":"2020-12-22 11:25:21","commitOrder":2,"curCode":"\tpublic void testCreateSourceTableWithoutPK() {\n\t\tthrown.expect(ValidationException.class);\n\t\tthrown.expect(containsCause(new ValidationException(\"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \" +\n\t\t\t\t\"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \" +\n\t\t\t\t\"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n\t\tTableSchema illegalSchema = TableSchema.builder()\n\t\t\t\t.field(\"window_start\", DataTypes.STRING())\n\t\t\t\t.field(\"region\", DataTypes.STRING())\n\t\t\t\t.field(\"view_count\", DataTypes.BIGINT())\n\t\t\t\t.build();\n\t\tcreateActualSource(illegalSchema, getFullSourceOptions());\n\t}\n","date":"2020-12-22 11:25:21","endLine":229,"groupId":"44345","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testCreateSourceTableWithoutPK","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/87/b9d0f13ac894352add359de3dae4fd3197cf61.src","preCode":"\tpublic void testCreateSourceTableWithoutPK() {\n\t\tthrown.expect(ValidationException.class);\n\t\tthrown.expect(containsCause(new ValidationException(\"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \" +\n\t\t\t\t\"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \" +\n\t\t\t\t\"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n\t\tTableSchema illegalSchema = TableSchema.builder()\n\t\t\t\t.field(\"window_start\", DataTypes.STRING())\n\t\t\t\t.field(\"region\", DataTypes.STRING())\n\t\t\t\t.field(\"view_count\", DataTypes.BIGINT())\n\t\t\t\t.build();\n\t\tcreateActualSource(illegalSchema, getFullSinkOptions());\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":217,"status":"M"},{"authorDate":"2020-11-04 10:54:31","commitOrder":2,"curCode":"\tpublic void testCreateSinkTableWithoutPK() {\n\t\tthrown.expect(ValidationException.class);\n\t\tthrown.expect(containsCause(new ValidationException(\"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \" +\n\t\t\t\t\"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \" +\n\t\t\t\t\"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n\t\tTableSchema illegalSchema = TableSchema.builder()\n\t\t\t\t.field(\"region\", DataTypes.STRING())\n\t\t\t\t.field(\"view_count\", DataTypes.BIGINT())\n\t\t\t\t.build();\n\t\tcreateActualSink(illegalSchema, getFullSinkOptions());\n\t}\n","date":"2020-11-05 21:08:26","endLine":211,"groupId":"44344","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testCreateSinkTableWithoutPK","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/ed/f697ba642c4739d1fce777c5d3456fd5600ad1.src","preCode":"\tpublic void testCreateSinkTableWithoutPK() {\n\t\tthrown.expect(ValidationException.class);\n\t\tthrown.expect(containsCause(new ValidationException(\"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \" +\n\t\t\t\t\"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \" +\n\t\t\t\t\"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n\t\tTableSchema illegalSchema = TableSchema.builder()\n\t\t\t\t.field(\"region\", DataTypes.STRING())\n\t\t\t\t.field(\"view_count\", DataTypes.BIGINT())\n\t\t\t\t.build();\n\t\tcreateActualSink(illegalSchema, getFullSinkOptions());\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":200,"status":"N"}],"commitId":"5fb6c0b30cfe30bd8f3a3bfc5aed815049e7c6b8","commitMessage":"@@@[FLINK-20546][kafka] Fix util method misuse in KafkaDynamicTableFactoryTest\n\nThis closes #14371","date":"2020-12-22 11:25:21","modifiedFileCount":"2","status":"M","submitter":"zoucao"},{"authorTime":"2021-03-18 19:13:17","codes":[{"authorDate":"2021-03-18 19:13:17","commitOrder":3,"curCode":"    public void testCreateSourceTableWithoutPK() {\n        thrown.expect(ValidationException.class);\n        thrown.expect(\n                containsCause(\n                        new ValidationException(\n                                \"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \"\n                                        + \"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \"\n                                        + \"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n        ResolvedSchema illegalSchema =\n                ResolvedSchema.of(\n                        Column.physical(\"window_start\", DataTypes.STRING()),\n                        Column.physical(\"region\", DataTypes.STRING()),\n                        Column.physical(\"view_count\", DataTypes.BIGINT()));\n        createTableSource(illegalSchema, getFullSourceOptions());\n    }\n","date":"2021-03-24 04:35:35","endLine":356,"groupId":"10222","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testCreateSourceTableWithoutPK","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d0/5845ee2118da97c22951328d6daca8d02cb380.src","preCode":"    public void testCreateSourceTableWithoutPK() {\n        thrown.expect(ValidationException.class);\n        thrown.expect(\n                containsCause(\n                        new ValidationException(\n                                \"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \"\n                                        + \"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \"\n                                        + \"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n        TableSchema illegalSchema =\n                TableSchema.builder()\n                        .field(\"window_start\", DataTypes.STRING())\n                        .field(\"region\", DataTypes.STRING())\n                        .field(\"view_count\", DataTypes.BIGINT())\n                        .build();\n        createActualSource(illegalSchema, getFullSourceOptions());\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":341,"status":"M"},{"authorDate":"2021-03-18 19:13:17","commitOrder":3,"curCode":"    public void testCreateSinkTableWithoutPK() {\n        thrown.expect(ValidationException.class);\n        thrown.expect(\n                containsCause(\n                        new ValidationException(\n                                \"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \"\n                                        + \"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \"\n                                        + \"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n        ResolvedSchema illegalSchema =\n                ResolvedSchema.of(\n                        Column.physical(\"region\", DataTypes.STRING()),\n                        Column.physical(\"view_count\", DataTypes.BIGINT()));\n        createTableSink(illegalSchema, getFullSinkOptions());\n    }\n","date":"2021-03-24 04:35:35","endLine":373,"groupId":"10222","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"testCreateSinkTableWithoutPK","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d0/5845ee2118da97c22951328d6daca8d02cb380.src","preCode":"    public void testCreateSinkTableWithoutPK() {\n        thrown.expect(ValidationException.class);\n        thrown.expect(\n                containsCause(\n                        new ValidationException(\n                                \"'upsert-kafka' tables require to define a PRIMARY KEY constraint. \"\n                                        + \"The PRIMARY KEY specifies which columns should be read from or write to the Kafka message key. \"\n                                        + \"The PRIMARY KEY also defines records in the 'upsert-kafka' table should update or delete on which keys.\")));\n\n        TableSchema illegalSchema =\n                TableSchema.builder()\n                        .field(\"region\", DataTypes.STRING())\n                        .field(\"view_count\", DataTypes.BIGINT())\n                        .build();\n        createActualSink(illegalSchema, getFullSinkOptions());\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/table/UpsertKafkaDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":359,"status":"M"}],"commitId":"73338e22bd0567169ce2636c8f9e3b87df783385","commitMessage":"@@@[FLINK-21913][table][connectors] Update DynamicTableFactory.Context to use ResolvedCatalogTable\n\nThis closes #15316.\n","date":"2021-03-24 04:35:35","modifiedFileCount":"45","status":"M","submitter":"Timo Walther"}]
