[{"authorTime":"2020-11-24 10:53:43","codes":[{"authorDate":"2020-11-24 10:53:43","commitOrder":1,"curCode":"\tpublic void testStaticPartition() throws Exception {\n\t\tTableEnvironment tableEnv = getTableEnvWithHiveCatalog();\n\t\ttableEnv.executeSql(\"create database db1\");\n\t\ttry {\n\t\t\ttableEnv.executeSql(\"create table db1.src (x int)\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, \"db1\", \"src\").addRow(new Object[]{1}).addRow(new Object[]{2}).commit();\n\t\t\ttableEnv.executeSql(\"create table db1.dest (x int) partitioned by (p1 string, p2 double)\");\n\t\t\ttableEnv.executeSql(\"insert into db1.dest partition (p1='1''1', p2=1.1) select x from db1.src\").await();\n\t\t\tassertEquals(1, hiveCatalog.listPartitions(new ObjectPath(\"db1\", \"dest\")).size());\n\t\t\tverifyHiveQueryResult(\"select * from db1.dest\", Arrays.asList(\"1\\t1'1\\t1.1\", \"2\\t1'1\\t1.1\"));\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop database db1 cascade\");\n\t\t}\n\t}\n","date":"2020-11-24 10:53:43","endLine":305,"groupId":"26126","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testStaticPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b5/a205589503c558d65f03370724f8db1f77b844.src","preCode":"\tpublic void testStaticPartition() throws Exception {\n\t\tTableEnvironment tableEnv = getTableEnvWithHiveCatalog();\n\t\ttableEnv.executeSql(\"create database db1\");\n\t\ttry {\n\t\t\ttableEnv.executeSql(\"create table db1.src (x int)\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, \"db1\", \"src\").addRow(new Object[]{1}).addRow(new Object[]{2}).commit();\n\t\t\ttableEnv.executeSql(\"create table db1.dest (x int) partitioned by (p1 string, p2 double)\");\n\t\t\ttableEnv.executeSql(\"insert into db1.dest partition (p1='1''1', p2=1.1) select x from db1.src\").await();\n\t\t\tassertEquals(1, hiveCatalog.listPartitions(new ObjectPath(\"db1\", \"dest\")).size());\n\t\t\tverifyHiveQueryResult(\"select * from db1.dest\", Arrays.asList(\"1\\t1'1\\t1.1\", \"2\\t1'1\\t1.1\"));\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop database db1 cascade\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveRunnerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":292,"status":"B"},{"authorDate":"2020-11-24 10:53:43","commitOrder":1,"curCode":"\tpublic void testPartialDynamicPartition() throws Exception {\n\t\tTableEnvironment tableEnv = getTableEnvWithHiveCatalog();\n\t\ttableEnv.executeSql(\"create database db1\");\n\t\ttry {\n\t\t\ttableEnv.executeSql(\"create table db1.src (x int, y string)\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, \"db1\", \"src\").addRow(new Object[]{1, \"a\"}).addRow(new Object[]{2, \"b\"}).commit();\n\t\t\ttableEnv.executeSql(\"create table db1.dest (x int) partitioned by (p1 double, p2 string)\");\n\t\t\ttableEnv.executeSql(\"insert into db1.dest partition (p1=1.1) select x,y from db1.src\").await();\n\t\t\tassertEquals(2, hiveCatalog.listPartitions(new ObjectPath(\"db1\", \"dest\")).size());\n\t\t\tverifyHiveQueryResult(\"select * from db1.dest\", Arrays.asList(\"1\\t1.1\\ta\", \"2\\t1.1\\tb\"));\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop database db1 cascade\");\n\t\t}\n\t}\n","date":"2020-11-24 10:53:43","endLine":341,"groupId":"26128","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"testPartialDynamicPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/b5/a205589503c558d65f03370724f8db1f77b844.src","preCode":"\tpublic void testPartialDynamicPartition() throws Exception {\n\t\tTableEnvironment tableEnv = getTableEnvWithHiveCatalog();\n\t\ttableEnv.executeSql(\"create database db1\");\n\t\ttry {\n\t\t\ttableEnv.executeSql(\"create table db1.src (x int, y string)\");\n\t\t\tHiveTestUtils.createTextTableInserter(hiveCatalog, \"db1\", \"src\").addRow(new Object[]{1, \"a\"}).addRow(new Object[]{2, \"b\"}).commit();\n\t\t\ttableEnv.executeSql(\"create table db1.dest (x int) partitioned by (p1 double, p2 string)\");\n\t\t\ttableEnv.executeSql(\"insert into db1.dest partition (p1=1.1) select x,y from db1.src\").await();\n\t\t\tassertEquals(2, hiveCatalog.listPartitions(new ObjectPath(\"db1\", \"dest\")).size());\n\t\t\tverifyHiveQueryResult(\"select * from db1.dest\", Arrays.asList(\"1\\t1.1\\ta\", \"2\\t1.1\\tb\"));\n\t\t} finally {\n\t\t\ttableEnv.executeSql(\"drop database db1 cascade\");\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveRunnerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":328,"status":"B"}],"commitId":"e9b05e723fb02d9a6dae607ef28244eca6e9edc8","commitMessage":"@@@[FLINK-19653][hive] Reduce our dependency on hive runner for tests\n\nThis closes #14123","date":"2020-11-24 10:53:43","modifiedFileCount":"8","status":"B","submitter":"Rui Li"},{"authorTime":"2021-03-30 21:56:18","codes":[{"authorDate":"2021-03-30 21:56:18","commitOrder":2,"curCode":"    public void testStaticPartition() throws Exception {\n        TableEnvironment tableEnv = getTableEnvWithHiveCatalog();\n        tableEnv.executeSql(\"create database db1\");\n        try {\n            tableEnv.executeSql(\"create table db1.src (x int)\");\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"db1\", \"src\")\n                    .addRow(new Object[] {1})\n                    .addRow(new Object[] {2})\n                    .commit();\n            tableEnv.executeSql(\n                    \"create table db1.dest (x int) partitioned by (p1 string, p2 double)\");\n            tableEnv.executeSql(\n                            \"insert into db1.dest partition (p1='1\\\\'1', p2=1.1) select x from db1.src\")\n                    .await();\n            assertEquals(1, hiveCatalog.listPartitions(new ObjectPath(\"db1\", \"dest\")).size());\n            verifyHiveQueryResult(\n                    \"select * from db1.dest\", Arrays.asList(\"1\\t1'1\\t1.1\", \"2\\t1'1\\t1.1\"));\n        } finally {\n            tableEnv.executeSql(\"drop database db1 cascade\");\n        }\n    }\n","date":"2021-04-01 10:31:50","endLine":347,"groupId":"101075","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testStaticPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/01/864aeb6bd552c9bf184b8bf627f953196d7d76.src","preCode":"    public void testStaticPartition() throws Exception {\n        TableEnvironment tableEnv = getTableEnvWithHiveCatalog();\n        tableEnv.executeSql(\"create database db1\");\n        try {\n            tableEnv.executeSql(\"create table db1.src (x int)\");\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"db1\", \"src\")\n                    .addRow(new Object[] {1})\n                    .addRow(new Object[] {2})\n                    .commit();\n            tableEnv.executeSql(\n                    \"create table db1.dest (x int) partitioned by (p1 string, p2 double)\");\n            tableEnv.executeSql(\n                            \"insert into db1.dest partition (p1='1''1', p2=1.1) select x from db1.src\")\n                    .await();\n            assertEquals(1, hiveCatalog.listPartitions(new ObjectPath(\"db1\", \"dest\")).size());\n            verifyHiveQueryResult(\n                    \"select * from db1.dest\", Arrays.asList(\"1\\t1'1\\t1.1\", \"2\\t1'1\\t1.1\"));\n        } finally {\n            tableEnv.executeSql(\"drop database db1 cascade\");\n        }\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveRunnerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":327,"status":"M"},{"authorDate":"2021-03-30 21:56:18","commitOrder":2,"curCode":"    public void testPartialDynamicPartition() throws Exception {\n        TableEnvironment tableEnv = getTableEnvWithHiveCatalog();\n        tableEnv.executeSql(\"create database db1\");\n        try {\n            tableEnv.executeSql(\"create table db1.src (x int, y string)\");\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"db1\", \"src\")\n                    .addRow(new Object[] {1, \"a\"})\n                    .addRow(new Object[] {2, \"b\"})\n                    .commit();\n            tableEnv.executeSql(\n                    \"create table db1.dest (x int) partitioned by (p1 double, p2 string)\");\n            tableEnv.executeSql(\n                            \"insert into db1.dest partition (p1=1.1,p2) select x,y from db1.src\")\n                    .await();\n            assertEquals(2, hiveCatalog.listPartitions(new ObjectPath(\"db1\", \"dest\")).size());\n            verifyHiveQueryResult(\n                    \"select * from db1.dest\", Arrays.asList(\"1\\t1.1\\ta\", \"2\\t1.1\\tb\"));\n        } finally {\n            tableEnv.executeSql(\"drop database db1 cascade\");\n        }\n    }\n","date":"2021-04-01 10:31:50","endLine":392,"groupId":"101075","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"testPartialDynamicPartition","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/01/864aeb6bd552c9bf184b8bf627f953196d7d76.src","preCode":"    public void testPartialDynamicPartition() throws Exception {\n        TableEnvironment tableEnv = getTableEnvWithHiveCatalog();\n        tableEnv.executeSql(\"create database db1\");\n        try {\n            tableEnv.executeSql(\"create table db1.src (x int, y string)\");\n            HiveTestUtils.createTextTableInserter(hiveCatalog, \"db1\", \"src\")\n                    .addRow(new Object[] {1, \"a\"})\n                    .addRow(new Object[] {2, \"b\"})\n                    .commit();\n            tableEnv.executeSql(\n                    \"create table db1.dest (x int) partitioned by (p1 double, p2 string)\");\n            tableEnv.executeSql(\"insert into db1.dest partition (p1=1.1) select x,y from db1.src\")\n                    .await();\n            assertEquals(2, hiveCatalog.listPartitions(new ObjectPath(\"db1\", \"dest\")).size());\n            verifyHiveQueryResult(\n                    \"select * from db1.dest\", Arrays.asList(\"1\\t1.1\\ta\", \"2\\t1.1\\tb\"));\n        } finally {\n            tableEnv.executeSql(\"drop database db1 cascade\");\n        }\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveRunnerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":372,"status":"M"}],"commitId":"04bbf03a0cdb2f455c1b06569dea95ace6fa7e7c","commitMessage":"@@@[FLINK-21808][hive] Support DQL/DML in HiveParser\n\nThis closes #15253\n","date":"2021-04-01 10:31:50","modifiedFileCount":"21","status":"M","submitter":"Rui Li"}]
