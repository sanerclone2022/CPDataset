[{"authorTime":"2020-11-07 14:23:56","codes":[{"authorDate":"2020-11-07 14:23:56","commitOrder":2,"curCode":"\tpublic static void setup() {\n\t\tEnvironmentSettings settings = EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();\n\t\ttableEnv = TableEnvironment.create(settings);\n\t\thiveCatalog = HiveTestUtils.createHiveCatalog();\n\t\ttableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n\t\ttableEnv.useCatalog(hiveCatalog.getName());\n\t\ttableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n\t}\n","date":"2020-11-07 14:23:56","endLine":67,"groupId":"47693","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"setup","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/1e/dd19f00cbeff66ecf13a9118a548d5a8bbde12.src","preCode":"\tpublic static void setup() {\n\t\tEnvironmentSettings settings = EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();\n\t\ttableEnv = TableEnvironment.create(settings);\n\t\thiveCatalog = HiveTestUtils.createHiveCatalog();\n\t\ttableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n\t\ttableEnv.useCatalog(hiveCatalog.getName());\n\t\ttableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":60,"status":"B"},{"authorDate":"2020-11-07 14:23:56","commitOrder":2,"curCode":"\tpublic static void setup() {\n\t\tEnvironmentSettings settings = EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();\n\t\ttableEnv = TableEnvironment.create(settings);\n\t\thiveCatalog = HiveTestUtils.createHiveCatalog();\n\t\ttableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n\t\ttableEnv.useCatalog(hiveCatalog.getName());\n\t\t\r\n\t\tTestCollectionTableFactory.initData(\n\t\t\t\tArrays.asList(Row.of(1, \"a\"), Row.of(1, \"c\"), Row.of(2, \"b\"), Row.of(2, \"c\"), Row.of(3, \"c\"), Row.of(4, \"d\")));\n\t\ttableEnv.executeSql(\"create table default_catalog.default_database.probe (x int,y string, p as proctime()) \" +\n\t\t\t\t\"with ('connector'='COLLECTION','is-bounded' = 'false')\");\n\n\t\ttableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table bounded_table (x int, y string, z int) tblproperties ('%s'='5min')\",\n\t\t\t\tFileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table bounded_partition_table (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties ('%s'='5min')\",\n\t\t\t\tFileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table partition_table (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties ('%s' = 'true', '%s' = 'latest', '%s' = 'partition-name', '%s'='2h')\",\n\t\t\t\tSTREAMING_SOURCE_ENABLE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_INCLUDE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_ORDER.key(),\n\t\t\t\tSTREAMING_SOURCE_MONITOR_INTERVAL.key()\n\t\t));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table partition_table_1 (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties ('%s' = 'true', '%s' = 'latest', '%s'='120min')\",\n\t\t\t\tFileSystemOptions.STREAMING_SOURCE_ENABLE.key(),\n\t\t\t\tFileSystemOptions.STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n\t\t\t\tFileSystemOptions.STREAMING_SOURCE_MONITOR_INTERVAL.key()\n\t\t));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table partition_table_2 (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties (\" +\n\t\t\t\t\t\t\"'%s' = 'true',\" +\n\t\t\t\t\t\t\" '%s' = 'latest',\" +\n\t\t\t\t\t\t\" '%s' = '12h',\" +\n\t\t\t\t\t\t\" '%s' = 'partition-time', \" +\n\t\t\t\t\t\t\" '%s' = 'default',\" +\n\t\t\t\t\t\t\" '%s' = '$pt_year-$pt_mon-$pt_day 00:00:00')\",\n\t\t\t\tSTREAMING_SOURCE_ENABLE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_INCLUDE.key(),\n\t\t\t\tSTREAMING_SOURCE_MONITOR_INTERVAL.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_ORDER.key(),\n\t\t\t\tPARTITION_TIME_EXTRACTOR_KIND.key(),\n\t\t\t\tPARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN.key()\n\t\t));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table partition_table_3 (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties (\" +\n\t\t\t\t\t\t\" '%s' = 'true',\" +\n\t\t\t\t\t\t\" '%s' = 'latest',\" +\n\t\t\t\t\t\t\" '%s' = 'create-time')\",\n\t\t\t\tSTREAMING_SOURCE_ENABLE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_INCLUDE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_ORDER.key()\n\t\t));\n\t\ttableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n\t}\n","date":"2020-11-07 14:23:56","endLine":147,"groupId":"47693","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"setup","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/63/84134e0eeaede6d2fa8c8de449ec0a9810f56f.src","preCode":"\tpublic static void setup() {\n\t\tEnvironmentSettings settings = EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();\n\t\ttableEnv = TableEnvironment.create(settings);\n\t\thiveCatalog = HiveTestUtils.createHiveCatalog();\n\t\ttableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n\t\ttableEnv.useCatalog(hiveCatalog.getName());\n\t\t\r\n\t\tTestCollectionTableFactory.initData(\n\t\t\t\tArrays.asList(Row.of(1, \"a\"), Row.of(1, \"c\"), Row.of(2, \"b\"), Row.of(2, \"c\"), Row.of(3, \"c\"), Row.of(4, \"d\")));\n\t\ttableEnv.executeSql(\"create table default_catalog.default_database.probe (x int,y string, p as proctime()) \" +\n\t\t\t\t\"with ('connector'='COLLECTION','is-bounded' = 'false')\");\n\n\t\ttableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table bounded_table (x int, y string, z int) tblproperties ('%s'='5min')\",\n\t\t\t\tFileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table bounded_partition_table (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties ('%s'='5min')\",\n\t\t\t\tFileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table partition_table (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties ('%s' = 'true', '%s' = 'latest', '%s' = 'partition-name', '%s'='2h')\",\n\t\t\t\tSTREAMING_SOURCE_ENABLE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_INCLUDE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_ORDER.key(),\n\t\t\t\tSTREAMING_SOURCE_MONITOR_INTERVAL.key()\n\t\t));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table partition_table_1 (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties ('%s' = 'true', '%s' = 'latest', '%s'='120min')\",\n\t\t\t\tFileSystemOptions.STREAMING_SOURCE_ENABLE.key(),\n\t\t\t\tFileSystemOptions.STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n\t\t\t\tFileSystemOptions.STREAMING_SOURCE_MONITOR_INTERVAL.key()\n\t\t));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table partition_table_2 (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties (\" +\n\t\t\t\t\t\t\"'%s' = 'true',\" +\n\t\t\t\t\t\t\" '%s' = 'latest',\" +\n\t\t\t\t\t\t\" '%s' = '12h',\" +\n\t\t\t\t\t\t\" '%s' = 'partition-time', \" +\n\t\t\t\t\t\t\" '%s' = 'default',\" +\n\t\t\t\t\t\t\" '%s' = '$pt_year-$pt_mon-$pt_day 00:00:00')\",\n\t\t\t\tSTREAMING_SOURCE_ENABLE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_INCLUDE.key(),\n\t\t\t\tSTREAMING_SOURCE_MONITOR_INTERVAL.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_ORDER.key(),\n\t\t\t\tPARTITION_TIME_EXTRACTOR_KIND.key(),\n\t\t\t\tPARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN.key()\n\t\t));\n\n\t\t\r\n\t\ttableEnv.executeSql(String.format(\n\t\t\t\t\"create table partition_table_3 (x int, y string, z int) partitioned by (\" +\n\t\t\t\t\t\t\" pt_year int, pt_mon string, pt_day string)\" +\n\t\t\t\t\t\t\" tblproperties (\" +\n\t\t\t\t\t\t\" '%s' = 'true',\" +\n\t\t\t\t\t\t\" '%s' = 'latest',\" +\n\t\t\t\t\t\t\" '%s' = 'create-time')\",\n\t\t\t\tSTREAMING_SOURCE_ENABLE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_INCLUDE.key(),\n\t\t\t\tSTREAMING_SOURCE_PARTITION_ORDER.key()\n\t\t));\n\t\ttableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":69,"status":"MB"}],"commitId":"09386f27b66c86e8148ae8d25d72e3c2ac552362","commitMessage":"@@@[FLINK-19644][hive] Support read latest partition of Hive table in temporal join\n\nThis closes #13729","date":"2020-11-07 14:23:56","modifiedFileCount":"10","status":"M","submitter":"Leonard Xu"},{"authorTime":"2021-06-07 23:37:43","codes":[{"authorDate":"2021-06-07 23:37:43","commitOrder":3,"curCode":"    public static void setup() {\n        tableEnv = TableEnvironment.create(EnvironmentSettings.inStreamingMode());\n        hiveCatalog = HiveTestUtils.createHiveCatalog();\n        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        tableEnv.useCatalog(hiveCatalog.getName());\n        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n    }\n","date":"2021-06-11 15:34:45","endLine":65,"groupId":"47693","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"setup","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f2/56ef73338f1553fbeb6b0e4b312fd4c438d577.src","preCode":"    public static void setup() {\n        EnvironmentSettings settings =\n                EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();\n        tableEnv = TableEnvironment.create(settings);\n        hiveCatalog = HiveTestUtils.createHiveCatalog();\n        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        tableEnv.useCatalog(hiveCatalog.getName());\n        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"M"},{"authorDate":"2021-06-07 23:37:43","commitOrder":3,"curCode":"    public static void setup() {\n        tableEnv = TableEnvironment.create(EnvironmentSettings.inStreamingMode());\n        hiveCatalog = HiveTestUtils.createHiveCatalog();\n        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        tableEnv.useCatalog(hiveCatalog.getName());\n        \r\n        TestCollectionTableFactory.initData(\n                Arrays.asList(\n                        Row.of(1, \"a\"),\n                        Row.of(1, \"c\"),\n                        Row.of(2, \"b\"),\n                        Row.of(2, \"c\"),\n                        Row.of(3, \"c\"),\n                        Row.of(4, \"d\")));\n        tableEnv.executeSql(\n                \"create table default_catalog.default_database.probe (x int,y string, p as proctime()) \"\n                        + \"with ('connector'='COLLECTION','is-bounded' = 'false')\");\n\n        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table bounded_table (x int, y string, z int) tblproperties ('%s'='5min')\",\n                        FileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table bounded_partition_table (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s'='5min')\",\n                        FileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s' = 'true', '%s' = 'latest', '%s' = 'partition-name', '%s'='2h')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key(),\n                        STREAMING_SOURCE_MONITOR_INTERVAL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_1 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s' = 'true', '%s' = 'latest', '%s'='120min')\",\n                        FileSystemOptions.STREAMING_SOURCE_ENABLE.key(),\n                        FileSystemOptions.STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        FileSystemOptions.STREAMING_SOURCE_MONITOR_INTERVAL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_2 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties (\"\n                                + \"'%s' = 'true',\"\n                                + \" '%s' = 'latest',\"\n                                + \" '%s' = '12h',\"\n                                + \" '%s' = 'partition-time', \"\n                                + \" '%s' = 'default',\"\n                                + \" '%s' = '$pt_year-$pt_mon-$pt_day 00:00:00')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_MONITOR_INTERVAL.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key(),\n                        PARTITION_TIME_EXTRACTOR_KIND.key(),\n                        PARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_3 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties (\"\n                                + \" '%s' = 'true',\"\n                                + \" '%s' = 'latest',\"\n                                + \" '%s' = 'create-time')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key()));\n        tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n    }\n","date":"2021-06-11 15:34:45","endLine":154,"groupId":"47693","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"setup","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d6/d74072a336453d8ed6b30e6819f52a65776043.src","preCode":"    public static void setup() {\n        EnvironmentSettings settings =\n                EnvironmentSettings.newInstance().inStreamingMode().useBlinkPlanner().build();\n        tableEnv = TableEnvironment.create(settings);\n        hiveCatalog = HiveTestUtils.createHiveCatalog();\n        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        tableEnv.useCatalog(hiveCatalog.getName());\n        \r\n        TestCollectionTableFactory.initData(\n                Arrays.asList(\n                        Row.of(1, \"a\"),\n                        Row.of(1, \"c\"),\n                        Row.of(2, \"b\"),\n                        Row.of(2, \"c\"),\n                        Row.of(3, \"c\"),\n                        Row.of(4, \"d\")));\n        tableEnv.executeSql(\n                \"create table default_catalog.default_database.probe (x int,y string, p as proctime()) \"\n                        + \"with ('connector'='COLLECTION','is-bounded' = 'false')\");\n\n        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table bounded_table (x int, y string, z int) tblproperties ('%s'='5min')\",\n                        FileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table bounded_partition_table (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s'='5min')\",\n                        FileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s' = 'true', '%s' = 'latest', '%s' = 'partition-name', '%s'='2h')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key(),\n                        STREAMING_SOURCE_MONITOR_INTERVAL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_1 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s' = 'true', '%s' = 'latest', '%s'='120min')\",\n                        FileSystemOptions.STREAMING_SOURCE_ENABLE.key(),\n                        FileSystemOptions.STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        FileSystemOptions.STREAMING_SOURCE_MONITOR_INTERVAL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_2 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties (\"\n                                + \"'%s' = 'true',\"\n                                + \" '%s' = 'latest',\"\n                                + \" '%s' = '12h',\"\n                                + \" '%s' = 'partition-time', \"\n                                + \" '%s' = 'default',\"\n                                + \" '%s' = '$pt_year-$pt_mon-$pt_day 00:00:00')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_MONITOR_INTERVAL.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key(),\n                        PARTITION_TIME_EXTRACTOR_KIND.key(),\n                        PARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_3 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties (\"\n                                + \" '%s' = 'true',\"\n                                + \" '%s' = 'latest',\"\n                                + \" '%s' = 'create-time')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key()));\n        tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":68,"status":"M"}],"commitId":"bd27a2e2846186f59556c38b7bf562a9b04d14ac","commitMessage":"@@@[FLINK-22744][table] Update and simplify EnvironmentSettings\n","date":"2021-06-11 15:34:45","modifiedFileCount":"33","status":"M","submitter":"Timo Walther"},{"authorTime":"2021-06-30 19:35:51","codes":[{"authorDate":"2021-06-07 23:37:43","commitOrder":4,"curCode":"    public static void setup() {\n        tableEnv = TableEnvironment.create(EnvironmentSettings.inStreamingMode());\n        hiveCatalog = HiveTestUtils.createHiveCatalog();\n        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        tableEnv.useCatalog(hiveCatalog.getName());\n        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n    }\n","date":"2021-06-11 15:34:45","endLine":65,"groupId":"101077","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"setup","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/f2/56ef73338f1553fbeb6b0e4b312fd4c438d577.src","preCode":"    public static void setup() {\n        tableEnv = TableEnvironment.create(EnvironmentSettings.inStreamingMode());\n        hiveCatalog = HiveTestUtils.createHiveCatalog();\n        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        tableEnv.useCatalog(hiveCatalog.getName());\n        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveDynamicTableFactoryTest.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":59,"status":"N"},{"authorDate":"2021-06-30 19:35:51","commitOrder":4,"curCode":"    public static void setup() {\n        tableEnv = TableEnvironment.create(EnvironmentSettings.inStreamingMode());\n        hiveCatalog = HiveTestUtils.createHiveCatalog();\n        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        tableEnv.useCatalog(hiveCatalog.getName());\n        \r\n        TestCollectionTableFactory.initData(\n                Arrays.asList(\n                        Row.of(1, \"a\"),\n                        Row.of(1, \"c\"),\n                        Row.of(2, \"b\"),\n                        Row.of(2, \"c\"),\n                        Row.of(3, \"c\"),\n                        Row.of(4, \"d\")));\n        tableEnv.executeSql(\n                \"create table default_catalog.default_database.probe (x int,y string, p as proctime()) \"\n                        + \"with ('connector'='COLLECTION','is-bounded' = 'false')\");\n\n        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table bounded_table (x int, y string, z int) tblproperties ('%s'='5min')\",\n                        FileSystemConnectorOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table bounded_partition_table (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s'='5min')\",\n                        FileSystemConnectorOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s' = 'true', '%s' = 'latest', '%s' = 'partition-name', '%s'='2h')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key(),\n                        STREAMING_SOURCE_MONITOR_INTERVAL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_1 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s' = 'true', '%s' = 'latest', '%s'='120min')\",\n                        FileSystemConnectorOptions.STREAMING_SOURCE_ENABLE.key(),\n                        FileSystemConnectorOptions.STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        FileSystemConnectorOptions.STREAMING_SOURCE_MONITOR_INTERVAL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_2 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties (\"\n                                + \"'%s' = 'true',\"\n                                + \" '%s' = 'latest',\"\n                                + \" '%s' = '12h',\"\n                                + \" '%s' = 'partition-time', \"\n                                + \" '%s' = 'default',\"\n                                + \" '%s' = '$pt_year-$pt_mon-$pt_day 00:00:00')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_MONITOR_INTERVAL.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key(),\n                        PARTITION_TIME_EXTRACTOR_KIND.key(),\n                        PARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_3 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties (\"\n                                + \" '%s' = 'true',\"\n                                + \" '%s' = 'latest',\"\n                                + \" '%s' = 'create-time')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key()));\n        tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n    }\n","date":"2021-07-12 18:56:18","endLine":154,"groupId":"101077","id":6,"instanceNumber":2,"isCurCommit":1,"methodName":"setup","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/dd/4c82bd11885775ca2ad89d8e3560723ea4e4df.src","preCode":"    public static void setup() {\n        tableEnv = TableEnvironment.create(EnvironmentSettings.inStreamingMode());\n        hiveCatalog = HiveTestUtils.createHiveCatalog();\n        tableEnv.registerCatalog(hiveCatalog.getName(), hiveCatalog);\n        tableEnv.useCatalog(hiveCatalog.getName());\n        \r\n        TestCollectionTableFactory.initData(\n                Arrays.asList(\n                        Row.of(1, \"a\"),\n                        Row.of(1, \"c\"),\n                        Row.of(2, \"b\"),\n                        Row.of(2, \"c\"),\n                        Row.of(3, \"c\"),\n                        Row.of(4, \"d\")));\n        tableEnv.executeSql(\n                \"create table default_catalog.default_database.probe (x int,y string, p as proctime()) \"\n                        + \"with ('connector'='COLLECTION','is-bounded' = 'false')\");\n\n        tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table bounded_table (x int, y string, z int) tblproperties ('%s'='5min')\",\n                        FileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table bounded_partition_table (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s'='5min')\",\n                        FileSystemOptions.LOOKUP_JOIN_CACHE_TTL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s' = 'true', '%s' = 'latest', '%s' = 'partition-name', '%s'='2h')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key(),\n                        STREAMING_SOURCE_MONITOR_INTERVAL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_1 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties ('%s' = 'true', '%s' = 'latest', '%s'='120min')\",\n                        FileSystemOptions.STREAMING_SOURCE_ENABLE.key(),\n                        FileSystemOptions.STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        FileSystemOptions.STREAMING_SOURCE_MONITOR_INTERVAL.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_2 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties (\"\n                                + \"'%s' = 'true',\"\n                                + \" '%s' = 'latest',\"\n                                + \" '%s' = '12h',\"\n                                + \" '%s' = 'partition-time', \"\n                                + \" '%s' = 'default',\"\n                                + \" '%s' = '$pt_year-$pt_mon-$pt_day 00:00:00')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_MONITOR_INTERVAL.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key(),\n                        PARTITION_TIME_EXTRACTOR_KIND.key(),\n                        PARTITION_TIME_EXTRACTOR_TIMESTAMP_PATTERN.key()));\n\n        \r\n        tableEnv.executeSql(\n                String.format(\n                        \"create table partition_table_3 (x int, y string, z int) partitioned by (\"\n                                + \" pt_year int, pt_mon string, pt_day string)\"\n                                + \" tblproperties (\"\n                                + \" '%s' = 'true',\"\n                                + \" '%s' = 'latest',\"\n                                + \" '%s' = 'create-time')\",\n                        STREAMING_SOURCE_ENABLE.key(),\n                        STREAMING_SOURCE_PARTITION_INCLUDE.key(),\n                        STREAMING_SOURCE_PARTITION_ORDER.key()));\n        tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);\n    }\n","realPath":"flink-connectors/flink-connector-hive/src/test/java/org/apache/flink/connectors/hive/HiveLookupJoinITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":68,"status":"M"}],"commitId":"40fbef3a2538f128aa79c2e477be6bc836464aef","commitMessage":"@@@[FLINK-23064][table-runtime-blink] Expose FileSystemOptions as PublicEvolving\n","date":"2021-07-12 18:56:18","modifiedFileCount":"26","status":"M","submitter":"Ingo B?rk"}]
