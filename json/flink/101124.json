[{"authorTime":"2019-10-31 21:15:13","codes":[{"authorDate":"2019-10-31 21:15:13","commitOrder":1,"curCode":"\tpublic FileSinkOperator.RecordWriter getHiveRecordWriter(JobConf jobConf, String outputFormatClzName,\n\t\t\tClass<? extends Writable> outValClz, boolean isCompressed, Properties tableProps, Path outPath) {\n\t\ttry {\n\t\t\tClass outputFormatClz = Class.forName(outputFormatClzName);\n\t\t\tClass utilClass = HiveFileFormatUtils.class;\n\t\t\tMethod utilMethod = utilClass.getDeclaredMethod(\"getOutputFormatSubstitute\", Class.class, boolean.class);\n\t\t\toutputFormatClz = (Class) utilMethod.invoke(null, outputFormatClz, false);\n\t\t\tPreconditions.checkState(outputFormatClz != null, \"No Hive substitute output format for \" + outputFormatClzName);\n\t\t\tHiveOutputFormat outputFormat = (HiveOutputFormat) outputFormatClz.newInstance();\n\t\t\tutilMethod = utilClass.getDeclaredMethod(\"getRecordWriter\", JobConf.class, HiveOutputFormat.class,\n\t\t\t\t\tClass.class, boolean.class, Properties.class, Path.class, Reporter.class);\n\t\t\treturn (FileSinkOperator.RecordWriter) utilMethod.invoke(null,\n\t\t\t\t\tjobConf, outputFormat, outValClz, isCompressed, tableProps, outPath, Reporter.NULL);\n\t\t} catch (Exception e) {\n\t\t\tthrow new CatalogException(\"Failed to create Hive RecordWriter\", e);\n\t\t}\n\t}\n","date":"2019-11-02 01:34:29","endLine":325,"groupId":"3607","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"getHiveRecordWriter","params":"(JobConfjobConf@StringoutputFormatClzName@Class<?extendsWritable>outValClz@booleanisCompressed@PropertiestableProps@PathoutPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/4a/fef67745b53787d27512b13c960055ed271bd8.src","preCode":"\tpublic FileSinkOperator.RecordWriter getHiveRecordWriter(JobConf jobConf, String outputFormatClzName,\n\t\t\tClass<? extends Writable> outValClz, boolean isCompressed, Properties tableProps, Path outPath) {\n\t\ttry {\n\t\t\tClass outputFormatClz = Class.forName(outputFormatClzName);\n\t\t\tClass utilClass = HiveFileFormatUtils.class;\n\t\t\tMethod utilMethod = utilClass.getDeclaredMethod(\"getOutputFormatSubstitute\", Class.class, boolean.class);\n\t\t\toutputFormatClz = (Class) utilMethod.invoke(null, outputFormatClz, false);\n\t\t\tPreconditions.checkState(outputFormatClz != null, \"No Hive substitute output format for \" + outputFormatClzName);\n\t\t\tHiveOutputFormat outputFormat = (HiveOutputFormat) outputFormatClz.newInstance();\n\t\t\tutilMethod = utilClass.getDeclaredMethod(\"getRecordWriter\", JobConf.class, HiveOutputFormat.class,\n\t\t\t\t\tClass.class, boolean.class, Properties.class, Path.class, Reporter.class);\n\t\t\treturn (FileSinkOperator.RecordWriter) utilMethod.invoke(null,\n\t\t\t\t\tjobConf, outputFormat, outValClz, isCompressed, tableProps, outPath, Reporter.NULL);\n\t\t} catch (Exception e) {\n\t\t\tthrow new CatalogException(\"Failed to create Hive RecordWriter\", e);\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV100.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":309,"status":"B"},{"authorDate":"2019-10-31 21:15:13","commitOrder":1,"curCode":"\tpublic FileSinkOperator.RecordWriter getHiveRecordWriter(JobConf jobConf, String outputFormatClzName,\n\t\t\tClass<? extends Writable> outValClz, boolean isCompressed, Properties tableProps, Path outPath) {\n\t\ttry {\n\t\t\tClass outputFormatClz = Class.forName(outputFormatClzName);\n\t\t\tClass utilClass = HiveFileFormatUtils.class;\n\t\t\tMethod utilMethod = utilClass.getDeclaredMethod(\"getOutputFormatSubstitute\", Class.class);\n\t\t\toutputFormatClz = (Class) utilMethod.invoke(null, outputFormatClz);\n\t\t\tPreconditions.checkState(outputFormatClz != null, \"No Hive substitute output format for \" + outputFormatClzName);\n\t\t\tOutputFormat outputFormat = (OutputFormat) outputFormatClz.newInstance();\n\t\t\tutilMethod = utilClass.getDeclaredMethod(\"getRecordWriter\", JobConf.class, OutputFormat.class,\n\t\t\t\t\tClass.class, boolean.class, Properties.class, Path.class, Reporter.class);\n\t\t\treturn (FileSinkOperator.RecordWriter) utilMethod.invoke(null,\n\t\t\t\t\tjobConf, outputFormat, outValClz, isCompressed, tableProps, outPath, Reporter.NULL);\n\t\t} catch (Exception e) {\n\t\t\tthrow new CatalogException(\"Failed to create Hive RecordWriter\", e);\n\t\t}\n\t}\n","date":"2019-11-02 01:34:29","endLine":62,"groupId":"3607","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getHiveRecordWriter","params":"(JobConfjobConf@StringoutputFormatClzName@Class<?extendsWritable>outValClz@booleanisCompressed@PropertiestableProps@PathoutPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/69/1c14a5d083cee73dd66504fc754dbfe7f92662.src","preCode":"\tpublic FileSinkOperator.RecordWriter getHiveRecordWriter(JobConf jobConf, String outputFormatClzName,\n\t\t\tClass<? extends Writable> outValClz, boolean isCompressed, Properties tableProps, Path outPath) {\n\t\ttry {\n\t\t\tClass outputFormatClz = Class.forName(outputFormatClzName);\n\t\t\tClass utilClass = HiveFileFormatUtils.class;\n\t\t\tMethod utilMethod = utilClass.getDeclaredMethod(\"getOutputFormatSubstitute\", Class.class);\n\t\t\toutputFormatClz = (Class) utilMethod.invoke(null, outputFormatClz);\n\t\t\tPreconditions.checkState(outputFormatClz != null, \"No Hive substitute output format for \" + outputFormatClzName);\n\t\t\tOutputFormat outputFormat = (OutputFormat) outputFormatClz.newInstance();\n\t\t\tutilMethod = utilClass.getDeclaredMethod(\"getRecordWriter\", JobConf.class, OutputFormat.class,\n\t\t\t\t\tClass.class, boolean.class, Properties.class, Path.class, Reporter.class);\n\t\t\treturn (FileSinkOperator.RecordWriter) utilMethod.invoke(null,\n\t\t\t\t\tjobConf, outputFormat, outValClz, isCompressed, tableProps, outPath, Reporter.NULL);\n\t\t} catch (Exception e) {\n\t\t\tthrow new CatalogException(\"Failed to create Hive RecordWriter\", e);\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV110.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":46,"status":"B"}],"commitId":"15f8f3c52a1bf11ecf9f550388eee550b7fc763e","commitMessage":"@@@[FLINK-14588][hive] Support Hive version 1.0.0 and 1.0.1\n\nTo support Hive 1.0.0 and 1.0.1.\n\nThis closes #10062.\n","date":"2019-11-02 01:34:29","modifiedFileCount":"9","status":"B","submitter":"Rui Li"},{"authorTime":"2020-03-23 11:55:59","codes":[{"authorDate":"2020-03-23 11:55:59","commitOrder":2,"curCode":"\tpublic FileSinkOperator.RecordWriter getHiveRecordWriter(JobConf jobConf, Class outputFormatClz,\n\t\t\tClass<? extends Writable> outValClz, boolean isCompressed, Properties tableProps, Path outPath) {\n\t\ttry {\n\t\t\tClass utilClass = HiveFileFormatUtils.class;\n\t\t\tHiveOutputFormat outputFormat = (HiveOutputFormat) outputFormatClz.newInstance();\n\t\t\tMethod utilMethod = utilClass.getDeclaredMethod(\"getRecordWriter\", JobConf.class, HiveOutputFormat.class,\n\t\t\t\t\tClass.class, boolean.class, Properties.class, Path.class, Reporter.class);\n\t\t\treturn (FileSinkOperator.RecordWriter) utilMethod.invoke(null,\n\t\t\t\t\tjobConf, outputFormat, outValClz, isCompressed, tableProps, outPath, Reporter.NULL);\n\t\t} catch (Exception e) {\n\t\t\tthrow new CatalogException(\"Failed to create Hive RecordWriter\", e);\n\t\t}\n\t}\n","date":"2020-03-27 11:03:36","endLine":203,"groupId":"101124","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"getHiveRecordWriter","params":"(JobConfjobConf@ClassoutputFormatClz@Class<?extendsWritable>outValClz@booleanisCompressed@PropertiestableProps@PathoutPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/da/e39d1b7bd603763de70bbcbbbd959005e1eac6.src","preCode":"\tpublic FileSinkOperator.RecordWriter getHiveRecordWriter(JobConf jobConf, String outputFormatClzName,\n\t\t\tClass<? extends Writable> outValClz, boolean isCompressed, Properties tableProps, Path outPath) {\n\t\ttry {\n\t\t\tClass outputFormatClz = Class.forName(outputFormatClzName);\n\t\t\tClass utilClass = HiveFileFormatUtils.class;\n\t\t\tMethod utilMethod = utilClass.getDeclaredMethod(\"getOutputFormatSubstitute\", Class.class, boolean.class);\n\t\t\toutputFormatClz = (Class) utilMethod.invoke(null, outputFormatClz, false);\n\t\t\tPreconditions.checkState(outputFormatClz != null, \"No Hive substitute output format for \" + outputFormatClzName);\n\t\t\tHiveOutputFormat outputFormat = (HiveOutputFormat) outputFormatClz.newInstance();\n\t\t\tutilMethod = utilClass.getDeclaredMethod(\"getRecordWriter\", JobConf.class, HiveOutputFormat.class,\n\t\t\t\t\tClass.class, boolean.class, Properties.class, Path.class, Reporter.class);\n\t\t\treturn (FileSinkOperator.RecordWriter) utilMethod.invoke(null,\n\t\t\t\t\tjobConf, outputFormat, outValClz, isCompressed, tableProps, outPath, Reporter.NULL);\n\t\t} catch (Exception e) {\n\t\t\tthrow new CatalogException(\"Failed to create Hive RecordWriter\", e);\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV100.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":191,"status":"M"},{"authorDate":"2020-03-23 11:55:59","commitOrder":2,"curCode":"\tpublic FileSinkOperator.RecordWriter getHiveRecordWriter(JobConf jobConf, Class outputFormatClz,\n\t\t\tClass<? extends Writable> outValClz, boolean isCompressed, Properties tableProps, Path outPath) {\n\t\ttry {\n\t\t\tClass utilClass = HiveFileFormatUtils.class;\n\t\t\tOutputFormat outputFormat = (OutputFormat) outputFormatClz.newInstance();\n\t\t\tMethod utilMethod = utilClass.getDeclaredMethod(\"getRecordWriter\", JobConf.class, OutputFormat.class,\n\t\t\t\t\tClass.class, boolean.class, Properties.class, Path.class, Reporter.class);\n\t\t\treturn (FileSinkOperator.RecordWriter) utilMethod.invoke(null,\n\t\t\t\t\tjobConf, outputFormat, outValClz, isCompressed, tableProps, outPath, Reporter.NULL);\n\t\t} catch (Exception e) {\n\t\t\tthrow new CatalogException(\"Failed to create Hive RecordWriter\", e);\n\t\t}\n\t}\n","date":"2020-03-27 11:03:36","endLine":60,"groupId":"101124","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getHiveRecordWriter","params":"(JobConfjobConf@ClassoutputFormatClz@Class<?extendsWritable>outValClz@booleanisCompressed@PropertiestableProps@PathoutPath)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/8d/1885da1864190770dbde0ff908ca63d2e19772.src","preCode":"\tpublic FileSinkOperator.RecordWriter getHiveRecordWriter(JobConf jobConf, String outputFormatClzName,\n\t\t\tClass<? extends Writable> outValClz, boolean isCompressed, Properties tableProps, Path outPath) {\n\t\ttry {\n\t\t\tClass outputFormatClz = Class.forName(outputFormatClzName);\n\t\t\tClass utilClass = HiveFileFormatUtils.class;\n\t\t\tMethod utilMethod = utilClass.getDeclaredMethod(\"getOutputFormatSubstitute\", Class.class);\n\t\t\toutputFormatClz = (Class) utilMethod.invoke(null, outputFormatClz);\n\t\t\tPreconditions.checkState(outputFormatClz != null, \"No Hive substitute output format for \" + outputFormatClzName);\n\t\t\tOutputFormat outputFormat = (OutputFormat) outputFormatClz.newInstance();\n\t\t\tutilMethod = utilClass.getDeclaredMethod(\"getRecordWriter\", JobConf.class, OutputFormat.class,\n\t\t\t\t\tClass.class, boolean.class, Properties.class, Path.class, Reporter.class);\n\t\t\treturn (FileSinkOperator.RecordWriter) utilMethod.invoke(null,\n\t\t\t\t\tjobConf, outputFormat, outValClz, isCompressed, tableProps, outPath, Reporter.NULL);\n\t\t} catch (Exception e) {\n\t\t\tthrow new CatalogException(\"Failed to create Hive RecordWriter\", e);\n\t\t}\n\t}\n","realPath":"flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/table/catalog/hive/client/HiveShimV110.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":48,"status":"M"}],"commitId":"51b1a4f6e9baaf1bf5276aa1c8cf3fe4ebb57fe7","commitMessage":"@@@[FLINK-16647][table-runtime-blink][hive] Miss file extension when inserting to hive table with compression\n\nThis closes #11440\n","date":"2020-03-27 11:03:36","modifiedFileCount":"10","status":"M","submitter":"Rui Li"}]
