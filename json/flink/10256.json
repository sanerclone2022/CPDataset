[{"authorTime":"2019-07-30 17:52:38","codes":[{"authorDate":"2018-10-13 14:43:28","commitOrder":2,"curCode":"\tpublic void testResumeTransaction() throws IOException {\n\t\tString topicName = \"flink-kafka-producer-resume-transaction\";\n\t\ttry (FlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\tkafkaProducer.initTransactions();\n\t\t\tkafkaProducer.beginTransaction();\n\t\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\t\tkafkaProducer.flush();\n\t\t\tlong producerId = kafkaProducer.getProducerId();\n\t\t\tshort epoch = kafkaProducer.getEpoch();\n\n\t\t\ttry (FlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t}\n\n\t\t\tassertRecord(topicName, \"42\", \"42\");\n\n\t\t\t\r\n\t\t\tkafkaProducer.commitTransaction();\n\n\t\t\t\r\n\t\t\ttry (FlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t}\n\t\t}\n\t\tdeleteTestTopic(topicName);\n\t}\n","date":"2018-10-16 23:41:13","endLine":102,"groupId":"35874","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"testResumeTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/d3/5af108ca49f02a75526cef8211b152c51498a2.src","preCode":"\tpublic void testResumeTransaction() throws IOException {\n\t\tString topicName = \"flink-kafka-producer-resume-transaction\";\n\t\ttry (FlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\tkafkaProducer.initTransactions();\n\t\t\tkafkaProducer.beginTransaction();\n\t\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\t\tkafkaProducer.flush();\n\t\t\tlong producerId = kafkaProducer.getProducerId();\n\t\t\tshort epoch = kafkaProducer.getEpoch();\n\n\t\t\ttry (FlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t}\n\n\t\t\tassertRecord(topicName, \"42\", \"42\");\n\n\t\t\t\r\n\t\t\tkafkaProducer.commitTransaction();\n\n\t\t\t\r\n\t\t\ttry (FlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t}\n\t\t}\n\t\tdeleteTestTopic(topicName);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":75,"status":"NB"},{"authorDate":"2019-07-30 17:52:38","commitOrder":2,"curCode":"\tprivate FlinkKafkaInternalProducer<String, String> getClosedProducer(String topicName) {\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\tkafkaProducer.initTransactions();\n\t\tkafkaProducer.beginTransaction();\n\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\tkafkaProducer.close();\n\t\treturn kafkaProducer;\n\t}\n","date":"2019-08-01 15:01:33","endLine":162,"groupId":"35504","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"getClosedProducer","params":"(StringtopicName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/2d/749ba8bee544ff75eabcb035fb5feca2b88b45.src","preCode":"\tprivate FlinkKafkaInternalProducer<String, String> getClosedProducer(String topicName) {\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\tkafkaProducer.initTransactions();\n\t\tkafkaProducer.beginTransaction();\n\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\tkafkaProducer.close();\n\t\treturn kafkaProducer;\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":155,"status":"B"}],"commitId":"cc3184a35f2430c94535a095c2f926e912f692bf","commitMessage":"@@@[FLINK-13226][connector/kafka] Fix deadlock between producer closure and transaction commit in the universal Kafka connector.\n\nThis patch fixes a race condition between the checkpointing thread and main thread.\nThe sequence causing the deadlock is the following:\n\n    1. In FlinkKafkaProducer.  the main thread encounters a problem and closes all the producer\n       to start failover.\n    2. The previous checkpoint has completed.  so the checkpointing thread grabs the checkpoint\n       lock and tries to commit the transaction on the producer that has been closed in step 1.\n       This commit will never succeed due to KAFKA-6635. So the checkpoint thread blocks forever.\n    3. In StreamTask.  the main thread will eventually try to release all the record writer.\n       To do that.  it attempts to grab the checkpoint lock which is hold by checkpoint thread in\n       step 2 and will never be released. So the main thread also blocks forever.\n\nKAFKA-6635 has been fixed in Kafka 2.3.0. But Flink 1.9 does not rely on that yet.  So we are just\ngoing to fix on the Flink side first. The solution is to make sure that in FlinkKafkaProducer any\noperation relying on the underlying sender thread to finish throws an exception if the producer\nis closed.\n","date":"2019-08-01 15:01:33","modifiedFileCount":"2","status":"M","submitter":"Jiangjie (Becket) Qin"},{"authorTime":"2020-05-11 17:32:37","codes":[{"authorDate":"2020-05-11 17:32:37","commitOrder":3,"curCode":"\tpublic void testResumeTransaction() throws IOException {\n\t\tString topicName = \"flink-kafka-producer-resume-transaction\";\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\ttry {\n\t\t\tkafkaProducer.initTransactions();\n\t\t\tkafkaProducer.beginTransaction();\n\t\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\t\tkafkaProducer.flush();\n\t\t\tlong producerId = kafkaProducer.getProducerId();\n\t\t\tshort epoch = kafkaProducer.getEpoch();\n\n\t\t\tFlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\t\ttry {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t} finally {\n\t\t\t\tresumeProducer.close(Duration.ofSeconds(5));\n\t\t\t}\n\n\t\t\tassertRecord(topicName, \"42\", \"42\");\n\n\t\t\t\r\n\t\t\tkafkaProducer.commitTransaction();\n\n\t\t\t\r\n\t\t\tresumeProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\t\ttry {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t} finally {\n\t\t\t\tresumeProducer.close(Duration.ofSeconds(5));\n\t\t\t}\n\t\t} finally {\n\t\t\tkafkaProducer.close(Duration.ofSeconds(5));\n\t\t}\n\t\tdeleteTestTopic(topicName);\n\t}\n","date":"2020-06-16 00:53:46","endLine":134,"groupId":"35504","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"testResumeTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/53/fb7814a6b257306ac326c608c978f737218082.src","preCode":"\tpublic void testResumeTransaction() throws IOException {\n\t\tString topicName = \"flink-kafka-producer-resume-transaction\";\n\t\ttry (FlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\tkafkaProducer.initTransactions();\n\t\t\tkafkaProducer.beginTransaction();\n\t\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\t\tkafkaProducer.flush();\n\t\t\tlong producerId = kafkaProducer.getProducerId();\n\t\t\tshort epoch = kafkaProducer.getEpoch();\n\n\t\t\ttry (FlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t}\n\n\t\t\tassertRecord(topicName, \"42\", \"42\");\n\n\t\t\t\r\n\t\t\tkafkaProducer.commitTransaction();\n\n\t\t\t\r\n\t\t\ttry (FlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties)) {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t}\n\t\t}\n\t\tdeleteTestTopic(topicName);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":98,"status":"M"},{"authorDate":"2020-05-11 17:32:37","commitOrder":3,"curCode":"\tprivate FlinkKafkaInternalProducer<String, String> getClosedProducer(String topicName) {\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\tkafkaProducer.initTransactions();\n\t\tkafkaProducer.beginTransaction();\n\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\tkafkaProducer.close(Duration.ofSeconds(5));\n\t\treturn kafkaProducer;\n\t}\n","date":"2020-06-16 00:53:46","endLine":211,"groupId":"35504","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"getClosedProducer","params":"(StringtopicName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/53/fb7814a6b257306ac326c608c978f737218082.src","preCode":"\tprivate FlinkKafkaInternalProducer<String, String> getClosedProducer(String topicName) {\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\tkafkaProducer.initTransactions();\n\t\tkafkaProducer.beginTransaction();\n\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\tkafkaProducer.close();\n\t\treturn kafkaProducer;\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":204,"status":"M"}],"commitId":"711f619d3f61b7cf37b13fefb820edff2199b19d","commitMessage":"@@@[FLINK-17327] Always use close() with zero timeout in exactly-once Kafka Producer\n\nNOTE: This fix does not work without also bumping the Kafka version to\nsth > 2.4 (2.3 might work as well). Because of KAFKA-6635/KAFKA-7763.\n\nCalling close() without timeout is equivalent to calling\nclose(Long.MAX_VALUE). This will leave lingering Kafka threads on\nshutdown.  which eventually cause the Task Manager to be killed by the\nFlink Task watchdog.\n\nWe also forbid calling close() without a timeout on our internal\nProducer.  which means that we have to change some code that uses\ntry-with-resources.  because this calls close() without a timeout.\n\nWe need to call close with a zero timeout to prevent in-flight\ntransactions from being aborted by the KafkaProducer/sender. This would\nbreak how we use transactions in our Kafka Producer.\n\nWe don't update FlinkKafkaProducerBase.  which is used for\nnon-exactly-once Kafka Producers.\n","date":"2020-06-16 00:53:46","modifiedFileCount":"4","status":"M","submitter":"Aljoscha Krettek"},{"authorTime":"2019-08-17 22:47:52","codes":[{"authorDate":"2019-08-17 22:47:52","commitOrder":4,"curCode":"\tpublic void testResumeTransaction() throws Exception {\n\t\tString topicName = \"flink-kafka-producer-resume-transaction\";\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\ttry {\n\t\t\tkafkaProducer.initTransactions();\n\t\t\tkafkaProducer.beginTransaction();\n\t\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"), new ErrorCheckingCallback());\n\t\t\tkafkaProducer.flush();\n\t\t\tassertNull(\"The message should have been successfully sent\", exceptionInCallback);\n\t\t\tlong producerId = kafkaProducer.getProducerId();\n\t\t\tshort epoch = kafkaProducer.getEpoch();\n\n\t\t\tFlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\t\ttry {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t} finally {\n\t\t\t\tresumeProducer.close(Duration.ofSeconds(5));\n\t\t\t}\n\n\t\t\tassertRecord(topicName, \"42\", \"42\");\n\n\t\t\t\r\n\t\t\tkafkaProducer.commitTransaction();\n\n\t\t\t\r\n\t\t\tresumeProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\t\ttry {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t} finally {\n\t\t\t\tresumeProducer.close(Duration.ofSeconds(5));\n\t\t\t}\n\t\t} finally {\n\t\t\tkafkaProducer.close(Duration.ofSeconds(5));\n\t\t}\n\t\tdeleteTestTopic(topicName);\n\t}\n","date":"2020-11-11 13:55:29","endLine":139,"groupId":"10256","id":5,"instanceNumber":1,"isCurCommit":0,"methodName":"testResumeTransaction","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/7c/dc84dd794b28e2afcafa0a05b7fb774b923856.src","preCode":"\tpublic void testResumeTransaction() throws IOException {\n\t\tString topicName = \"flink-kafka-producer-resume-transaction\";\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\ttry {\n\t\t\tkafkaProducer.initTransactions();\n\t\t\tkafkaProducer.beginTransaction();\n\t\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\t\tkafkaProducer.flush();\n\t\t\tlong producerId = kafkaProducer.getProducerId();\n\t\t\tshort epoch = kafkaProducer.getEpoch();\n\n\t\t\tFlinkKafkaInternalProducer<String, String> resumeProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\t\ttry {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t} finally {\n\t\t\t\tresumeProducer.close(Duration.ofSeconds(5));\n\t\t\t}\n\n\t\t\tassertRecord(topicName, \"42\", \"42\");\n\n\t\t\t\r\n\t\t\tkafkaProducer.commitTransaction();\n\n\t\t\t\r\n\t\t\tresumeProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\t\ttry {\n\t\t\t\tresumeProducer.resumeTransaction(producerId, epoch);\n\t\t\t\tresumeProducer.commitTransaction();\n\t\t\t} finally {\n\t\t\t\tresumeProducer.close(Duration.ofSeconds(5));\n\t\t\t}\n\t\t} finally {\n\t\t\tkafkaProducer.close(Duration.ofSeconds(5));\n\t\t}\n\t\tdeleteTestTopic(topicName);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":102,"status":"M"},{"authorDate":"2019-08-17 22:47:52","commitOrder":4,"curCode":"\tprivate FlinkKafkaInternalProducer<String, String> getClosedProducer(String topicName) {\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\tkafkaProducer.initTransactions();\n\t\tkafkaProducer.beginTransaction();\n\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"), new ErrorCheckingCallback());\n\t\tkafkaProducer.close(Duration.ofSeconds(5));\n\t\tassertNull(\"The message should have been successfully sent\", exceptionInCallback);\n\t\treturn kafkaProducer;\n\t}\n","date":"2020-11-11 13:55:29","endLine":217,"groupId":"10256","id":6,"instanceNumber":2,"isCurCommit":0,"methodName":"getClosedProducer","params":"(StringtopicName)","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/7c/dc84dd794b28e2afcafa0a05b7fb774b923856.src","preCode":"\tprivate FlinkKafkaInternalProducer<String, String> getClosedProducer(String topicName) {\n\t\tFlinkKafkaInternalProducer<String, String> kafkaProducer = new FlinkKafkaInternalProducer<>(extraProperties);\n\t\tkafkaProducer.initTransactions();\n\t\tkafkaProducer.beginTransaction();\n\t\tkafkaProducer.send(new ProducerRecord<>(topicName, \"42\", \"42\"));\n\t\tkafkaProducer.close(Duration.ofSeconds(5));\n\t\treturn kafkaProducer;\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/FlinkKafkaInternalProducerITCase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":209,"status":"M"}],"commitId":"9528677754dfa78d136817d9116a14b5ceb3f0f2","commitMessage":"@@@[FLINK-13733][connector/kafka][test] Make FlinkKafkaInternalProducerITCase more robust.\n","date":"2020-11-11 13:55:29","modifiedFileCount":"1","status":"M","submitter":"Jiangjie (Becket) Qin"}]
