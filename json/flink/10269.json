[{"authorTime":"2020-10-16 20:19:57","codes":[{"authorDate":"2020-10-16 20:19:57","commitOrder":1,"curCode":"\tpublic void runOneSourceMultiplePartitionsExactlyOnceTest() throws Exception {\n\t\tfinal String topic = \"oneToManyTopic\";\n\t\tfinal int numPartitions = 5;\n\t\tfinal int numElementsPerPartition = 1000;\n\t\tfinal int totalElements = numPartitions * numElementsPerPartition;\n\t\tfinal int failAfterElements = numElementsPerPartition / 3;\n\n\t\tfinal int parallelism = 2;\n\n\t\tcreateTestTopic(topic, numPartitions, 1);\n\n\t\tDataGenerators.generateRandomizedIntegerSequence(\n\t\t\t\tStreamExecutionEnvironment.getExecutionEnvironment(),\n\t\t\t\tkafkaServer,\n\t\t\t\ttopic,\n\t\t\t\tnumPartitions,\n\t\t\t\tnumElementsPerPartition,\n\t\t\t\ttrue);\n\n\t\t\r\n\n\t\tDeserializationSchema<Integer> schema =\n\t\t\t\tnew TypeInformationSerializationSchema<>(BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\n\t\tProperties props = new Properties();\n\t\tprops.putAll(standardProps);\n\t\tprops.putAll(secureProps);\n\t\tFlinkKafkaConsumerBase<Integer> kafkaSource = kafkaServer.getConsumer(topic, schema, props);\n\n\t\tenv\n\t\t\t\t.addSource(kafkaSource)\n\t\t\t\t.map(new PartitionValidatingMapper(numPartitions, 3))\n\t\t\t\t.map(new FailingIdentityMapper<Integer>(failAfterElements))\n\t\t\t\t.addSink(new ValidatingExactlyOnceSink(totalElements)).setParallelism(1);\n\n\t\tFailingIdentityMapper.failedBefore = false;\n\t\ttryExecute(env, \"One-source-multi-partitions exactly once test\");\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2020-10-20 05:13:30","endLine":915,"groupId":"23047","id":1,"instanceNumber":1,"isCurCommit":0,"methodName":"runOneSourceMultiplePartitionsExactlyOnceTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/45/cb862f300a7c0e0f8a396a92a1bfcae40d57c2.src","preCode":"\tpublic void runOneSourceMultiplePartitionsExactlyOnceTest() throws Exception {\n\t\tfinal String topic = \"oneToManyTopic\";\n\t\tfinal int numPartitions = 5;\n\t\tfinal int numElementsPerPartition = 1000;\n\t\tfinal int totalElements = numPartitions * numElementsPerPartition;\n\t\tfinal int failAfterElements = numElementsPerPartition / 3;\n\n\t\tfinal int parallelism = 2;\n\n\t\tcreateTestTopic(topic, numPartitions, 1);\n\n\t\tDataGenerators.generateRandomizedIntegerSequence(\n\t\t\t\tStreamExecutionEnvironment.getExecutionEnvironment(),\n\t\t\t\tkafkaServer,\n\t\t\t\ttopic,\n\t\t\t\tnumPartitions,\n\t\t\t\tnumElementsPerPartition,\n\t\t\t\ttrue);\n\n\t\t\r\n\n\t\tDeserializationSchema<Integer> schema =\n\t\t\t\tnew TypeInformationSerializationSchema<>(BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\tenv.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\n\t\tProperties props = new Properties();\n\t\tprops.putAll(standardProps);\n\t\tprops.putAll(secureProps);\n\t\tFlinkKafkaConsumerBase<Integer> kafkaSource = kafkaServer.getConsumer(topic, schema, props);\n\n\t\tenv\n\t\t\t\t.addSource(kafkaSource)\n\t\t\t\t.map(new PartitionValidatingMapper(numPartitions, 3))\n\t\t\t\t.map(new FailingIdentityMapper<Integer>(failAfterElements))\n\t\t\t\t.addSink(new ValidatingExactlyOnceSink(totalElements)).setParallelism(1);\n\n\t\tFailingIdentityMapper.failedBefore = false;\n\t\ttryExecute(env, \"One-source-multi-partitions exactly once test\");\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":871,"status":"B"},{"authorDate":"2020-10-16 20:19:57","commitOrder":1,"curCode":"\tpublic void runMultipleSourcesOnePartitionExactlyOnceTest() throws Exception {\n\t\tfinal String topic = \"manyToOneTopic\";\n\t\tfinal int numPartitions = 5;\n\t\tfinal int numElementsPerPartition = 1000;\n\t\tfinal int totalElements = numPartitions * numElementsPerPartition;\n\t\tfinal int failAfterElements = numElementsPerPartition / 3;\n\n\t\tfinal int parallelism = 8;\n\n\t\tcreateTestTopic(topic, numPartitions, 1);\n\n\t\tDataGenerators.generateRandomizedIntegerSequence(\n\t\t\t\tStreamExecutionEnvironment.getExecutionEnvironment(),\n\t\t\t\tkafkaServer,\n\t\t\t\ttopic,\n\t\t\t\tnumPartitions,\n\t\t\t\tnumElementsPerPartition,\n\t\t\t\ttrue);\n\n\t\t\r\n\n\t\tDeserializationSchema<Integer> schema =\n\t\t\t\tnew TypeInformationSerializationSchema<>(BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\t\r\n\t\tenv.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\t\t\t\tenv.setBufferTimeout(0);\n\n\t\tProperties props = new Properties();\n\t\tprops.putAll(standardProps);\n\t\tprops.putAll(secureProps);\n\t\tFlinkKafkaConsumerBase<Integer> kafkaSource = kafkaServer.getConsumer(topic, schema, props);\n\n\t\tenv\n\t\t\t.addSource(kafkaSource)\n\t\t\t.map(new PartitionValidatingMapper(numPartitions, 1))\n\t\t\t.map(new FailingIdentityMapper<Integer>(failAfterElements))\n\t\t\t.addSink(new ValidatingExactlyOnceSink(totalElements)).setParallelism(1);\n\n\t\tFailingIdentityMapper.failedBefore = false;\n\t\ttryExecute(env, \"multi-source-one-partitions exactly once test\");\n\n\t\tdeleteTestTopic(topic);\n\t}\n","date":"2020-10-20 05:13:30","endLine":967,"groupId":"23045","id":2,"instanceNumber":2,"isCurCommit":0,"methodName":"runMultipleSourcesOnePartitionExactlyOnceTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/45/cb862f300a7c0e0f8a396a92a1bfcae40d57c2.src","preCode":"\tpublic void runMultipleSourcesOnePartitionExactlyOnceTest() throws Exception {\n\t\tfinal String topic = \"manyToOneTopic\";\n\t\tfinal int numPartitions = 5;\n\t\tfinal int numElementsPerPartition = 1000;\n\t\tfinal int totalElements = numPartitions * numElementsPerPartition;\n\t\tfinal int failAfterElements = numElementsPerPartition / 3;\n\n\t\tfinal int parallelism = 8;\n\n\t\tcreateTestTopic(topic, numPartitions, 1);\n\n\t\tDataGenerators.generateRandomizedIntegerSequence(\n\t\t\t\tStreamExecutionEnvironment.getExecutionEnvironment(),\n\t\t\t\tkafkaServer,\n\t\t\t\ttopic,\n\t\t\t\tnumPartitions,\n\t\t\t\tnumElementsPerPartition,\n\t\t\t\ttrue);\n\n\t\t\r\n\n\t\tDeserializationSchema<Integer> schema =\n\t\t\t\tnew TypeInformationSerializationSchema<>(BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n\t\tStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\t\tenv.enableCheckpointing(500);\n\t\tenv.setParallelism(parallelism);\n\t\t\r\n\t\tenv.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\t\t\t\tenv.setBufferTimeout(0);\n\n\t\tProperties props = new Properties();\n\t\tprops.putAll(standardProps);\n\t\tprops.putAll(secureProps);\n\t\tFlinkKafkaConsumerBase<Integer> kafkaSource = kafkaServer.getConsumer(topic, schema, props);\n\n\t\tenv\n\t\t\t.addSource(kafkaSource)\n\t\t\t.map(new PartitionValidatingMapper(numPartitions, 1))\n\t\t\t.map(new FailingIdentityMapper<Integer>(failAfterElements))\n\t\t\t.addSink(new ValidatingExactlyOnceSink(totalElements)).setParallelism(1);\n\n\t\tFailingIdentityMapper.failedBefore = false;\n\t\ttryExecute(env, \"multi-source-one-partitions exactly once test\");\n\n\t\tdeleteTestTopic(topic);\n\t}\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":921,"status":"B"}],"commitId":"a87407e60be4e69cb18b6d29b9754d740b8243f0","commitMessage":"@@@[FLINK-19672][connector-kafka] Merge connector-kafka-base and connector-kafka\n","date":"2020-10-20 05:13:30","modifiedFileCount":"0","status":"B","submitter":"Timo Walther"},{"authorTime":"2021-03-08 09:35:30","codes":[{"authorDate":"2021-03-08 09:35:30","commitOrder":2,"curCode":"    public void runOneSourceMultiplePartitionsExactlyOnceTest() throws Exception {\n        final String topic = \"oneToManyTopic\";\n        final int numPartitions = 5;\n        final int numElementsPerPartition = 1000;\n        final int totalElements = numPartitions * numElementsPerPartition;\n        final int failAfterElements = numElementsPerPartition / 3;\n\n        final int parallelism = 2;\n\n        createTestTopic(topic, numPartitions, 1);\n\n        DataGenerators.generateRandomizedIntegerSequence(\n                StreamExecutionEnvironment.getExecutionEnvironment(),\n                kafkaServer,\n                topic,\n                numPartitions,\n                numElementsPerPartition,\n                true);\n\n        \r\n\n        DeserializationSchema<Integer> schema =\n                new TypeInformationSerializationSchema<>(\n                        BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.enableCheckpointing(500);\n        env.setParallelism(parallelism);\n        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\n        Properties props = new Properties();\n        props.putAll(standardProps);\n        props.putAll(secureProps);\n\n        getStream(env, topic, schema, props)\n                .map(new PartitionValidatingMapper(numPartitions, 3))\n                .map(new FailingIdentityMapper<Integer>(failAfterElements))\n                .addSink(new ValidatingExactlyOnceSink(totalElements))\n                .setParallelism(1);\n\n        FailingIdentityMapper.failedBefore = false;\n        tryExecute(env, \"One-source-multi-partitions exactly once test\");\n\n        deleteTestTopic(topic);\n    }\n","date":"2021-03-30 07:53:01","endLine":1062,"groupId":"10269","id":3,"instanceNumber":1,"isCurCommit":0,"methodName":"runOneSourceMultiplePartitionsExactlyOnceTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/93/e0cfef96b5b0f0e877c88de0373924f5a0b515.src","preCode":"    public void runOneSourceMultiplePartitionsExactlyOnceTest() throws Exception {\n        final String topic = \"oneToManyTopic\";\n        final int numPartitions = 5;\n        final int numElementsPerPartition = 1000;\n        final int totalElements = numPartitions * numElementsPerPartition;\n        final int failAfterElements = numElementsPerPartition / 3;\n\n        final int parallelism = 2;\n\n        createTestTopic(topic, numPartitions, 1);\n\n        DataGenerators.generateRandomizedIntegerSequence(\n                StreamExecutionEnvironment.getExecutionEnvironment(),\n                kafkaServer,\n                topic,\n                numPartitions,\n                numElementsPerPartition,\n                true);\n\n        \r\n\n        DeserializationSchema<Integer> schema =\n                new TypeInformationSerializationSchema<>(\n                        BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.enableCheckpointing(500);\n        env.setParallelism(parallelism);\n        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\n        Properties props = new Properties();\n        props.putAll(standardProps);\n        props.putAll(secureProps);\n        FlinkKafkaConsumerBase<Integer> kafkaSource = kafkaServer.getConsumer(topic, schema, props);\n\n        env.addSource(kafkaSource)\n                .map(new PartitionValidatingMapper(numPartitions, 3))\n                .map(new FailingIdentityMapper<Integer>(failAfterElements))\n                .addSink(new ValidatingExactlyOnceSink(totalElements))\n                .setParallelism(1);\n\n        FailingIdentityMapper.failedBefore = false;\n        tryExecute(env, \"One-source-multi-partitions exactly once test\");\n\n        deleteTestTopic(topic);\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":1018,"status":"M"},{"authorDate":"2021-03-08 09:35:30","commitOrder":2,"curCode":"    public void runMultipleSourcesOnePartitionExactlyOnceTest() throws Exception {\n        final String topic = \"manyToOneTopic\";\n        final int numPartitions = 5;\n        final int numElementsPerPartition = 1000;\n        final int totalElements = numPartitions * numElementsPerPartition;\n        final int failAfterElements = numElementsPerPartition / 3;\n\n        final int parallelism = 8;\n\n        createTestTopic(topic, numPartitions, 1);\n\n        DataGenerators.generateRandomizedIntegerSequence(\n                StreamExecutionEnvironment.getExecutionEnvironment(),\n                kafkaServer,\n                topic,\n                numPartitions,\n                numElementsPerPartition,\n                true);\n\n        \r\n\n        DeserializationSchema<Integer> schema =\n                new TypeInformationSerializationSchema<>(\n                        BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.enableCheckpointing(500);\n        env.setParallelism(parallelism);\n        \r\n        \r\n        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n        env.setBufferTimeout(0);\n\n        Properties props = new Properties();\n        props.putAll(standardProps);\n        props.putAll(secureProps);\n\n        getStream(env, topic, schema, props)\n                .map(new PartitionValidatingMapper(numPartitions, 1))\n                .map(new FailingIdentityMapper<Integer>(failAfterElements))\n                .addSink(new ValidatingExactlyOnceSink(totalElements))\n                .setParallelism(1);\n\n        FailingIdentityMapper.failedBefore = false;\n        tryExecute(env, \"multi-source-one-partitions exactly once test\");\n\n        deleteTestTopic(topic);\n    }\n","date":"2021-03-30 07:53:01","endLine":1115,"groupId":"10269","id":4,"instanceNumber":2,"isCurCommit":0,"methodName":"runMultipleSourcesOnePartitionExactlyOnceTest","params":"()","path":"/mnt/clonedata/CloneManagementServer/ManagementServer/consistResult/result-flink-10-0.7/blobInfo/CC_OUT/blobs/93/e0cfef96b5b0f0e877c88de0373924f5a0b515.src","preCode":"    public void runMultipleSourcesOnePartitionExactlyOnceTest() throws Exception {\n        final String topic = \"manyToOneTopic\";\n        final int numPartitions = 5;\n        final int numElementsPerPartition = 1000;\n        final int totalElements = numPartitions * numElementsPerPartition;\n        final int failAfterElements = numElementsPerPartition / 3;\n\n        final int parallelism = 8;\n\n        createTestTopic(topic, numPartitions, 1);\n\n        DataGenerators.generateRandomizedIntegerSequence(\n                StreamExecutionEnvironment.getExecutionEnvironment(),\n                kafkaServer,\n                topic,\n                numPartitions,\n                numElementsPerPartition,\n                true);\n\n        \r\n\n        DeserializationSchema<Integer> schema =\n                new TypeInformationSerializationSchema<>(\n                        BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        env.enableCheckpointing(500);\n        env.setParallelism(parallelism);\n        \r\n        \r\n        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n        env.setBufferTimeout(0);\n\n        Properties props = new Properties();\n        props.putAll(standardProps);\n        props.putAll(secureProps);\n        FlinkKafkaConsumerBase<Integer> kafkaSource = kafkaServer.getConsumer(topic, schema, props);\n\n        env.addSource(kafkaSource)\n                .map(new PartitionValidatingMapper(numPartitions, 1))\n                .map(new FailingIdentityMapper<Integer>(failAfterElements))\n                .addSink(new ValidatingExactlyOnceSink(totalElements))\n                .setParallelism(1);\n\n        FailingIdentityMapper.failedBefore = false;\n        tryExecute(env, \"multi-source-one-partitions exactly once test\");\n\n        deleteTestTopic(topic);\n    }\n","realPath":"flink-connectors/flink-connector-kafka/src/test/java/org/apache/flink/streaming/connectors/kafka/KafkaConsumerTestBase.java","repoName":"flink","snippetEndLine":0,"snippetStartLine":0,"startLine":1068,"status":"M"}],"commitId":"3abf5550a11ac4733799187bf49122417a177b6a","commitMessage":"@@@[FLINK-20114][connector/kafka] Add IT cases for KafkaSource by migrating IT cases from FlinkKafkaConsumer.\n","date":"2021-03-30 07:53:01","modifiedFileCount":"4","status":"M","submitter":"Dong Lin"}]
